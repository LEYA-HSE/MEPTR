{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2a5532a-325e-4224-a422-7e8679fcb6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import random\n",
    "import logging\n",
    "from torch.utils.data import DataLoader, ConcatDataset, WeightedRandomSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import pickle\n",
    "import ast\n",
    "from copy import deepcopy\n",
    "\n",
    "import warnings\n",
    "for warn in [UserWarning, FutureWarning]: warnings.filterwarnings(\"ignore\", category = warn)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3292b4a0-d762-437f-bd58-4f09f2f3c3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMambaBlock(nn.Module):\n",
    "    def __init__(self, d_input, d_model, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.in_proj = nn.Linear(d_input, d_model)\n",
    "        self.s_B = nn.Linear(d_model, d_model)\n",
    "        self.s_C = nn.Linear(d_model, d_model)\n",
    "        self.out_proj = nn.Linear(d_model, d_input)\n",
    "        self.norm = nn.LayerNorm(d_input)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_in = x\n",
    "        x = self.in_proj(x)\n",
    "        B = self.s_B(x)\n",
    "        C = self.s_C(x)\n",
    "        x = x + B + C\n",
    "        x = self.activation(x)\n",
    "        x = self.out_proj(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.norm(x + x_in)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a54ebd3f-6f53-4662-8afe-67c659dfbd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.layer_1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.layer_2 = nn.Linear(hidden_dim, input_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer_1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.dropout(x)\n",
    "        return self.layer_2(x)\n",
    "class AddAndNorm(nn.Module):\n",
    "    def __init__(self, input_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(input_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, residual):\n",
    "        return self.norm(x + self.dropout(residual))\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[: x.size(1)].detach()  # Отключаем градиенты\n",
    "        return self.dropout(x)\n",
    "\n",
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, input_dim, num_heads, dropout=0.1, positional_encoding=False):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.self_attention = nn.MultiheadAttention(input_dim, num_heads, dropout=dropout, batch_first=True)\n",
    "        self.feed_forward = PositionWiseFeedForward(input_dim, input_dim, dropout=dropout)\n",
    "        self.add_norm_after_attention = AddAndNorm(input_dim, dropout=dropout)\n",
    "        self.add_norm_after_ff = AddAndNorm(input_dim, dropout=dropout)\n",
    "        self.positional_encoding = PositionalEncoding(input_dim) if positional_encoding else None\n",
    "\n",
    "    def forward(self, query, key, value):\n",
    "        if self.positional_encoding:\n",
    "            key = self.positional_encoding(key)\n",
    "            value = self.positional_encoding(value)\n",
    "            query = self.positional_encoding(query)\n",
    "\n",
    "        attn_output, _ = self.self_attention(query, key, value, need_weights=False)\n",
    "\n",
    "        x = self.add_norm_after_attention(attn_output, query)\n",
    "\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.add_norm_after_ff(ff_output, x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a8da44a-5ce2-4532-8c95-7fb9e0805ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionMamba(nn.Module):\n",
    "    def __init__(self, input_dim_emotion=1024, input_dim_personality=1024, hidden_dim=128, out_features=512, mamba_layer_number=2, mamba_d_model=256, positional_encoding=True, num_transformer_heads=4, transformer_dropout=0.1, tr_layer_number=1, dropout=0.1, num_emotions=7, num_traits=5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.emo_proj = nn.Sequential(\n",
    "            nn.Linear(input_dim_emotion, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        self.emotion_encoder = nn.ModuleList([\n",
    "            CustomMambaBlock(hidden_dim, mamba_d_model, dropout=dropout)\n",
    "            for _ in range(mamba_layer_number)\n",
    "        ])\n",
    "\n",
    "\n",
    "        self.emotion_fc_out = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, out_features),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(out_features, num_emotions)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, emotion_input=None, personality_input=None, return_features=False):\n",
    "        emo = self.emo_proj(emotion_input)  # (B, T, hidden_dim)\n",
    "        for layer in self.emotion_encoder:\n",
    "            emo = layer(emo)\n",
    "        out_emo = self.emotion_fc_out(emo.mean(dim=1))  # (B, num_emotions)\n",
    "        if return_features:\n",
    "            return {\n",
    "                'emotion_logits': out_emo,\n",
    "                'last_encoder_features': emo,\n",
    "            }\n",
    "        else:\n",
    "            return {'emotion_logits': out_emo}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a3ff704-1a0d-4645-8b1b-07d1e2b105b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersonalityMamba(nn.Module):\n",
    "    def __init__(self, input_dim_emotion=1024, input_dim_personality=1024, hidden_dim=128, out_features=512, mamba_layer_number=2, mamba_d_model=256, per_activation=\"sigmoid\", positional_encoding=True, num_transformer_heads=4, tr_layer_number=1, dropout=0.1, num_emotions=7, num_traits=5, device='cpu'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.per_proj = nn.Sequential(\n",
    "            nn.Linear(input_dim_personality, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        self.personality_encoder = nn.ModuleList([\n",
    "            CustomMambaBlock(hidden_dim, mamba_d_model, dropout=dropout)\n",
    "            for _ in range(mamba_layer_number)\n",
    "        ])\n",
    "\n",
    "        self.personality_fc_out = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, out_features),\n",
    "            nn.LayerNorm(out_features),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(out_features, num_traits)\n",
    "        )\n",
    "\n",
    "        if per_activation == \"sigmoid\":\n",
    "            self.activation = nn.Sigmoid()\n",
    "        elif per_activation == \"relu\":\n",
    "            self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, emotion_input=None, personality_input=None, return_features=False):\n",
    "        per = self.per_proj(personality_input)\n",
    "\n",
    "        for layer in self.personality_encoder:\n",
    "            per = layer(per)\n",
    "\n",
    "        out_per = self.personality_fc_out(per.mean(dim=1))\n",
    "    \n",
    "        if return_features:\n",
    "            return {\n",
    "                'personality_scores': self.activation(out_per),\n",
    "                'last_encoder_features': per,\n",
    "            }\n",
    "        else:\n",
    "            return {'personality_scores': self.activation(out_per)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b7a1a3f-448f-4c9a-8381-dc832ed6c181",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FusionTransformer(nn.Module):\n",
    "    def __init__(self, emo_model, per_model, input_dim_emotion=512, input_dim_personality=512, hidden_dim=128, out_features=512, mamba_layer_number=2, mamba_d_model=256, per_activation=\"sigmoid\", positional_encoding=True, num_transformer_heads=4, tr_layer_number=1, dropout=0.1, num_emotions=7, num_traits=5, device='cpu'):\n",
    "        super().__init__()\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.emo_model = emo_model\n",
    "        self.per_model = per_model\n",
    "\n",
    "        for param in self.emo_model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        for param in self.per_model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.emo_proj = nn.Sequential(\n",
    "            nn.Linear(self.emo_model.hidden_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        self.per_proj = nn.Sequential(\n",
    "            nn.Linear(self.per_model.hidden_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        self.emotion_to_personality_attn = nn.ModuleList([\n",
    "            TransformerEncoderLayer(\n",
    "                input_dim=hidden_dim,\n",
    "                num_heads=num_transformer_heads,\n",
    "                dropout=dropout,\n",
    "                positional_encoding=positional_encoding\n",
    "            ) for _ in range(tr_layer_number)\n",
    "        ])\n",
    "\n",
    "        self.personality_to_emotion_attn = nn.ModuleList([\n",
    "            TransformerEncoderLayer(\n",
    "                input_dim=hidden_dim,\n",
    "                num_heads=num_transformer_heads,\n",
    "                dropout=dropout,\n",
    "                positional_encoding=positional_encoding\n",
    "            ) for _ in range(tr_layer_number)\n",
    "        ])\n",
    "\n",
    "        self.emotion_personality_fc_out = nn.Sequential(\n",
    "            nn.Linear(hidden_dim*2, out_features),\n",
    "            nn.LayerNorm(out_features),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(out_features, num_emotions)\n",
    "        )\n",
    "\n",
    "        self.personality_emotion_fc_out = nn.Sequential(\n",
    "            nn.Linear(hidden_dim*2, out_features),\n",
    "            nn.LayerNorm(out_features),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(out_features, num_traits)\n",
    "        )        \n",
    "\n",
    "        if per_activation == \"sigmoid\":\n",
    "            self.activation = nn.Sigmoid()\n",
    "        elif per_activation == \"relu\":\n",
    "            self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, emotion_input=None, personality_input=None, return_features=False):\n",
    "        emo_features = self.emo_model(emotion_input=emotion_input, return_features=True)\n",
    "        per_features = self.per_model(personality_input=personality_input, return_features=True)\n",
    "\n",
    "        emo_emd = self.emo_proj(emo_features['last_encoder_features'])\n",
    "        per_emd = self.per_proj(per_features['last_encoder_features'])\n",
    "        \n",
    "        # padding\n",
    "        max_len = max(emo_emd.shape[1], per_emd.shape[1])\n",
    "        emo_emd = emo_emd.cpu().detach().numpy()\n",
    "        per_emd = per_emd.cpu().detach().numpy()\n",
    "        emo_emd = np.pad(emo_emd[:, :max_len, :], ((0, 0), (0, max(0, max_len - emo_emd.shape[1])), (0, 0)), \"constant\")\n",
    "        per_emd = np.pad(per_emd[:, :max_len, :], ((0, 0), (0, max(0, max_len - per_emd.shape[1])), (0, 0)), \"constant\")\n",
    "        emo_emd = torch.tensor(emo_emd, device=self.device)\n",
    "        per_emd = torch.tensor(per_emd, device=self.device)\n",
    "\n",
    "        for layer in self.emotion_to_personality_attn:\n",
    "            emo_emd += layer(emo_emd, per_emd, per_emd) # or per_emd, emo_emd, emo_emd\n",
    "\n",
    "        for layer in self.personality_to_emotion_attn:\n",
    "            per_emd += layer(per_emd, emo_emd, emo_emd) # or emo_emd, per_emd, per_emd\n",
    "\n",
    "        fused = torch.cat([emo_emd, per_emd], dim=-1)\n",
    "        emotion_logits = self.emotion_personality_fc_out(fused.mean(dim=1))\n",
    "        personality_scores = self.personality_emotion_fc_out(fused.mean(dim=1))\n",
    "\n",
    "        if return_features:\n",
    "            return {\n",
    "                'emotion_logits': (emotion_logits+emo_features['emotion_logits'])/2,\n",
    "                'personality_scores': (self.activation(personality_scores)+per_features['personality_scores'])/2,\n",
    "                'last_emo_encoder_features': emo_emd,\n",
    "                'last_per_encoder_features': per_emd,\n",
    "            }\n",
    "        else:\n",
    "            return {'emotion_logits': (emotion_logits+emo_features['emotion_logits'])/2,\n",
    "                    'personality_scores': (self.activation(personality_scores)+per_features['personality_scores'])/2,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "594b9946-2588-4a0d-b7a7-964cb1472558",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9eb1eb8-3536-43a2-961a-d2ca61fe0a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_matrix(matrix):\n",
    "    threshold1 = 1 - 1/7 \n",
    "    threshold2 = 1/7\n",
    "    mask1 = matrix[:, 0] >= threshold1\n",
    "    result = np.zeros_like(matrix[:, 1:])\n",
    "    transformed = (matrix[:, 1:] >= threshold2).astype(int)\n",
    "    result[~mask1] = transformed[~mask1]\n",
    "    return result\n",
    "def process_predictions(pred_emo):\n",
    "    pred_emo = torch.nn.functional.softmax(pred_emo, dim=1).cpu().detach().numpy()\n",
    "    pred_emo = transform_matrix(pred_emo).tolist()\n",
    "    return pred_emo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3ad79c-0c9e-45a9-8324-c6a5a878b65c",
   "metadata": {},
   "source": [
    "### Load emotion classifier and personality regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4366b6df-5ab1-44cd-a064-9843337f1c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "emo_path = os.path.join(\".\", \"best_models\", \"Mamba_bge-small_emotion.pt\")\n",
    "pers_path = os.path.join(\".\", \"best_models\", \"Mamba_bge-small_personality.pt\")\n",
    "fusion_path = os.path.join(\".\", \"best_models\", \"Mamba_bge-small_fusion_best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d72a7414-3054-477e-b928-0365f0e70c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models(emo_path, pers_path, fusion_path, device):\n",
    "    emo_model = EmotionMamba(input_dim_emotion=384, input_dim_personality=384, hidden_dim=256, out_features=256, mamba_layer_number=4, mamba_d_model=256, dropout=0.2).to(device)\n",
    "    checkpoint = torch.load(emo_path, map_location=device)\n",
    "    emo_model.load_state_dict(checkpoint)\n",
    "    \n",
    "    per_model = PersonalityMamba(input_dim_emotion=384, input_dim_personality=384, hidden_dim=128, out_features=128, mamba_layer_number=1, mamba_d_model=128, dropout=0.1).to(device)\n",
    "    checkpoint = torch.load(pers_path, map_location=device)\n",
    "    per_model.load_state_dict(checkpoint)\n",
    "    \n",
    "    model = FusionTransformer(emo_model, per_model, input_dim_emotion=384, input_dim_personality=384, hidden_dim=256, out_features=512, tr_layer_number=2, num_transformer_heads=8).to(device)\n",
    "    checkpoint = torch.load(fusion_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f833fd8-9efb-481c-836a-3ca6333a5f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_models(emo_path, pers_path, fusion_path, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f37feac-ffae-4777-931a-3ae7340d0b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, text, device):\n",
    "    feature_extractor_tokenizer = AutoTokenizer.from_pretrained(\"BAAI/bge-small-en-v1.5\")\n",
    "    feature_extractor_model = AutoModel.from_pretrained(\"BAAI/bge-small-en-v1.5\").to(device)\n",
    "    encoded_input = feature_extractor_tokenizer(text, padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "    with torch.no_grad():\n",
    "        features = feature_extractor_model(**encoded_input)[0][0]\n",
    "    model.eval()\n",
    "    return model(emotion_input=features.unsqueeze(0).to(device), personality_input=features.unsqueeze(0).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "628fb222-8df1-4157-8b69-359f5e850f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = inference(model, 'You are the best!', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ce520f8-496c-44e4-8e05-bc3fdc309bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion\n",
      "  Neutral: 0.1192\n",
      "  Anger: 0.0658\n",
      "  Disgust: 0.0078\n",
      "  Fear: 0.0506\n",
      "  Happiness: 0.6279\n",
      "  Sadness: 0.0335\n",
      "  Surprise: 0.0953\n",
      "Personality\n",
      "  Openness: 0.8092\n",
      "  Conscientiousness: 0.6119\n",
      "  Extraversion: 0.7637\n",
      "  Agreeableness: 0.6649\n",
      "  Neuroticism: 0.7665\n"
     ]
    }
   ],
   "source": [
    "print(\"Emotion\")\n",
    "prob_emo = torch.nn.functional.softmax(logits['emotion_logits'], dim=1).cpu().detach().numpy()\n",
    "emo_names = ['Neutral', 'Anger', 'Disgust', 'Fear', 'Happiness', 'Sadness', 'Surprise']\n",
    "for name, v in zip(emo_names, prob_emo[0]):\n",
    "    print(f\"  {name}: {v:.4f}\")\n",
    "print(\"Personality\")   \n",
    "pers_names = ['Openness', 'Conscientiousness', 'Extraversion', 'Agreeableness', 'Neuroticism']\n",
    "for name, v in zip(pers_names, logits['personality_scores'].tolist()[0]):\n",
    "    print(f\"  {name}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c3f223-bbfb-4644-8c22-56772ebe66a9",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fd7136df-70bd-427f-a02c-9eb1caa7918e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cmu_mosei_data(path, part='train'):\n",
    "    if part in ['train', 'dev', 'test']:\n",
    "        df = pd.read_csv(os.path.join(path, part + \"_full.csv\"))\n",
    "    else:\n",
    "        raise ValueError('Unknown part of train / dev / test')\n",
    "    return df.text.values, np.dstack((df.Neutral.to_numpy(), df.Anger.to_numpy(), df.Disgust.to_numpy(), df.Fear.to_numpy(), df.Happiness.to_numpy(), df.Sadness.to_numpy(), df.Surprise.to_numpy()))\n",
    "\n",
    "def get_first_imp_data(path, part='train'):\n",
    "    if part in ['train', 'dev', 'test']:\n",
    "        if part == 'dev':\n",
    "            part = 'val'\n",
    "        df_first_emp = pd.read_csv(os.path.join(path, \"FirstImpressionV2_text_\" + part + \".csv\")).dropna()\n",
    "        df_first_emp.columns=[\"NAME_VIDEO\", \"text\"]\n",
    "        df_first_emp.NAME_VIDEO = df_first_emp.NAME_VIDEO + \".mp4\"\n",
    "        df_first_emp_all = pd.read_csv(os.path.join(path, \"data_true_traits_fi.csv\"))\n",
    "        df_first_emp_all = df_first_emp_all[df_first_emp_all.Subset == ('val' if part == 'dev' else part)]\n",
    "        df = pd.merge(df_first_emp, df_first_emp_all, on='NAME_VIDEO', how='left').dropna()\n",
    "    else:\n",
    "        raise ValueError('Unknown part of train / dev / test')\n",
    "    return df.text.values, np.dstack((df.openness.to_numpy(), df.conscientiousness.to_numpy(), df.extraversion.to_numpy(), df.agreeableness.to_numpy(), df['non-neuroticism'].to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "74df8533-9d9f-46bf-b4ec-51fdf803756a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetEmotionPersonality(Dataset): \n",
    "    def __init__(self, dataset='CMU-MOSEI', part='train', path='data', path_to_emb=None, model='jina'): \n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        if dataset == 'CMU-MOSEI':\n",
    "            texts, labels = get_cmu_mosei_data(path, part)\n",
    "        elif dataset == 'FirstImpressionV2':\n",
    "            texts, labels = get_first_imp_data(path, part)\n",
    "        else:\n",
    "            raise ValueError('Unknown dataset (CMU-MOSEI / FirstImpressionV2)')\n",
    "        self.x = texts\n",
    "        self.y = labels[0]\n",
    "        if path_to_emb is None:\n",
    "            if model == 'jina':\n",
    "                self.feature_extractor_tokenizer = AutoTokenizer.from_pretrained(\"jinaai/jina-embeddings-v3\", code_revision='da863dd04a4e5dce6814c6625adfba87b83838aa', trust_remote_code=True)\n",
    "                self.feature_extractor_model = AutoModel.from_pretrained(\"jinaai/jina-embeddings-v3\", code_revision='da863dd04a4e5dce6814c6625adfba87b83838aa', trust_remote_code=True).to(self.device)\n",
    "            elif model == 'xlm-roberta-base':\n",
    "                self.feature_extractor_tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n",
    "                self.feature_extractor_model = AutoModel.from_pretrained('xlm-roberta-base').to(self.device)\n",
    "            elif model == 'bge-small':\n",
    "                self.feature_extractor_tokenizer = AutoTokenizer.from_pretrained(\"BAAI/bge-small-en-v1.5\")\n",
    "                self.feature_extractor_model = AutoModel.from_pretrained(\"BAAI/bge-small-en-v1.5\").to(self.device)\n",
    "            else:\n",
    "                raise ValueError('Unknown name of model')\n",
    "            self.text_embedding = []\n",
    "            for t in tqdm(texts):\n",
    "                encoded_input = self.feature_extractor_tokenizer(t, padding=True, truncation=True, return_tensors='pt').to(self.device)\n",
    "                with torch.no_grad():\n",
    "                    features = self.feature_extractor_model(**encoded_input)[0][0]\n",
    "                self.text_embedding.append(features)\n",
    "                \n",
    "        else:\n",
    "            with open(path_to_emb, 'rb') as file:\n",
    "                self.text_embedding = pickle.load(file)\n",
    "        self.n_samples = len(texts)        \n",
    "\n",
    "    def __getitem__(self, index): \n",
    "        return {\n",
    "            \"text\": self.x[index], \n",
    "            \"text_embedding\" : self.text_embedding[index],\n",
    "            \"label\" :self.y[index] \n",
    "        }\n",
    "        \n",
    "    def __len__(self): \n",
    "        return self.n_samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "16b0c62d-39c3-443a-bcc1-cd49e43c180f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch):\n",
    "    \"\"\"Собирает список образцов в единый батч, отбрасывая None (невалидные).\"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    batch = [x for x in batch if x is not None]\n",
    "    if not batch:\n",
    "        return None\n",
    "\n",
    "    text = [b[\"text\"] for b in batch]\n",
    "\n",
    "    labels = [b[\"label\"] for b in batch]\n",
    "    label_tensor = torch.tensor(labels, device=device)\n",
    "\n",
    "    text_embedding = [torch.tensor(b[\"text_embedding\"], device=device) for b in batch]\n",
    "    text_tensor = pad_sequence(text_embedding, batch_first=True)\n",
    "    text_tensor = text_tensor.to(device)\n",
    "\n",
    "    return {\n",
    "        \"text\": text,\n",
    "        \"text_embedding\": text_tensor.float(),\n",
    "        \"label\": label_tensor,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "16f508b7-1882-4e31-8cd6-2932fe246470",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4653/4653 [00:57<00:00, 80.88it/s]\n",
      "100%|██████████| 1991/1991 [00:23<00:00, 84.64it/s] \n"
     ]
    }
   ],
   "source": [
    "emotion_test_dataset = dataset=DatasetEmotionPersonality(dataset='CMU-MOSEI', part='test', model='bge-small')\n",
    "personality_test_dataset = dataset=DatasetEmotionPersonality(dataset='FirstImpressionV2', part='test', model='bge-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9219c031-3449-41df-b4c4-bb130d30f139",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "emotion_test_dataloader = DataLoader(dataset=emotion_test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=custom_collate_fn)\n",
    "personality_test_dataloader = DataLoader(dataset=personality_test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=custom_collate_fn)\n",
    "test_loaders = {'cmu_mosei' : emotion_test_dataloader, 'fiv2' : personality_test_dataloader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9d9ddb61-38f8-4dc1-a878-64a50410a80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.measures import uar, mf1, acc_func, ccc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "52c941f8-08e1-4591-bd2d-d61965d40fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_predictions(pred_emo, true_emo):\n",
    "    pred_emo = torch.nn.functional.softmax(pred_emo, dim=1).cpu().detach().numpy()\n",
    "    pred_emo = transform_matrix(pred_emo).tolist()\n",
    "    true_emo = true_emo.cpu().detach().numpy()\n",
    "    true_emo = np.where(true_emo > 0, 1, 0)[:, 1:].tolist()\n",
    "    return pred_emo, true_emo\n",
    "\n",
    "def run_emo_eval(model, loader, device=\"cuda\", mode = \"emotion\", disable_print=True):\n",
    "    \"\"\"\n",
    "    Оценка модели по задаче эмоций. Возвращает (uar, mf1).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_preds = []\n",
    "    total_targets = []\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, disable=disable_print):\n",
    "            if batch is None:\n",
    "                continue\n",
    "\n",
    "            labels = batch[\"label\"].to(device)      # shape: (B, 7)\n",
    "            text  = batch[\"text_embedding\"].to(device)      # shape: (B, D, F)\n",
    "            \n",
    "\n",
    "            if mode == \"emotion\":\n",
    "                logits = model(emotion_input=text)\n",
    "            elif mode == \"fusion\":\n",
    "                logits = model(emotion_input=text, personality_input=text)\n",
    "\n",
    "            bs = text.shape[0]\n",
    "            total += bs\n",
    "\n",
    "            preds, target =  process_predictions(logits['emotion_logits'], labels)\n",
    "            total_preds.extend(preds)\n",
    "            total_targets.extend(target)\n",
    "\n",
    "    uar_m = uar(total_targets, total_preds)\n",
    "    mf1_m = mf1(total_targets, total_preds)\n",
    "\n",
    "    return uar_m, mf1_m\n",
    "\n",
    "def run_per_eval(model, loader, device=\"cuda\", mode=\"personality\", disable_print=True):\n",
    "    \"\"\"\n",
    "    Оценка модели по задаче персональные качества личности. Возвращает (m_acc, m_ccc).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_preds = []\n",
    "    total_targets = []\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, disable=disable_print):\n",
    "            if batch is None:\n",
    "                continue\n",
    "\n",
    "            labels = batch[\"label\"].to(device)      # shape: (B, 7)\n",
    "            text  = batch[\"text_embedding\"].to(device)      # shape: (B, D, F)\n",
    "            if mode == \"personality\":\n",
    "                logits = model(personality_input=text)\n",
    "            elif mode == \"fusion\":\n",
    "                logits = model(emotion_input=text, personality_input=text)\n",
    "\n",
    "            bs = text.shape[0]\n",
    "            total += bs\n",
    "\n",
    "            preds = logits['personality_scores']\n",
    "            total_preds.extend(preds.detach().cpu().numpy())\n",
    "            total_targets.extend(labels.detach().cpu().numpy())\n",
    "\n",
    "    total_preds = np.array(total_preds)\n",
    "    total_targets = np.array(total_targets)\n",
    "\n",
    "    m_acc = acc_func(total_targets, total_preds)\n",
    "    m_ccc = ccc(total_targets, total_preds)\n",
    "\n",
    "    return m_acc, m_ccc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "911b220c-045f-44f2-bda7-0e7135c79aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 146/146 [00:02<00:00, 53.47it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6516559495186202, 0.6082743589709423)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_emo_eval(model, test_loaders['cmu_mosei'], device=\"cuda\", mode = \"fusion\", disable_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ab9456b9-8ca7-41b0-922d-e7a73bd33a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:01<00:00, 52.71it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8729764261853946, 0.33992263064351597)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_per_eval(model, test_loaders['fiv2'], device=\"cuda\", mode = \"fusion\", disable_print=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Google Colab Analog 2024 (PyTorch 2.5.1 + TensorFlow 2.18) [python-google_colab_gpu_2024]",
   "language": "python",
   "name": "conda-env-python-google_colab_gpu_2024-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
