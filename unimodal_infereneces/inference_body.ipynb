{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea8d5e05-042a-47ea-ac9d-731db6bcb373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from transformers import CLIPProcessor\n",
    "from models.models import EmotionMamba, PersonalityMamba, FusionTransformer\n",
    "from data_loading.feature_extractor import PretrainedImageEmbeddingExtractor\n",
    "from utils.config_loader import ConfigLoader\n",
    "\n",
    "def draw_box(image, box, color=(255, 0, 255)):\n",
    "    \"\"\"Draw a rectangle on the image.\"\"\"\n",
    "    line_width = 2\n",
    "    lw = line_width or max(round(sum(image.shape) / 2 * 0.003), 2)\n",
    "    p1, p2 = (int(box[0]), int(box[1])), (int(box[2]), int(box[3]))\n",
    "    cv2.rectangle(image, p1, p2, color, thickness=lw, lineType=cv2.LINE_AA)\n",
    "\n",
    "def image_processing(image, image_processor):\n",
    "    image = image_processor(images=image, return_tensors=\"pt\").to(\"cuda\")\n",
    "    image = image['pixel_values']\n",
    "    return image\n",
    "\n",
    "def preprocess_face(face_roi: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ–±–ª–∞—Å—Ç–∏ –ª–∏—Ü–∞ (–ø—Ä–∏–º–µ—Ä: –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è + resize).\"\"\"\n",
    "    # –ü—Ä–∏–º–µ—Ä: –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ 112x112 –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º [0, 1]\n",
    "    face_roi = cv2.resize(face_roi, (112, 112))\n",
    "    face_roi = face_roi.astype('float32') / 255.0\n",
    "    return face_roi\n",
    "\n",
    "def preprocess_body(body_roi: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ–±–ª–∞—Å—Ç–∏ —Ç–µ–ª–∞ (–ø—Ä–∏–º–µ—Ä: –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è + resize).\"\"\"\n",
    "    # –ü—Ä–∏–º–µ—Ä: –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ 224x224 –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º [0, 1]\n",
    "    body_roi = cv2.resize(body_roi, (224, 224))\n",
    "    body_roi = body_roi.astype('float32') / 255.0\n",
    "    return body_roi\n",
    "\n",
    "def select_uniform_frames(frames, N):\n",
    "    if len(frames) <= N:\n",
    "        return frames\n",
    "    else:\n",
    "        indices = np.linspace(0, len(frames) - 1, num=N, dtype=int)\n",
    "        return [frames[i] for i in indices]\n",
    "\n",
    "def get_fusion_model(config, device):\n",
    "    emo_model = EmotionMamba(\n",
    "    input_dim_emotion     = config.image_embedding_dim,\n",
    "    input_dim_personality = config.image_embedding_dim,\n",
    "    len_seq               = config.counter_need_frames, \n",
    "    hidden_dim            = config.hidden_dim_emo,\n",
    "    out_features          = config.out_features_emo,\n",
    "    tr_layer_number       = config.tr_layer_number_emo,\n",
    "    num_transformer_heads = config.num_transformer_heads_emo,\n",
    "    positional_encoding   = config.positional_encoding_emo,\n",
    "    mamba_d_model         = config.mamba_d_state_emo,\n",
    "    mamba_layer_number    = config.mamba_layer_number_emo,\n",
    "    dropout               = config.dropout,\n",
    "    num_emotions          = 7,\n",
    "    num_traits            = 5,\n",
    "    device                = device\n",
    "    ).to(device).eval()\n",
    "    # –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–¥–∞–µ–º –¥–ª—è –ª—É—á—à–µ–π –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏\n",
    "    per_model = PersonalityMamba(\n",
    "    input_dim_emotion     = config.image_embedding_dim,\n",
    "    input_dim_personality = config.image_embedding_dim,\n",
    "    len_seq               = config.counter_need_frames, \n",
    "    hidden_dim            = config.hidden_dim_per,\n",
    "    out_features          = config.out_features_per,\n",
    "    per_activation        = config.best_per_activation,\n",
    "    tr_layer_number       = config.tr_layer_number_per,\n",
    "    num_transformer_heads = config.num_transformer_heads_per,\n",
    "    positional_encoding   = config.positional_encoding_per,\n",
    "    mamba_d_model         = config.mamba_d_state_per,\n",
    "    mamba_layer_number    = config.mamba_layer_number_per,\n",
    "    dropout               = config.dropout,\n",
    "    num_emotions          = 7,\n",
    "    num_traits            = 5,\n",
    "    device                = device\n",
    "    ).to(device).eval()\n",
    "\n",
    "    # emo_state = torch.load(config.path_to_saved_emotion_model, map_location=device)\n",
    "    # emo_model.load_state_dict(emo_state)\n",
    "\n",
    "    # emo_state = torch.load(config.path_to_saved_personality_model, map_location=device)\n",
    "    # per_model.load_state_dict(emo_state)\n",
    "    model = FusionTransformer(\n",
    "        emo_model             = emo_model,\n",
    "        per_model             = per_model,\n",
    "        input_dim_emotion     = config.image_embedding_dim,\n",
    "        input_dim_personality = config.image_embedding_dim,\n",
    "        hidden_dim            = config.hidden_dim,\n",
    "        out_features          = config.out_features,\n",
    "        per_activation        = config.per_activation,\n",
    "        tr_layer_number       = config.tr_layer_number,\n",
    "        num_transformer_heads = config.num_transformer_heads,\n",
    "        positional_encoding   = config.positional_encoding,\n",
    "        mamba_d_model         = config.mamba_d_state,\n",
    "        mamba_layer_number    = config.mamba_layer_number,\n",
    "        dropout               = config.dropout,\n",
    "        num_emotions          = 7,\n",
    "        num_traits            = 5,\n",
    "        device                = device\n",
    "        ).to(device).eval()\n",
    "\n",
    "    return model\n",
    "\n",
    "def transform_matrix(matrix):\n",
    "    threshold1 = 1 - 1/7 \n",
    "    threshold2 = 1/7\n",
    "    mask1 = matrix[:, 0] >= threshold1\n",
    "    result = np.zeros_like(matrix[:, 1:])\n",
    "    transformed = (matrix[:, 1:] >= threshold2).astype(int)\n",
    "    result[~mask1] = transformed[~mask1]\n",
    "    return result\n",
    "\n",
    "def process_predictions(pred_emo):\n",
    "    pred_emo = torch.nn.functional.softmax(pred_emo, dim=1).cpu().detach().numpy()\n",
    "    pred_emo = transform_matrix(pred_emo).tolist()\n",
    "    return pred_emo\n",
    "\n",
    "def get_metadata(video_path: str, segment_length: int, image_processor: None, image_feature_extractor: None, device: None) -> pd.DataFrame:\n",
    "    \"\"\"–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: –ø–æ–ª—É—á–∞–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤–∏–¥–µ–æ.\"\"\"\n",
    "    if hasattr(body_detector.predictor, 'trackers'):\n",
    "        body_detector.predictor.trackers[0].reset()\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    video_name = os.path.basename(video_path)\n",
    "    w, h, fps, total_frames = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS, cv2.CAP_PROP_FRAME_COUNT))\n",
    "    need_frames = select_uniform_frames(list(range(total_frames)), segment_length)\n",
    "    \n",
    "    counter = 0\n",
    "    embeds = []\n",
    "\n",
    "    body_list = []\n",
    "    face_list = []\n",
    "    \n",
    "    while True:\n",
    "        ret, im0 = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if counter in need_frames:\n",
    "            # –î–µ—Ç–µ–∫—Ü–∏—è –≤—Å–µ—Ö –ª–∏—Ü\n",
    "            preprocessed_body = []\n",
    "            preprocessed_face = []\n",
    "            face_results = face_detector.process(cv2.cvtColor(im0, cv2.COLOR_BGR2RGB))\n",
    "            # –î–µ—Ç–µ–∫—Ü–∏—è –≤—Å–µ—Ö —Ç–µ–ª\n",
    "            body_results = body_detector.track(im0, persist=True, imgsz=640, conf=0.01, iou=0.5, \n",
    "                                             augment=False, device=0, verbose=False)\n",
    "\n",
    "            # –°–ª—É—á–∞–π 1: –ï—Å—Ç—å –ª–∏—Ü–∞ ‚Äî –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥–æ–µ\n",
    "            if face_results.detections:\n",
    "                for face_idx, detection in enumerate(face_results.detections):\n",
    "                    # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –ª–∏—Ü–∞\n",
    "                    bbox = detection.location_data.relative_bounding_box\n",
    "                    x1, y1 = max(int(bbox.xmin * w), 0), max(int(bbox.ymin * h), 0)\n",
    "                    x2, y2 = min(int((bbox.xmin + bbox.width) * w), w), min(int((bbox.ymin + bbox.height) * h), h)\n",
    "                    face_bbox = (x1, y1, x2, y2)\n",
    "                    face_center = ((x1 + x2) // 2, (y1 + y2) // 2)\n",
    "\n",
    "                    # –ò—â–µ–º —Ç–µ–ª–æ, —Å–æ–¥–µ—Ä–∂–∞—â–µ–µ —Ü–µ–Ω—Ç—Ä –ª–∏—Ü–∞\n",
    "                    body_bbox = None\n",
    "                    body_id = -1\n",
    "                    if body_results and len(body_results[0].boxes) > 0:\n",
    "                        for box in body_results[0].boxes:\n",
    "                            box_coords = box.xyxy.int().cpu().numpy()[0]\n",
    "                            if (box_coords[0] <= face_center[0] <= box_coords[2] and \n",
    "                                box_coords[1] <= face_center[1] <= box_coords[3]):\n",
    "                                body_bbox = box_coords\n",
    "                                body_id = box.id.int().cpu().item() if box.id else -1\n",
    "                                break\n",
    "\n",
    "                    # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞\n",
    "                    face_roi = im0[y1:y2, x1:x2]\n",
    "                    draw_box(im0, [x1, y1, x2, y2])\n",
    "                    draw_box(im0, [body_bbox[0], body_bbox[1], body_bbox[2], body_bbox[3]])\n",
    "                    preprocessed_face = image_processing(face_roi, image_processor) if face_roi.size > 0 else None\n",
    "                    \n",
    "                    if body_bbox is not None:\n",
    "                        body_roi = im0[body_bbox[1]:body_bbox[3], body_bbox[0]:body_bbox[2]]\n",
    "                        preprocessed_body = image_processing(body_roi, image_processor) if body_roi.size > 0 else None\n",
    "                    else:\n",
    "                        preprocessed_body = []\n",
    "\n",
    "                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
    "                    embeds.append([\n",
    "                        video_name, counter, body_id,\n",
    "                        x1, y1, x2, y2,\n",
    "                        body_bbox[0] if body_bbox is not None else None,\n",
    "                        body_bbox[1] if body_bbox is not None else None,\n",
    "                        body_bbox[2] if body_bbox is not None else None,\n",
    "                        body_bbox[3] if body_bbox is not None else None,\n",
    "                        # preprocessed_face,\n",
    "                        # preprocessed_body\n",
    "                    ])\n",
    "                    # print(preprocessed_body.shape)\n",
    "                    # print(preprocessed_face.shape)\n",
    "                    if preprocessed_body.shape[0] > 0:\n",
    "                        body_list.append(preprocessed_body)\n",
    "                    if preprocessed_face.shape[0] > 0:\n",
    "                        face_list.append(preprocessed_face)\n",
    "                    \n",
    "\n",
    "            # –°–ª—É—á–∞–π 2: –õ–∏—Ü –Ω–µ—Ç ‚Äî –±–µ—Ä—ë–º —Å–∞–º–æ–µ –±–æ–ª—å—à–æ–µ —Ç–µ–ª–æ\n",
    "            elif body_results and len(body_results[0].boxes) > 0:\n",
    "                largest_body = max(\n",
    "                    body_results[0].boxes,\n",
    "                    key=lambda box: (box.xyxy[0,2] - box.xyxy[0,0]) * (box.xyxy[0,3] - box.xyxy[0,1])\n",
    "                )\n",
    "                body_coords = largest_body.xyxy.int().cpu().numpy()[0]\n",
    "                body_id = largest_body.id.int().cpu().item() if largest_body.id else -1\n",
    "\n",
    "                # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–ª–∞\n",
    "                body_roi = im0[body_coords[1]:body_coords[3], body_coords[0]:body_coords[2]]\n",
    "                preprocessed_body = preprocess_body(body_roi) if body_roi.size > 0 else []\n",
    "\n",
    "                embeds.append([\n",
    "                    video_name, counter, body_id,\n",
    "                    None, None, None, None,  # –ù–µ—Ç –ª–∏—Ü–∞\n",
    "                    body_coords[0], body_coords[1], body_coords[2], body_coords[3],\n",
    "                    # None,  # –ù–µ—Ç –ª–∏—Ü–∞\n",
    "                    # preprocessed_body\n",
    "                ])\n",
    "\n",
    "                if preprocessed_body.shape[0] > 0:\n",
    "                    body_list.append(preprocessed_body)\n",
    "                if preprocessed_face.shape[0] > 0:\n",
    "                    face_list.append(preprocessed_face)\n",
    "\n",
    "            plt.imshow(cv2.cvtColor(im0, cv2.COLOR_BGR2RGB))\n",
    "            plt.show()\n",
    "\n",
    "        counter += 1\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    body_list = torch.cat(body_list, dim=0)\n",
    "    body_feature = image_feature_extractor.extract(body_list).to(device)\n",
    "\n",
    "    face_list = torch.cat(face_list, dim=0)\n",
    "    face_feature = image_feature_extractor.extract(face_list).to(device)\n",
    "    \n",
    "    df = pd.DataFrame(embeds, columns=[\n",
    "        \"video_name\", \"frame\", \"person_id\",\n",
    "        \"face_x1\", \"face_y1\", \"face_x2\", \"face_y2\",\n",
    "        \"body_x1\", \"body_y1\", \"body_x2\", \"body_y2\",\n",
    "        # \"preprocessed_face\", \"preprocessed_body\"\n",
    "    ])\n",
    "    return df, body_feature, face_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca879103-6ed9-4998-9d67-2261ff0c4e80",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for FusionTransformer:\n\tsize mismatch for emo_proj.0.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for emo_proj.0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for emo_proj.1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for emo_proj.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for per_proj.0.weight: copying a param with shape torch.Size([1024, 1024]) from checkpoint, the shape in current model is torch.Size([256, 1024]).\n\tsize mismatch for per_proj.0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for per_proj.1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for per_proj.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for emotion_to_personality_attn.0.self_attention.in_proj_weight: copying a param with shape torch.Size([3072, 1024]) from checkpoint, the shape in current model is torch.Size([768, 256]).\n\tsize mismatch for emotion_to_personality_attn.0.self_attention.in_proj_bias: copying a param with shape torch.Size([3072]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for emotion_to_personality_attn.0.self_attention.out_proj.weight: copying a param with shape torch.Size([1024, 1024]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for emotion_to_personality_attn.0.self_attention.out_proj.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for emotion_to_personality_attn.0.feed_forward.layer_1.weight: copying a param with shape torch.Size([1024, 1024]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for emotion_to_personality_attn.0.feed_forward.layer_1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for emotion_to_personality_attn.0.feed_forward.layer_2.weight: copying a param with shape torch.Size([1024, 1024]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for emotion_to_personality_attn.0.feed_forward.layer_2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for emotion_to_personality_attn.0.add_norm_after_attention.norm.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for emotion_to_personality_attn.0.add_norm_after_attention.norm.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for emotion_to_personality_attn.0.add_norm_after_ff.norm.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for emotion_to_personality_attn.0.add_norm_after_ff.norm.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for emotion_to_personality_attn.0.positional_encoding.pe: copying a param with shape torch.Size([5000, 1024]) from checkpoint, the shape in current model is torch.Size([5000, 256]).\n\tsize mismatch for personality_to_emotion_attn.0.self_attention.in_proj_weight: copying a param with shape torch.Size([3072, 1024]) from checkpoint, the shape in current model is torch.Size([768, 256]).\n\tsize mismatch for personality_to_emotion_attn.0.self_attention.in_proj_bias: copying a param with shape torch.Size([3072]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for personality_to_emotion_attn.0.self_attention.out_proj.weight: copying a param with shape torch.Size([1024, 1024]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for personality_to_emotion_attn.0.self_attention.out_proj.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for personality_to_emotion_attn.0.feed_forward.layer_1.weight: copying a param with shape torch.Size([1024, 1024]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for personality_to_emotion_attn.0.feed_forward.layer_1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for personality_to_emotion_attn.0.feed_forward.layer_2.weight: copying a param with shape torch.Size([1024, 1024]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for personality_to_emotion_attn.0.feed_forward.layer_2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for personality_to_emotion_attn.0.add_norm_after_attention.norm.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for personality_to_emotion_attn.0.add_norm_after_attention.norm.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for personality_to_emotion_attn.0.add_norm_after_ff.norm.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for personality_to_emotion_attn.0.add_norm_after_ff.norm.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for personality_to_emotion_attn.0.positional_encoding.pe: copying a param with shape torch.Size([5000, 1024]) from checkpoint, the shape in current model is torch.Size([5000, 256]).\n\tsize mismatch for emotion_personality_fc_out.0.weight: copying a param with shape torch.Size([128, 2048]) from checkpoint, the shape in current model is torch.Size([128, 512]).\n\tsize mismatch for personality_emotion_fc_out.0.weight: copying a param with shape torch.Size([128, 2048]) from checkpoint, the shape in current model is torch.Size([128, 512]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m config_face \u001b[38;5;241m=\u001b[39m ConfigLoader(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minference_config_face.toml\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# image_feature_extractor = PretrainedImageEmbeddingExtractor(config_body)\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m image_feature_extractor \u001b[38;5;241m=\u001b[39m \u001b[43mPretrainedImageEmbeddingExtractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Models can download from https://drive.google.com/drive/folders/1APMtC4LXjuW9behd2TxVXz0DsjQKAgRR?usp=sharing\u001b[39;00m\n\u001b[0;32m     11\u001b[0m body_model \u001b[38;5;241m=\u001b[39m get_fusion_model(config_body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\Prgrm\\EAAI_2025\\data_loading\\feature_extractor.py:16\u001b[0m, in \u001b[0;36mPretrainedImageEmbeddingExtractor.__init__\u001b[1;34m(self, device, clip_name)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m device\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessor \u001b[38;5;241m=\u001b[39m CLIPProcessor\u001b[38;5;241m.\u001b[39mfrom_pretrained(clip_name)\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbody_model \u001b[38;5;241m=\u001b[39m \u001b[43mget_fusion_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbody\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mface_model \u001b[38;5;241m=\u001b[39m get_fusion_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mface\u001b[39m\u001b[38;5;124m\"\u001b[39m, device)\n",
      "File \u001b[1;32mC:\\Prgrm\\EAAI_2025\\utils\\body\\model_loader.py:103\u001b[0m, in \u001b[0;36mget_fusion_model\u001b[1;34m(modality, device)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# ‚Üê‚Äì‚Äì‚Äì –∑–∞–≥—Ä—É–∂–∞–µ–º –∂—ë—Å—Ç–∫–æ –∑–∞–¥–∞–Ω–Ω—ã–π checkpoint ‚Äì‚Äì‚Äì‚Üí\u001b[39;00m\n\u001b[0;32m    102\u001b[0m state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(meta[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mckpt\u001b[39m\u001b[38;5;124m\"\u001b[39m], map_location\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m--> 103\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m        \u001b[38;5;66;03m# strict=True\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Prgrm\\EAAI_2025\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2581\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2573\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2574\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   2575\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2576\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[0;32m   2577\u001b[0m             ),\n\u001b[0;32m   2578\u001b[0m         )\n\u001b[0;32m   2580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2581\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   2582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2583\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[0;32m   2584\u001b[0m         )\n\u001b[0;32m   2585\u001b[0m     )\n\u001b[0;32m   2586\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for FusionTransformer:\n\tsize mismatch for emo_proj.0.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for emo_proj.0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for emo_proj.1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for emo_proj.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for per_proj.0.weight: copying a param with shape torch.Size([1024, 1024]) from checkpoint, the shape in current model is torch.Size([256, 1024]).\n\tsize mismatch for per_proj.0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for per_proj.1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for per_proj.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for emotion_to_personality_attn.0.self_attention.in_proj_weight: copying a param with shape torch.Size([3072, 1024]) from checkpoint, the shape in current model is torch.Size([768, 256]).\n\tsize mismatch for emotion_to_personality_attn.0.self_attention.in_proj_bias: copying a param with shape torch.Size([3072]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for emotion_to_personality_attn.0.self_attention.out_proj.weight: copying a param with shape torch.Size([1024, 1024]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for emotion_to_personality_attn.0.self_attention.out_proj.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for emotion_to_personality_attn.0.feed_forward.layer_1.weight: copying a param with shape torch.Size([1024, 1024]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for emotion_to_personality_attn.0.feed_forward.layer_1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for emotion_to_personality_attn.0.feed_forward.layer_2.weight: copying a param with shape torch.Size([1024, 1024]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for emotion_to_personality_attn.0.feed_forward.layer_2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for emotion_to_personality_attn.0.add_norm_after_attention.norm.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for emotion_to_personality_attn.0.add_norm_after_attention.norm.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for emotion_to_personality_attn.0.add_norm_after_ff.norm.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for emotion_to_personality_attn.0.add_norm_after_ff.norm.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for emotion_to_personality_attn.0.positional_encoding.pe: copying a param with shape torch.Size([5000, 1024]) from checkpoint, the shape in current model is torch.Size([5000, 256]).\n\tsize mismatch for personality_to_emotion_attn.0.self_attention.in_proj_weight: copying a param with shape torch.Size([3072, 1024]) from checkpoint, the shape in current model is torch.Size([768, 256]).\n\tsize mismatch for personality_to_emotion_attn.0.self_attention.in_proj_bias: copying a param with shape torch.Size([3072]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for personality_to_emotion_attn.0.self_attention.out_proj.weight: copying a param with shape torch.Size([1024, 1024]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for personality_to_emotion_attn.0.self_attention.out_proj.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for personality_to_emotion_attn.0.feed_forward.layer_1.weight: copying a param with shape torch.Size([1024, 1024]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for personality_to_emotion_attn.0.feed_forward.layer_1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for personality_to_emotion_attn.0.feed_forward.layer_2.weight: copying a param with shape torch.Size([1024, 1024]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for personality_to_emotion_attn.0.feed_forward.layer_2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for personality_to_emotion_attn.0.add_norm_after_attention.norm.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for personality_to_emotion_attn.0.add_norm_after_attention.norm.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for personality_to_emotion_attn.0.add_norm_after_ff.norm.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for personality_to_emotion_attn.0.add_norm_after_ff.norm.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for personality_to_emotion_attn.0.positional_encoding.pe: copying a param with shape torch.Size([5000, 1024]) from checkpoint, the shape in current model is torch.Size([5000, 256]).\n\tsize mismatch for emotion_personality_fc_out.0.weight: copying a param with shape torch.Size([128, 2048]) from checkpoint, the shape in current model is torch.Size([128, 512]).\n\tsize mismatch for personality_emotion_fc_out.0.weight: copying a param with shape torch.Size([128, 2048]) from checkpoint, the shape in current model is torch.Size([128, 512])."
     ]
    }
   ],
   "source": [
    "mp_face_detection = mp.solutions.face_detection\n",
    "face_detector = mp_face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.6)\n",
    "body_detector = YOLO('extractors/body/best.pt')\n",
    "image_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "config_body = ConfigLoader(\"inference_config_body.toml\")\n",
    "config_face = ConfigLoader(\"inference_config_face.toml\")\n",
    "# image_feature_extractor = PretrainedImageEmbeddingExtractor(config_body)\n",
    "image_feature_extractor = PretrainedImageEmbeddingExtractor(device=\"cuda\")\n",
    "# Models can download from https://drive.google.com/drive/folders/1APMtC4LXjuW9behd2TxVXz0DsjQKAgRR?usp=sharing\n",
    "\n",
    "body_model = get_fusion_model(config_body, 'cuda')\n",
    "face_model = get_fusion_model(config_face, 'cuda')\n",
    "# results_clip_body_true_mamba_fusiontransformer_2025-06-27_16-10-57/metrics_by_epoch/metrics_epochlog_FusionTransformer_num_transformer_heads_16_20250627_183039_timestamp/best_model_dev.pt\n",
    "body_fusion_model_path = 'extractors/body/clip_body_mamba_transformer_fusion_model.pt'\n",
    "# results_fusiontransformer_2025-07-03_09-41-13/metrics_by_epoch/metrics_epochlog_FusionTransformer_tr_layer_number_3_20250703_124848_timestamp/best_model_dev.pt\n",
    "face_fusion_model_path = 'extractors/face/clip_face_mamba_transformer_fusion_model.pt'\n",
    "\n",
    "body_state = torch.load(body_fusion_model_path, map_location='cuda')\n",
    "body_model.load_state_dict(body_state)\n",
    "\n",
    "face_state = torch.load(face_fusion_model_path, map_location='cuda')\n",
    "face_model.load_state_dict(face_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68ac5f2-8c4a-4f4e-b95c-209089183698",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bfabde07-afb4-4f68-9c28-4ba802d5921f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç –ü–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç:\n",
      "{'sample_name': '-6rXp3zJ3kc_14.4680_22.8820', 'video_path': 'E:/CMU-MOSEI//video/test/-6rXp3zJ3kc_14.4680_22.8820.mp4', 'audio_path': 'E:/CMU-MOSEI//audio/test/-6rXp3zJ3kc_14.4680_22.8820.wav', 'features': {'body': {'emotion_logits': tensor([ 0.4595,  1.5333, -0.9546,  0.3222, -0.7833,  1.2438, -0.9155]), 'personality_scores': tensor([0.3668, 0.6629, 0.3182, 0.5780, 0.5149]), 'last_emo_encoder_features': tensor([ 1.6797,  1.1995,  0.0361,  ...,  1.3864,  5.1510, -0.0212]), 'last_per_encoder_features': tensor([-0.1187,  3.0620, -1.4489,  ..., -0.2055, -0.5260,  0.7611])}, 'face': {'emotion_logits': tensor([ 0.6361,  1.7097, -0.3265, -0.9575, -1.2868,  0.9896, -0.9342]), 'personality_scores': tensor([0.4642, 0.6192, 0.3096, 0.5205, 0.4690]), 'last_emo_encoder_features': tensor([-8.2230e+00, -6.9223e+00, -5.7896e+00, -3.3821e+00, -3.7589e+00,\n",
      "         2.9955e+00,  3.7664e+00,  1.5413e+00, -1.1885e-01,  6.8728e-01,\n",
      "        -2.7760e+00, -4.4210e+00,  2.4823e+00,  3.9500e+00,  2.7767e+00,\n",
      "         2.2599e+00,  6.4001e+00,  4.4730e+00, -1.3443e+00, -2.7031e+00,\n",
      "         2.0057e+00, -4.8556e+00, -2.8505e+00, -1.9169e+00, -3.1854e+00,\n",
      "        -5.5063e+00, -4.2218e+00,  3.9150e+00, -1.7913e+00, -4.4975e+00,\n",
      "         8.2613e+00, -3.4638e+00,  1.6140e+00, -6.0594e+00, -8.1935e+00,\n",
      "        -1.0164e-01,  9.1869e-01,  1.6131e+00,  8.4634e-01,  2.2539e+00,\n",
      "         3.3320e+00, -8.5332e-01,  8.1516e-01, -3.0834e-02, -3.8450e+00,\n",
      "        -1.2430e+00, -2.4587e+00,  2.1414e+00, -3.6509e-01, -1.2770e+00,\n",
      "        -2.8965e+00, -7.0327e+00,  4.1330e-01, -2.6275e+00,  9.6468e-01,\n",
      "         6.3285e-01, -2.2495e+00,  3.2848e+00,  4.6593e+00,  1.6630e+00,\n",
      "         2.8398e+00,  3.1506e+00,  3.3379e+00,  4.5112e+00, -2.4032e+00,\n",
      "        -6.9692e-01,  7.6390e+00,  3.9145e+00,  1.7551e+00,  5.0412e-01,\n",
      "         3.8861e+00,  7.0959e-01, -6.1046e+00,  8.3063e-02, -2.3711e+00,\n",
      "        -8.8101e+00,  4.8471e+00, -7.1430e+00, -5.4627e+00,  5.2093e+00,\n",
      "        -4.6960e+00, -4.4088e+00, -7.7346e-01, -5.7917e+00, -3.2479e+00,\n",
      "         1.9602e+00,  6.1130e+00,  3.5822e+00, -1.8639e+00,  3.0398e-01,\n",
      "         5.0134e+00, -7.7534e-01, -3.2203e-01, -4.7398e+00, -5.3993e+00,\n",
      "        -3.3205e+00,  2.3089e+00,  2.6681e+00, -1.3856e+00,  1.6674e+00,\n",
      "        -9.4366e-01,  1.0224e+00, -2.5366e-01, -1.0956e+00, -2.5524e-03,\n",
      "        -2.3988e+00, -1.4950e+00, -3.7093e+00, -1.0811e+00, -2.3931e+00,\n",
      "        -2.0864e+00, -2.4135e+00, -5.5368e-01, -8.0471e-02,  4.6487e+00,\n",
      "         1.3678e+00,  7.7976e-01,  9.8927e-01, -1.0328e+00, -1.6091e+00,\n",
      "        -3.9836e+00, -9.4524e-01,  2.9006e+00, -2.1330e+00, -1.2851e+00,\n",
      "        -2.6698e+00, -6.2792e+00,  4.1980e+00,  2.4782e+00,  3.8517e+00,\n",
      "        -1.5659e+00,  3.0305e+00,  1.6429e+00,  2.8950e+00,  5.4329e+00,\n",
      "        -5.4138e-01,  5.6006e-01, -3.7967e+00, -4.9832e-02,  3.6089e+00,\n",
      "        -2.5060e+00, -3.0748e-01,  2.9736e+00, -4.2760e-01, -5.5670e+00,\n",
      "        -1.4583e+00,  3.9547e+00,  1.8745e+00, -2.4937e+00, -4.5061e+00,\n",
      "         7.1186e-01,  1.2927e+00,  1.2588e+00, -3.3954e+00,  2.0785e-01,\n",
      "        -5.9976e+00,  2.5679e+00, -2.1499e+00, -9.0661e+00, -6.7806e-01,\n",
      "         2.8380e+00, -1.9499e+00, -1.8708e+00,  3.8926e-01, -6.8401e+00,\n",
      "         2.5549e+00, -1.3256e+00, -1.1856e+00, -5.8949e+00,  6.7677e+00,\n",
      "        -2.3680e+00,  5.5643e-02,  4.7482e+00, -3.3046e+00,  3.3528e+00,\n",
      "         5.5654e+00, -2.7584e+00,  1.1931e+00, -2.2151e+00,  2.5569e+00,\n",
      "         3.1064e+00, -5.0153e-01, -6.3089e+00, -9.4190e-02, -1.2811e+00,\n",
      "         1.0611e+00,  2.9882e+00,  7.8081e+00,  4.4540e+00,  2.0978e+00,\n",
      "        -3.1566e+00,  4.7358e-01,  2.5205e+00, -2.4982e+00, -1.2211e+00,\n",
      "         1.0048e+00,  1.8879e+00, -7.6357e+00,  7.4511e+00,  9.3876e-01,\n",
      "        -7.5215e-01, -1.6824e+00,  2.7095e+00, -1.3934e+00, -5.8884e+00,\n",
      "        -7.5591e-01,  7.3867e-01, -6.6348e+00, -5.1034e+00, -5.5617e-01,\n",
      "         1.4414e+00, -2.9867e-01, -1.5052e+00, -5.5971e+00, -9.7235e+00,\n",
      "         2.0925e+00, -3.4975e+00,  2.0486e+00,  2.8045e-01, -1.2995e+00,\n",
      "        -4.3494e-01,  4.4868e-01, -4.7383e+00, -4.5860e+00, -6.6773e+00,\n",
      "         9.3402e-01, -3.3955e+00, -4.1155e+00, -1.1057e+00, -3.5150e+00,\n",
      "        -1.4785e+00,  7.1319e+00, -4.2114e+00,  2.2300e+00,  2.0169e+00,\n",
      "         6.4295e+00,  6.1487e-01, -3.5167e+00,  1.0974e+00,  3.8238e+00,\n",
      "         1.7027e-01,  3.6279e-02,  4.6143e+00, -2.5862e+00,  6.0949e-01,\n",
      "         5.9581e+00, -3.6620e+00, -3.2413e+00, -6.0385e+00,  3.5595e+00,\n",
      "        -1.3551e-01,  5.6899e-01,  3.4073e+00,  1.1798e+00,  2.2692e+00,\n",
      "         2.6881e+00,  2.6486e+00,  1.7158e+00, -2.5973e+00, -1.6380e+00,\n",
      "        -3.0164e+00,  4.9023e-02, -2.0941e+00,  7.0048e+00, -4.2084e+00,\n",
      "        -5.9765e+00, -5.3780e-01, -6.2532e+00, -6.2134e-02, -3.1948e+00,\n",
      "        -5.3641e+00, -1.2445e-01,  9.5685e-01,  3.4994e-01,  1.7162e+00,\n",
      "         3.9847e+00, -6.2725e-01,  2.3030e+00, -9.6583e-02, -9.6818e-01,\n",
      "        -5.3083e+00,  1.2905e+00, -2.6743e+00, -2.4229e+00,  2.0376e+00,\n",
      "        -3.1894e+00, -6.2834e+00,  2.1044e-03,  1.1365e+00, -6.1925e+00,\n",
      "         5.5213e-01,  6.3934e-01,  4.5598e+00,  8.0125e+00,  1.9740e+00,\n",
      "        -3.0094e+00,  2.0265e+00,  5.0624e+00, -1.6511e+00,  1.3980e+00,\n",
      "        -1.5678e+00,  3.4822e+00, -3.7313e+00,  6.3424e+00,  2.6572e+00,\n",
      "        -5.6988e+00,  1.6478e-01,  5.8050e-01,  4.5561e+00,  3.4308e+00,\n",
      "        -1.9348e+00,  6.4955e+00,  1.9993e+00,  3.4664e+00,  1.1618e+00,\n",
      "         2.0522e+00,  2.2624e+00,  4.1647e+00, -3.8520e+00,  6.3257e+00,\n",
      "        -3.3091e-01,  2.3852e+00,  7.0001e-02, -4.2246e+00, -9.2681e+00,\n",
      "        -1.7196e-01, -8.3950e-01, -1.0774e+00,  1.7218e+00, -1.1135e+00,\n",
      "        -2.5927e+00,  4.4034e+00,  7.4703e-01, -1.0076e-01, -1.8658e+00,\n",
      "         1.5608e+00,  7.4284e+00,  8.0560e+00, -6.7068e-01,  4.6330e+00,\n",
      "        -2.8679e+00,  9.7087e-01, -1.2751e+00, -2.6933e-02, -7.6210e+00,\n",
      "        -3.1978e+00, -5.7582e+00, -8.8414e+00, -2.3240e+00, -8.3657e-01,\n",
      "        -3.7112e+00,  2.3510e+00, -3.4441e+00, -1.4957e+00,  1.8680e+00,\n",
      "        -6.4914e-01,  5.2631e+00,  1.4055e+00,  1.4343e+00,  6.2031e+00,\n",
      "         3.2263e-01,  7.1986e-01, -3.3497e+00,  5.2781e+00, -2.0148e+00,\n",
      "         9.2892e-01,  1.8375e+00,  4.1965e+00,  2.4361e+00, -3.8927e+00,\n",
      "        -1.6976e+00, -4.0349e+00, -1.1983e+00, -1.6589e+00, -5.9584e+00,\n",
      "         2.2770e-02, -6.2872e-02,  1.0817e+00, -3.5063e+00,  3.0854e-01,\n",
      "         1.0663e-01, -8.5329e-02, -2.8056e+00,  1.9624e+00,  9.1626e+00,\n",
      "         5.3828e+00,  2.4524e+00,  6.2560e+00, -6.0847e+00,  2.6875e+00,\n",
      "        -1.8888e+00,  2.6180e+00, -1.0192e+00,  1.8928e+00,  6.1438e+00,\n",
      "         1.1989e+00, -1.4508e+00,  2.8505e+00,  3.9434e+00,  8.1090e-01,\n",
      "         3.0524e+00,  4.1107e+00,  1.9565e+00,  6.6892e-01, -5.8196e+00,\n",
      "        -5.4994e-01, -3.0158e+00,  4.3137e-02, -1.9308e+00,  2.5785e+00,\n",
      "        -5.5248e-01, -1.5829e-01,  6.0883e-01, -3.6279e+00,  2.9361e+00,\n",
      "         2.8819e+00,  1.8848e+00, -1.8269e+00,  4.4456e+00,  1.4964e+00,\n",
      "         2.3559e+00,  2.8386e+00, -1.1184e+00,  6.9954e-01, -5.3147e+00,\n",
      "        -2.0223e-01, -6.5192e+00, -2.9826e-03, -6.1818e+00, -1.0043e+00,\n",
      "        -1.8644e+00,  1.1995e+00, -1.5130e+00,  2.9251e+00,  6.8909e-01,\n",
      "        -3.3229e-01,  2.0579e+00, -1.9918e+00, -6.3983e+00,  1.5820e+00,\n",
      "        -1.8549e+00,  5.1048e+00,  6.5702e-01,  3.8572e-01,  1.0853e+01,\n",
      "         4.2606e+00,  7.0870e+00,  7.2006e-01,  5.0863e+00, -3.6083e+00,\n",
      "        -4.3109e+00, -2.9254e+00,  7.9206e-02, -6.5374e+00,  8.2698e+00,\n",
      "         8.3765e+00,  3.1523e+00,  4.3179e+00, -6.9291e+00, -5.7146e-01,\n",
      "         4.1675e-01,  8.5232e-01, -7.1066e+00,  6.6067e+00,  5.4377e+00,\n",
      "         9.4504e-01,  2.5154e+00, -4.8530e+00, -6.5161e+00,  8.0458e+00,\n",
      "         1.3343e+00,  7.0417e+00, -5.2461e-01, -7.5717e-01, -3.0376e+00,\n",
      "        -6.4579e+00,  4.6384e+00, -3.2064e-01,  6.8399e+00,  5.4367e+00,\n",
      "         4.1278e+00,  7.6766e-01, -2.1928e-01,  8.0883e+00, -3.2628e+00,\n",
      "         1.4437e-01,  4.0816e+00,  3.9095e+00,  1.7602e+00, -1.4343e+00,\n",
      "        -1.6665e+00, -8.4307e-03, -2.7171e+00, -9.3143e-01, -1.2625e+00,\n",
      "         4.6817e+00, -6.5978e-01,  6.3072e+00,  5.1893e+00,  9.2511e-01,\n",
      "         5.7323e-01, -2.9279e+00, -2.0089e+00,  2.4654e+00, -1.7888e+00,\n",
      "         2.5497e+00,  2.8937e+00,  4.3658e+00, -2.9963e+00, -1.8934e+00,\n",
      "        -4.1100e-01,  6.4432e-01]), 'last_per_encoder_features': tensor([-1.1956e+00, -1.4257e-01, -1.4800e+00, -1.0203e+00,  6.1449e-01,\n",
      "         1.4512e+00,  2.5570e+00, -1.9612e+00, -8.3595e-01,  1.2635e+00,\n",
      "        -6.7601e-03, -1.8668e+00,  1.0171e+00,  8.9388e-01,  3.3275e+00,\n",
      "         1.4547e+00,  6.3957e-02, -2.2506e+00,  5.1887e+00,  7.2922e+00,\n",
      "         8.2894e-01,  2.9701e+00,  2.3753e+00, -2.0052e+00, -3.9808e+00,\n",
      "        -3.4508e+00,  4.1967e+00, -2.4241e+00,  1.6925e+00, -1.7567e+00,\n",
      "         5.1017e+00, -3.2309e+00, -2.0472e+00,  5.3050e+00,  2.2768e+00,\n",
      "         2.0056e-01,  2.7105e+00, -8.6809e-01,  4.8544e-01, -1.0089e+00,\n",
      "        -8.0589e-02, -2.2238e+00, -2.2309e+00,  1.5864e+00, -5.0825e-01,\n",
      "        -1.2272e+00,  3.4127e-02,  1.0247e-01, -4.6980e+00,  2.4505e+00,\n",
      "         1.4319e+00, -3.1828e+00,  2.2441e+00, -1.8705e+00, -6.9859e-01,\n",
      "         7.7636e-01,  3.3317e+00,  8.1688e-01,  2.2520e+00, -2.7532e+00,\n",
      "        -4.3729e+00,  7.7408e+00, -2.4143e+00, -1.7663e+00,  4.6938e+00,\n",
      "         1.2273e+00,  8.8919e-01,  1.1716e+00, -1.7520e+00, -3.1161e+00,\n",
      "        -4.1274e+00,  4.2425e+00,  1.3422e+00,  7.5631e+00, -2.3085e+00,\n",
      "         3.2478e+00, -5.6842e+00, -4.8356e-01, -7.7743e-01,  2.1669e+00,\n",
      "         1.1606e+00, -1.3926e+00, -3.3021e-01, -6.5281e-01,  2.4478e+00,\n",
      "         3.1388e+00,  1.2902e+00,  1.2050e+00,  2.6362e+00,  2.7109e+00,\n",
      "         1.5126e+00, -1.6687e-01, -4.7609e-01,  5.1137e+00, -4.6336e+00,\n",
      "        -6.1363e-01, -1.1604e-01, -1.6072e+00, -4.3464e+00,  6.4762e-01,\n",
      "         1.1588e-01,  2.2450e-01, -8.6734e-01, -9.1110e-01, -2.2721e+00,\n",
      "        -1.1587e+00, -6.2232e-01,  7.5925e-01,  2.1445e+00, -2.9712e+00,\n",
      "         4.1312e+00, -7.3622e-01, -3.4427e+00, -1.6633e+00,  3.1826e+00,\n",
      "        -6.9155e-01,  1.3750e+00, -3.2018e+00,  1.6784e+00,  9.4154e-01,\n",
      "        -8.0728e-01, -4.5005e+00, -4.1519e+00,  1.2112e+00, -1.1257e+00,\n",
      "        -2.9794e+00,  2.9857e+00,  8.5248e-01,  2.2703e+00, -2.9965e+00,\n",
      "        -1.0371e+00,  4.5198e+00,  8.4541e-01,  2.9599e+00,  1.2485e+00,\n",
      "        -2.5343e+00,  7.1509e+00, -3.8614e-01, -3.1841e+00,  2.5762e+00,\n",
      "         5.0922e-01,  5.3787e-01, -4.7055e-01,  1.4044e+00,  5.0434e-01,\n",
      "         3.1450e+00,  2.7750e+00,  1.5062e-01,  2.9778e-01, -2.1670e-01,\n",
      "         3.1531e+00,  3.1851e+00,  4.5128e-01, -3.7008e+00, -1.4875e+00,\n",
      "        -3.0960e+00,  3.4612e+00,  2.9452e+00, -1.1490e+00, -2.7636e+00,\n",
      "        -2.2861e+00,  1.6817e+00, -3.7541e+00,  5.3285e+00,  4.3442e+00,\n",
      "         1.3789e+00, -5.4005e-01,  1.5185e+00, -1.0920e+00,  7.2181e-01,\n",
      "         2.2241e+00, -2.0053e+00, -9.0704e-01, -2.3622e+00, -5.9643e+00,\n",
      "         4.2818e+00, -1.8112e+00,  1.1493e+00, -3.9741e-01, -6.4411e-01,\n",
      "        -1.8526e+00, -1.2493e+00, -5.5603e+00, -1.5978e+00,  1.4695e-01,\n",
      "        -4.9023e+00, -6.1502e+00,  2.2660e+00,  4.8033e-01, -1.4105e+00,\n",
      "         1.0854e+00,  1.7496e-01,  1.9329e+00,  7.8413e-01, -3.6434e+00,\n",
      "         2.4942e+00,  5.0837e+00, -1.0060e+00, -4.1455e-01, -1.3801e+00,\n",
      "         1.3972e+00,  1.3569e-01, -2.1337e-01,  4.3847e-01, -5.4291e-01,\n",
      "         2.3687e+00, -4.8644e+00,  1.1332e+00, -9.5954e-01,  1.6698e-01,\n",
      "         3.3734e+00,  3.5599e+00, -3.0967e+00,  2.4895e+00,  1.8307e-01,\n",
      "         2.3437e+00, -1.6860e+00, -7.4562e-01,  4.1024e+00,  1.3354e+00,\n",
      "        -4.3255e+00, -4.0565e-02,  1.3429e+00, -3.6988e+00,  4.1463e+00,\n",
      "        -3.8066e+00, -5.5523e+00,  1.1830e+00, -3.4526e-01, -4.3035e+00,\n",
      "        -3.1081e+00, -1.9549e+00,  5.2116e-02, -2.4909e+00,  3.6313e+00,\n",
      "         3.7308e+00, -1.1656e+00,  2.7124e+00,  2.8690e+00, -3.7376e+00,\n",
      "         1.6889e+00,  1.5041e+00,  1.1491e+00,  5.2397e+00,  4.2034e-01,\n",
      "         5.3707e-01,  3.2612e+00, -3.0864e+00, -3.5407e+00,  2.2537e+00,\n",
      "         1.8376e+00,  5.2764e+00,  3.7649e-01,  1.4560e+00,  9.8268e-01,\n",
      "        -5.1011e+00,  5.9703e-01,  4.1511e+00,  1.6714e+00, -6.3416e+00,\n",
      "        -4.4849e+00, -1.9616e+00, -8.7672e+00, -2.0786e+00, -4.9608e+00,\n",
      "         4.0571e+00,  1.8596e+00,  3.4207e-02, -5.0172e+00,  1.4763e+00,\n",
      "         3.2753e+00,  2.0708e+00, -2.2833e+00,  6.5065e-01, -8.9259e-01,\n",
      "         6.1852e-01, -7.1792e+00,  9.2044e-01,  5.6267e-01, -4.6747e-01,\n",
      "         2.0115e+00, -2.1248e+00, -3.7582e-01,  8.7119e-01, -4.9023e+00,\n",
      "        -8.1783e-01, -2.2953e+00, -8.9224e-01, -3.7232e+00,  5.6078e+00,\n",
      "         2.1440e+00, -2.3636e+00, -1.0670e+00, -6.5007e+00, -3.1750e+00,\n",
      "        -2.7770e+00,  1.2156e+00, -2.8212e+00,  3.0820e+00,  2.1906e+00,\n",
      "         5.3644e-01,  4.0787e+00, -1.5636e+00,  1.4104e+00, -5.8426e+00,\n",
      "         4.5281e+00,  2.5768e-01, -5.3646e-01, -2.9252e-01,  1.0354e+01,\n",
      "         3.0106e+00, -7.3969e-01, -4.3983e+00, -2.3761e-01, -4.1746e+00,\n",
      "        -2.1513e+00,  2.7986e+00,  4.4146e+00, -3.1968e+00,  5.6137e+00,\n",
      "        -2.5926e+00, -1.4483e+00,  2.9632e+00, -9.5199e-01, -3.5649e+00,\n",
      "        -9.1007e-01,  5.8761e-01,  2.9677e+00,  2.1091e+00, -9.6730e-01,\n",
      "        -1.1950e+00,  4.2964e+00,  8.8464e-01, -5.6999e-01, -8.4325e-01,\n",
      "        -2.4963e-01, -3.9704e+00,  4.7755e+00,  6.7932e-01, -1.9336e-01,\n",
      "         8.6468e-01,  4.5822e+00, -4.6049e+00, -2.9996e+00,  3.7518e+00,\n",
      "        -4.9539e+00,  4.5371e+00, -1.8402e+00,  1.2579e-01, -7.8131e-01,\n",
      "         9.9778e-01,  2.1694e+00,  3.3439e-01, -4.8620e+00,  8.2149e-01,\n",
      "        -1.1994e+00, -2.2537e+00,  3.5201e+00,  2.2295e+00, -2.5026e+00,\n",
      "        -1.7625e+00, -2.2471e+00, -2.9352e+00,  2.9395e+00,  1.4159e+00,\n",
      "         1.7875e+00, -3.8404e+00, -2.4462e+00, -3.1560e+00, -2.6114e+00,\n",
      "         2.9903e+00,  1.0480e+00,  6.9566e-01,  3.4284e-01, -1.6339e-01,\n",
      "         5.3163e+00,  5.0338e-03, -2.9113e+00,  1.0665e+00, -1.5730e+00,\n",
      "         2.5091e+00, -2.2708e+00,  3.2762e+00, -4.0386e+00, -6.6649e-01,\n",
      "         1.1057e+00,  1.3895e+00,  3.7091e+00, -6.7106e+00, -2.0928e-02,\n",
      "         4.1830e+00, -8.3880e-01, -1.2823e+00,  9.2604e-01, -1.0632e+00,\n",
      "         1.5000e+00,  3.3975e+00,  1.4446e+00,  2.8187e+00, -1.4946e+00,\n",
      "        -4.7649e+00, -8.6203e-02, -1.9486e+00, -6.2698e-02,  1.8385e+00,\n",
      "        -6.4872e-01,  2.5066e+00, -3.6508e+00,  1.9902e-01, -1.0010e+00,\n",
      "         9.9560e-01, -2.5517e+00,  1.4461e+00, -9.7284e-01, -3.8140e+00,\n",
      "        -1.5772e+00, -3.4730e+00, -7.8874e+00, -1.0917e+00, -1.1314e-01,\n",
      "         3.2832e+00,  2.1131e-01, -3.9033e+00, -2.1121e-01,  2.6342e+00,\n",
      "        -9.2859e-01,  8.8836e-01,  4.2129e-01,  2.2333e+00,  1.2740e+00,\n",
      "         2.6908e+00,  2.7322e+00, -1.2759e+00,  7.4289e-01,  4.1224e+00,\n",
      "         1.7729e+00, -8.6192e-01, -3.6214e+00,  9.1707e-01, -1.0902e+00,\n",
      "         9.9702e-01,  1.7284e+00, -2.2635e+00, -1.3035e+00, -7.8553e-01,\n",
      "        -2.0401e+00, -2.0716e+00, -2.5511e+00,  2.0938e+00,  8.9188e-01,\n",
      "        -3.0981e+00,  1.3676e-01, -2.9521e+00,  4.0491e+00, -3.5398e-01,\n",
      "        -4.2148e-01,  2.9475e+00,  3.6427e+00, -2.1459e+00, -4.1912e+00,\n",
      "         2.4158e+00,  7.1285e+00,  1.1886e+00,  1.3678e+00,  1.7753e+00,\n",
      "         4.1111e-01, -1.9923e+00,  7.5460e-01, -2.0834e-01,  6.4048e-01,\n",
      "         3.0398e-02,  3.5322e+00, -2.1514e-02,  4.7102e+00,  2.8624e+00,\n",
      "        -1.9120e+00,  8.3368e-01,  3.9288e+00, -6.9795e+00,  2.5870e+00,\n",
      "        -5.1068e+00, -3.6768e+00, -2.8805e-02, -1.4011e+00, -7.8055e-01,\n",
      "         2.3593e+00,  1.0439e-01, -4.6426e+00,  3.4683e-01,  2.9670e-01,\n",
      "        -6.1627e-01,  1.2926e+00, -1.6850e+00, -8.4600e-01,  1.4434e+00,\n",
      "        -7.8742e+00,  2.2936e+00, -1.4492e+00,  4.1491e+00, -2.3288e+00,\n",
      "         3.2073e+00,  1.3170e+00, -7.7178e-04, -1.5989e+00,  1.3186e+00,\n",
      "        -1.8878e+00, -4.9344e+00,  3.5554e+00,  1.0948e+00, -5.0737e+00,\n",
      "         2.8131e+00,  1.8211e+00])}, 'scene': {'emotion_logits': tensor([ 0.4340,  0.8846, -1.4251,  0.3228, -0.6891,  1.5473, -1.7124]), 'personality_scores': tensor([0.3037, 0.6032, 0.2477, 0.4853, 0.3627]), 'last_emo_encoder_features': tensor([ 1.2217e+00, -8.9602e+00, -1.7551e+00, -4.0319e+00,  2.2815e+00,\n",
      "         2.9453e+00,  2.7794e+00, -3.7807e-01, -2.7433e+00, -6.4504e+00,\n",
      "        -3.9900e+00, -8.2831e+00,  2.6902e-01, -2.3909e+00,  9.1235e+00,\n",
      "         2.5213e+00, -1.8649e-01,  4.5236e+00,  1.5040e-01, -1.3834e+00,\n",
      "        -2.3296e+00,  3.2758e+00, -6.9711e+00, -1.4475e+00,  1.7681e+00,\n",
      "        -6.1205e+00, -4.5116e-01, -9.6991e+00, -5.7082e+00,  1.7945e+00,\n",
      "         3.4375e+00,  8.1405e-01,  8.8073e+00,  7.9224e-01, -5.8375e-01,\n",
      "        -1.8409e+00, -6.5707e+00, -7.6375e+00, -4.8186e+00, -4.9546e+00,\n",
      "        -6.9039e+00,  9.7882e-01, -1.5009e+00,  7.6022e+00, -1.1113e+01,\n",
      "         5.8002e+00, -1.1282e+01,  4.6391e-01,  3.1907e+00, -3.7432e+00,\n",
      "        -3.9211e+00,  1.4173e+00, -4.4895e+00, -1.8551e+00, -2.8924e+00,\n",
      "        -6.8016e+00,  4.7094e+00, -1.7210e-01,  7.5409e-01, -2.7515e+00,\n",
      "        -1.9702e+00, -8.5547e-01,  1.1245e+01,  1.1329e+00, -3.6584e+00,\n",
      "        -4.3793e+00,  6.5021e-01, -1.0507e+01, -5.2010e+00, -1.5302e+01,\n",
      "         2.4888e+00, -9.5641e+00, -1.0418e+01, -1.6824e+00,  2.1268e+00,\n",
      "        -1.3275e+00, -2.9629e+00,  1.1652e+01, -4.5521e+00,  5.1430e+00,\n",
      "        -6.3036e-02, -3.3122e+00,  4.4246e+00,  5.1170e+00, -4.6569e-01,\n",
      "        -5.7971e-01, -3.7886e-02, -3.0951e+00, -9.3335e-01, -4.3930e+00,\n",
      "         1.8401e+00, -6.3377e+00, -6.8257e+00, -7.0588e+00, -9.0184e-01,\n",
      "        -4.7097e+00, -2.0480e+00,  9.6633e+00, -2.7481e+00, -6.2915e+00,\n",
      "        -3.0376e+00, -1.0228e+01, -2.4418e+00,  4.8489e+00, -6.0519e+00,\n",
      "        -2.4313e+00,  6.0970e+00,  8.5645e+00, -6.3870e+00,  8.4453e+00,\n",
      "         8.7474e-01, -1.0864e+01, -3.0926e+00,  5.3285e+00, -7.6918e+00,\n",
      "        -1.4152e+00,  1.2937e+01,  6.3798e+00, -1.7780e+00, -9.4001e+00,\n",
      "        -5.7429e+00, -1.5135e+00,  5.5344e+00, -4.0834e+00, -5.9259e+00,\n",
      "        -3.2774e+00,  1.4065e-01, -1.2872e+00,  5.6771e+00, -1.1437e+01,\n",
      "        -5.4436e+00,  4.2994e+00,  1.9486e+00, -4.8808e+00,  8.1240e-02,\n",
      "        -5.0294e-01,  2.8486e+00, -6.3830e+00,  3.4106e+00,  1.9890e-03,\n",
      "        -3.3673e-01,  7.7208e+00,  2.4456e+00, -1.0594e+01,  2.4043e+00,\n",
      "        -3.9086e+00, -4.6095e+00,  1.9967e+00, -5.8392e+00, -1.0830e+01,\n",
      "         9.4867e+00,  5.7355e-01, -9.0110e+00,  6.7070e-01,  5.3583e+00,\n",
      "        -1.1271e+00, -3.3653e+00, -5.1677e+00, -9.3209e+00,  8.6048e+00,\n",
      "         1.0556e+01, -3.5906e+00,  1.8631e+00, -4.6639e+00,  1.9642e+00,\n",
      "         8.8270e+00,  4.6348e+00,  1.2815e+00, -8.7714e+00, -1.0297e+01,\n",
      "        -4.2200e-01, -4.8159e+00,  8.5046e+00,  4.2125e-01, -9.0848e+00,\n",
      "         8.9708e+00, -5.0332e+00, -5.6349e-02, -5.8743e+00, -4.7551e+00,\n",
      "         1.0420e+01, -2.5725e+00,  9.0946e+00,  1.7001e+00, -2.7871e+00,\n",
      "         6.2071e+00, -1.1256e+00,  3.7818e+00,  1.7232e+00, -8.2791e+00,\n",
      "        -7.1448e+00,  1.0707e+00,  3.2924e+00, -7.3003e+00,  1.0440e+01,\n",
      "        -6.1808e-01, -9.2407e+00,  3.6726e+00,  9.1212e+00,  1.2026e+01,\n",
      "         7.5204e+00, -8.2279e-01,  1.2117e+00, -6.2814e+00,  5.7574e+00,\n",
      "        -2.3413e+00,  1.0452e+01,  8.5774e+00,  2.6902e+00,  3.7137e+00,\n",
      "        -3.1037e+00,  2.7199e+00,  1.2827e+00,  2.9258e+00,  3.4275e+00,\n",
      "         3.3025e+00, -1.6017e+00,  6.8913e+00, -3.1167e+00, -2.2015e+00,\n",
      "        -2.7570e+00,  6.5389e+00,  1.0044e+00, -1.4165e+00, -1.7763e+00,\n",
      "        -2.6450e+00,  4.6008e+00,  3.6367e+00,  2.1782e-01,  7.2253e+00,\n",
      "         3.7917e+00, -5.8991e+00, -7.2645e+00, -5.5821e+00,  2.6666e+00,\n",
      "        -2.4436e+00,  1.8438e+00,  7.5079e+00, -1.3923e+00, -6.2474e+00,\n",
      "         1.1648e+01,  7.0364e+00, -6.9127e-01,  2.8601e+00,  4.4659e+00,\n",
      "         1.1924e+00,  1.1235e+00, -3.7256e-01, -6.5801e+00, -6.4200e+00,\n",
      "        -2.6790e+00,  6.4258e+00, -1.4457e+00, -1.6862e+00, -2.4093e+00,\n",
      "         4.8780e+00,  4.4683e+00,  2.2484e+00,  8.8936e+00,  5.6933e+00,\n",
      "         3.5838e-01, -4.2888e-01,  5.8465e+00, -2.1255e-02, -7.8355e+00,\n",
      "        -4.4258e+00, -7.3730e+00,  1.9342e+00,  1.2140e+00, -5.2888e+00,\n",
      "        -7.3742e+00,  6.7059e+00,  1.0309e+01,  1.2673e+01, -7.9654e+00,\n",
      "         7.7794e+00, -4.1205e+00, -1.7468e+00, -9.3065e-01,  8.8445e+00,\n",
      "        -6.2238e+00, -1.2452e+00,  1.4563e+00,  8.1812e-01,  2.5104e+00,\n",
      "        -1.7283e+00,  2.8316e+00,  4.5145e+00,  1.1206e+01,  2.5550e+00,\n",
      "         3.6423e+00,  3.8213e+00,  6.3788e+00,  3.4287e-01, -8.8371e+00,\n",
      "         2.3005e+00, -7.2260e+00, -5.6899e+00, -8.8060e+00, -2.1667e+00,\n",
      "         4.7845e+00, -2.7188e+00,  1.4144e-01,  6.9757e+00,  4.1029e-01,\n",
      "        -5.6272e+00,  1.1212e+00,  7.5376e+00, -4.0073e+00,  2.8744e+00,\n",
      "        -7.6239e+00,  2.9869e+00,  1.2012e+01, -3.0944e+00,  2.3374e+00,\n",
      "         2.4542e+00, -5.3905e+00,  1.3843e+00, -6.7923e+00,  6.7458e+00,\n",
      "         1.7607e+00, -3.7648e+00,  8.3726e+00, -5.2702e+00, -1.2475e+01,\n",
      "        -1.4132e+00, -5.9330e-01,  7.5488e+00, -2.7223e-01,  2.6254e+00,\n",
      "         3.0209e+00,  1.8855e+00,  5.3436e+00,  7.5094e+00, -4.8222e+00,\n",
      "        -3.1615e+00, -5.5330e+00,  3.9027e+00, -1.3401e+01,  2.4370e+00,\n",
      "         5.5299e-01,  1.2234e+00,  1.2659e+01, -1.3771e-01, -2.4566e+00,\n",
      "         6.2265e+00,  4.6051e+00,  7.7095e-01,  2.0200e+00, -3.0239e-01,\n",
      "        -1.2289e+00,  8.8080e+00, -1.9205e+00,  7.6920e+00,  6.8637e+00,\n",
      "        -1.0710e+00,  3.9175e+00,  4.2594e+00,  2.2631e-01,  3.1262e+00,\n",
      "        -1.2051e+01,  5.5550e+00,  3.2718e+00, -6.8487e+00, -3.7159e+00,\n",
      "        -7.6867e+00, -6.9791e+00,  4.7470e+00,  3.2389e+00,  3.4066e+00,\n",
      "        -2.4775e-01,  2.1495e+00,  1.6185e+00,  2.0929e-01, -1.7861e-02,\n",
      "        -6.3839e+00,  5.9498e-01,  8.5504e+00,  5.5596e+00, -1.0089e+00,\n",
      "        -6.4706e+00,  1.5331e+01,  4.2172e+00,  1.3346e+01, -3.5894e+00,\n",
      "         2.0100e+00, -1.4589e+01, -8.2423e+00,  5.5055e+00,  1.2651e+01,\n",
      "        -1.7630e+00,  6.4116e+00,  7.8224e-01,  6.2216e+00, -4.6620e+00,\n",
      "         2.1835e+00,  1.5931e+00,  2.6112e+00,  3.0046e+00,  4.6356e+00,\n",
      "         4.4772e+00, -4.9113e+00, -3.0065e+00,  6.8660e-01, -4.5388e+00,\n",
      "        -3.0267e-01,  1.1093e+01,  9.7616e+00,  5.3064e+00, -3.3494e+00,\n",
      "        -4.1876e+00, -4.7406e+00,  1.5060e+00,  4.3726e+00, -1.5205e+00,\n",
      "        -1.5068e+01, -3.6817e+00, -3.5107e+00,  2.4940e+00, -1.1031e+01,\n",
      "        -7.9549e+00,  5.2045e-01, -4.6977e+00, -5.1406e+00,  9.3801e+00,\n",
      "        -3.2354e+00,  3.7903e+00,  3.1685e+00, -1.7297e+01,  1.7925e+00,\n",
      "         7.6932e+00,  6.0081e+00,  2.1452e+00,  2.6669e+00, -5.9290e+00,\n",
      "         1.3378e+01, -2.2700e+00,  1.6147e+00,  9.9213e+00,  9.8308e+00,\n",
      "         2.8789e+00, -4.5569e-01, -3.3837e+00,  1.9135e+00, -5.4969e+00,\n",
      "        -3.8451e-01, -2.1745e+00, -1.2010e-01, -5.0566e+00, -2.6929e+00,\n",
      "         3.7594e+00, -1.0827e+01,  5.9425e+00,  1.2104e+01,  4.3683e+00,\n",
      "         6.4608e+00,  5.4284e+00, -1.2010e+00, -2.4383e+00,  2.7006e+00,\n",
      "        -2.4887e+00, -3.1846e+00, -3.4277e+00, -2.7606e+00, -1.8824e+00,\n",
      "         5.2940e-01, -1.8982e+00, -1.1574e+01, -1.0739e+01,  6.7891e+00,\n",
      "         6.5938e+00, -2.4923e-01, -9.0324e-02,  7.3374e+00, -7.3537e+00,\n",
      "        -6.5008e+00,  4.9910e+00,  8.1479e+00, -3.7358e-01,  8.2054e+00,\n",
      "        -3.1079e+00,  7.8963e+00,  9.1582e+00, -4.9025e+00,  1.1761e+00,\n",
      "         4.0979e-01, -2.8927e+00,  5.5592e+00, -3.1613e+00,  7.2585e+00,\n",
      "         1.4196e+00, -7.1262e-01, -3.0269e+00,  1.2238e+00, -4.2195e+00,\n",
      "         1.2351e+00, -9.8858e-01, -1.1431e+00, -6.8081e+00,  8.9447e+00,\n",
      "        -2.8946e+00,  8.4672e-01,  6.3097e-01,  8.5769e+00,  6.0293e-01,\n",
      "        -3.2654e+00,  4.7155e+00, -2.5350e+00, -8.4108e+00,  6.6807e-01,\n",
      "         5.0546e+00,  3.8142e+00, -4.6141e+00, -3.5147e+00, -1.0086e+01,\n",
      "        -5.4860e+00,  4.8984e+00, -2.3355e+00,  2.3893e+00,  7.4647e-01,\n",
      "         1.9526e+00, -5.4756e-01, -1.3231e+00,  9.3781e-01,  1.4491e+00,\n",
      "        -3.3552e+00,  6.6459e+00, -3.4361e+00,  1.6148e+00, -1.8817e+00,\n",
      "        -4.7850e+00, -6.4652e-01, -9.6941e+00, -2.1499e+00,  5.6858e+00,\n",
      "        -3.7792e-01,  6.3642e+00, -2.5013e+00, -5.6793e+00, -6.8593e+00,\n",
      "        -9.8514e+00,  6.8960e-01, -2.0991e+00, -2.0142e+00, -1.0609e+01,\n",
      "         6.9789e+00, -2.8329e-01, -8.2473e+00,  6.8587e+00, -2.0356e+00,\n",
      "         5.4948e+00, -2.8449e-01,  1.2301e+00, -6.9751e-01,  9.9070e-01,\n",
      "         8.9922e+00, -4.7860e+00, -1.4071e+00, -2.9924e+00,  7.7300e+00,\n",
      "        -5.1595e-02, -3.5635e+00, -1.3328e+00, -5.9459e-01, -3.1563e+00,\n",
      "         1.4040e+00, -3.0574e+00, -2.1791e+00, -1.3479e+00, -1.1660e+00,\n",
      "         1.1131e+01,  3.6063e+00, -2.1863e+00,  2.2527e+00, -3.5165e+00,\n",
      "         1.0305e+00, -6.2277e+00,  5.5108e+00,  3.9454e+00,  4.5599e+00,\n",
      "        -6.6983e-01,  1.2683e+01, -2.0384e+00,  4.0517e-01,  4.1845e+00,\n",
      "         8.4457e+00, -1.0848e+00,  1.9968e+00, -2.6238e+00, -1.1490e+01,\n",
      "         6.8016e+00,  3.4315e+00,  3.5205e-01, -3.4590e-01, -3.4651e+00,\n",
      "         1.7326e+00,  1.0789e+00,  6.7501e+00, -5.0178e+00,  2.4352e+00,\n",
      "        -4.3006e+00,  4.5153e-01,  2.0113e+00, -2.0870e+00, -3.0422e-01,\n",
      "         7.5339e+00, -1.0622e+01, -3.5743e+00,  4.8818e+00,  1.9492e+00,\n",
      "         1.4579e-01, -8.1872e+00,  4.6323e+00,  1.5995e+01, -2.2408e+00,\n",
      "         5.9435e+00,  5.3168e+00, -2.9048e+00, -2.2277e-01,  3.2686e+00,\n",
      "        -3.8679e-01, -3.3821e+00, -1.8525e-01,  2.9899e+00, -1.0259e+01,\n",
      "        -3.0591e+00,  3.2534e+00,  5.0183e+00,  2.1025e+00,  2.1684e+00,\n",
      "        -2.3563e+00,  1.8194e+00,  8.5576e+00, -1.3071e+00, -1.2467e+01,\n",
      "        -6.3604e+00, -1.0367e+00,  3.7884e+00, -2.3507e+00, -1.6568e+00,\n",
      "         6.6598e+00,  6.8683e+00,  1.4847e+00,  2.6437e+00,  6.8087e+00,\n",
      "        -2.7819e+00, -4.2079e+00,  2.7172e+00, -2.5094e+00,  1.1810e+01,\n",
      "         2.7841e+00,  2.6252e+00,  1.8891e+00,  3.5404e+00, -1.2818e+01,\n",
      "         3.8977e+00, -2.3633e+00, -5.2806e+00, -6.9943e+00,  1.0293e+01,\n",
      "         1.0911e+01,  8.4429e+00, -1.7468e-01, -6.9942e+00, -1.4680e+00,\n",
      "         2.8720e+00,  1.2538e+00, -2.8429e+00,  5.9695e+00,  1.1043e+01,\n",
      "         1.0275e+01, -4.3886e+00,  4.6166e+00, -2.5425e+00,  6.7124e+00,\n",
      "        -6.3402e-01, -9.8085e+00, -7.9306e+00,  4.9513e+00, -3.5772e+00,\n",
      "         2.6235e+00,  4.4676e+00,  5.8254e+00, -2.3423e+00, -1.0887e+01,\n",
      "        -1.8227e+00,  2.0273e+00, -1.1722e+01,  9.7483e+00,  1.8299e+00,\n",
      "        -1.1624e+00, -6.4352e+00, -2.9325e+00,  1.0306e+01,  4.0449e+00,\n",
      "        -2.5185e+00, -3.3362e+00,  1.6176e+00, -7.0300e+00,  2.2775e+00,\n",
      "        -4.0481e+00, -2.6464e+00,  2.2618e+00,  2.5917e+00, -1.3160e+00,\n",
      "        -1.5104e+00, -1.0487e+01,  4.8516e+00, -8.2209e+00, -1.5418e+01,\n",
      "        -1.6062e+00, -1.1603e+01,  8.2033e+00, -8.8305e+00, -6.1379e-01,\n",
      "         2.1584e+00,  3.1527e+00,  1.4028e+00,  3.3513e+00, -5.7012e+00,\n",
      "        -1.7114e+00,  6.9216e+00,  1.3378e+00,  1.7218e+00,  2.5845e-02,\n",
      "         5.6218e+00,  5.0038e+00,  2.8219e+00, -1.8279e-01,  1.4583e+00,\n",
      "         1.8924e+00,  3.7013e+00,  5.6275e+00, -3.3774e+00, -1.2231e+01,\n",
      "        -3.0961e+00,  3.7815e+00, -1.7560e+00, -1.4537e+01, -2.1641e+00,\n",
      "         1.9368e+00, -1.9701e+00,  4.6438e-01, -5.7024e+00, -1.7770e+00,\n",
      "         4.8117e+00, -5.7986e+00,  5.8175e+00, -1.8358e+00,  1.9073e+00,\n",
      "        -6.3955e+00,  5.4007e-01, -7.1028e+00, -1.3466e+00,  9.2929e+00,\n",
      "        -6.9603e+00, -1.3135e+01, -1.3302e+00,  6.8117e+00,  1.2055e+00,\n",
      "        -1.3527e+00,  3.1760e-01,  1.8500e+00,  4.5776e+00,  3.0958e+00,\n",
      "        -8.1687e+00,  3.8411e+00, -5.1250e+00]), 'last_per_encoder_features': tensor([ 4.5201e+00,  5.1942e+00, -4.5707e+00,  7.3472e-01, -1.8096e+00,\n",
      "        -9.0183e+00, -7.7191e+00,  2.1242e+00, -5.6698e+00,  3.5174e+00,\n",
      "        -1.9038e+00,  4.3116e+00, -5.2693e+00, -1.5951e+00, -5.5408e+00,\n",
      "         4.2053e+00, -1.3448e+01,  1.1094e+01, -1.7712e+00, -3.7969e+00,\n",
      "         6.8961e-01, -1.1966e+00, -2.2038e+00,  2.1897e+00,  3.6671e+00,\n",
      "         2.2563e+00, -2.6904e+00,  1.1397e+00,  3.3585e+00,  7.9125e+00,\n",
      "        -9.2788e+00, -2.3659e+00, -6.6228e+00,  1.3333e+00,  6.6109e+00,\n",
      "        -9.5044e+00, -5.2969e-02,  5.4487e+00, -8.6163e+00, -8.9236e+00,\n",
      "        -6.1324e+00, -6.0055e+00, -9.3112e+00, -4.5179e+00, -2.1421e+00,\n",
      "        -4.4059e+00,  8.0847e-01,  7.9763e+00,  1.6104e+00, -5.0198e+00,\n",
      "         2.7316e+00, -7.0768e-01,  1.4445e+00, -1.0394e+00, -3.8230e-01,\n",
      "        -2.8979e+00,  1.5083e+00, -4.5411e-01,  7.2885e-01,  3.0477e+00,\n",
      "        -2.5524e+00, -8.3784e+00, -2.5075e+00,  2.4037e+00, -7.5999e+00,\n",
      "        -6.0773e+00,  7.3587e+00,  8.7723e-01,  3.9107e-01,  3.8267e+00,\n",
      "         6.8607e+00,  7.7275e+00, -4.7494e-01,  3.0111e+00, -1.1856e+00,\n",
      "         1.6877e+00,  2.3376e-01, -8.5098e-01,  1.8752e+00,  9.1950e-01,\n",
      "         1.3830e+00, -2.9078e+00, -5.3387e-01, -4.5310e+00,  2.5046e+00,\n",
      "         2.0158e+00, -7.7899e+00, -3.6840e+00,  1.1566e+01,  8.0151e-01,\n",
      "         5.8989e+00, -2.5297e+00,  1.7230e+00,  1.5812e+00, -4.1509e+00,\n",
      "        -5.5869e+00, -4.9673e+00,  3.6599e+00, -5.4359e+00, -8.8548e+00,\n",
      "         8.7994e+00, -5.2780e+00,  4.5500e+00, -4.0100e+00,  3.9064e-01,\n",
      "         2.6066e+00,  5.7258e+00, -5.6849e-01, -4.7480e+00,  2.8668e+00,\n",
      "        -3.3706e+00, -2.9285e+00,  9.7911e-01, -3.3062e+00,  5.3045e+00,\n",
      "         3.7942e-01,  4.6763e-01, -1.8668e+00,  8.2925e-01,  2.8480e+00,\n",
      "        -9.3774e-01,  5.2750e+00,  3.9696e+00,  5.2423e+00,  4.3611e+00,\n",
      "         4.2615e+00, -7.5280e-01, -3.5221e-01, -1.4926e-01,  7.2913e+00,\n",
      "         4.0564e-01, -1.2494e+00, -1.5096e+00, -6.9552e-01, -2.5281e+00,\n",
      "         5.3814e+00,  5.2195e+00, -4.8434e+00,  9.4976e-01, -3.0518e+00,\n",
      "        -6.5737e-01, -3.1558e+00,  6.3368e+00,  3.4367e+00, -5.4742e+00,\n",
      "        -2.4756e+00, -8.9766e+00, -2.0141e+00,  1.5673e+00,  6.0534e-01,\n",
      "        -5.0722e+00,  8.8375e-01, -4.1930e+00,  3.6838e-01, -3.4493e+00,\n",
      "         2.7877e+00, -7.5403e+00, -3.6960e+00, -5.2667e+00, -1.3885e+00,\n",
      "         4.1415e+00, -4.0861e+00,  3.2208e+00,  5.1656e+00,  9.3932e-02,\n",
      "         9.4379e+00,  1.3977e+01,  1.3983e+00, -2.3752e+00,  1.1207e+01,\n",
      "         2.6887e+00,  2.5905e+00, -3.6320e+00,  3.8610e+00,  5.8090e+00,\n",
      "         3.3347e+00, -3.0097e+00, -1.7908e+00,  1.2954e+00, -3.0814e+00,\n",
      "         7.3054e+00,  2.1738e+00, -1.6038e+00,  3.2450e+00, -4.9978e-01,\n",
      "        -3.0677e+00, -7.0729e+00, -1.4534e+00,  1.4923e+00,  6.0551e+00,\n",
      "         1.5771e+00,  2.4934e+00,  2.5713e+00,  3.2873e+00, -6.3567e+00,\n",
      "        -3.6071e+00, -5.6840e+00,  2.9053e+00,  4.3611e+00,  6.6235e+00,\n",
      "        -3.9984e+00,  9.2616e+00, -2.9759e+00,  7.4410e-01,  1.3060e+00,\n",
      "        -8.1639e+00, -3.3917e+00,  4.1268e+00, -1.6937e-01, -3.2361e-01,\n",
      "        -2.9280e+00,  4.3292e+00,  1.1432e+00, -1.9240e+00,  3.9335e+00,\n",
      "        -4.4853e-02,  3.2807e+00,  7.6804e-01,  1.2747e+01,  5.4010e-01,\n",
      "        -4.2382e-01, -5.0781e+00,  2.7268e+00, -4.7278e+00, -2.0230e+00,\n",
      "         1.1943e+00, -8.9545e+00,  5.5735e+00,  7.6956e+00, -1.1420e+00,\n",
      "        -1.0812e+00,  1.6610e+00,  6.5339e+00, -1.3163e+00,  3.7538e+00,\n",
      "         6.7883e+00,  4.1196e+00, -1.5216e-01, -1.2318e+00,  6.3709e+00,\n",
      "         5.1743e+00,  3.4850e-01, -3.5331e+00, -8.8532e+00, -9.5591e+00,\n",
      "        -2.7327e+00, -3.8167e+00,  7.9779e-01,  1.7630e+00, -8.8417e-02,\n",
      "        -4.2238e-01,  1.2917e+00, -1.2233e+00,  2.1290e+00, -6.9629e+00,\n",
      "        -4.5751e+00,  7.2036e+00, -4.8681e-01,  4.3724e+00, -5.1149e+00,\n",
      "        -5.2599e-01,  9.9783e-01,  7.5808e-01, -2.8651e+00,  3.6175e+00,\n",
      "         3.7714e+00, -1.0672e+00, -9.9646e+00,  1.8230e+00, -2.3727e+00,\n",
      "        -3.2894e+00, -1.5748e+00,  3.5672e-01, -1.0931e+00, -2.9637e+00,\n",
      "        -3.8143e+00,  3.4939e+00,  7.5502e+00,  3.9010e+00,  2.2294e+00,\n",
      "        -7.9996e+00,  2.9727e-01,  4.9412e+00,  5.0856e-01,  4.1064e+00,\n",
      "        -1.1064e+00, -4.1637e-01, -7.7077e+00,  9.7876e+00,  5.0591e+00,\n",
      "        -3.2524e+00, -1.0206e+01, -6.7940e+00,  1.1699e+00, -2.0022e+00,\n",
      "        -2.1715e+00,  8.4682e+00,  2.9849e+00, -1.2049e+00, -6.2802e+00,\n",
      "        -7.1563e-01,  1.9898e+00, -7.1180e+00,  8.6564e+00, -9.7644e-01,\n",
      "        -3.5700e+00, -1.2707e-01, -2.5993e+00, -9.2174e-01,  1.5704e+00,\n",
      "         2.9958e+00,  2.2914e+00,  8.0242e+00, -2.7513e+00,  4.5822e+00,\n",
      "        -8.1259e+00,  5.6880e+00,  2.4849e+00,  6.7958e-01, -2.3381e+00,\n",
      "        -1.1927e+00,  2.8535e+00,  8.6307e+00, -3.1599e+00, -1.1895e+00,\n",
      "        -4.9879e+00, -5.1416e+00,  1.1168e-01, -5.9050e+00, -2.3007e-01,\n",
      "         1.3126e+00, -1.6802e+00, -1.2102e+00,  3.0952e-01, -5.6566e+00,\n",
      "         2.4336e+00, -4.4125e+00, -6.6612e+00, -1.4992e+00, -1.8419e+00,\n",
      "        -9.3471e+00, -1.2356e+01,  3.3628e+00,  9.1651e+00,  5.6033e+00,\n",
      "         1.4792e+00, -3.4611e+00,  4.9550e+00, -1.6370e+00, -6.3226e+00,\n",
      "         1.2799e+00, -7.4378e+00, -3.2884e+00,  7.9174e+00, -7.7304e+00,\n",
      "         1.1117e+01,  1.9776e+00,  9.3973e-01, -1.6657e+00,  6.3677e+00,\n",
      "        -9.1364e+00, -4.8015e+00, -2.4661e+00, -3.3141e+00, -4.0770e+00,\n",
      "        -5.7710e+00, -2.7518e-01,  9.6619e+00,  7.7996e-01, -5.7445e+00,\n",
      "        -3.6233e+00, -3.8185e+00,  4.3506e+00, -1.5899e+00,  7.0205e+00,\n",
      "        -3.4252e+00, -5.8510e+00,  7.6807e-01,  6.0706e+00, -4.1745e+00,\n",
      "         4.4973e-01, -3.8074e+00,  5.2203e+00, -3.6680e+00, -9.2555e+00,\n",
      "         4.0483e-01, -9.7755e-01, -1.7897e-01, -1.9905e+00, -7.7934e+00,\n",
      "        -8.2677e-01, -8.9102e+00, -1.5592e+00, -1.0689e+01, -3.8611e+00,\n",
      "         1.1594e+01, -3.1963e+00,  2.1829e+00,  3.0591e+00,  4.3354e-01,\n",
      "         2.5297e+00,  5.7394e+00, -1.8363e+00, -6.8760e-01,  2.5932e+00,\n",
      "        -2.7962e-01, -6.4488e+00,  3.8876e+00, -1.5073e+00,  2.8422e+00,\n",
      "        -1.9206e+00, -1.0985e+00, -2.9138e+00,  3.8040e+00,  3.6504e+00,\n",
      "         5.3468e+00,  2.1958e+00,  8.0706e-01, -9.1702e-01, -7.6649e-01,\n",
      "        -2.6626e+00,  4.6867e+00, -2.7567e+00,  5.1231e+00, -4.2895e+00,\n",
      "         6.0808e+00, -7.2320e+00,  4.5281e+00,  2.3553e+00,  3.9814e+00,\n",
      "        -2.4757e-01,  1.3456e-01,  3.0894e+00,  3.3261e+00,  6.1707e+00,\n",
      "        -9.2060e-01, -1.6756e+00,  4.9550e+00,  3.9249e+00, -8.0805e-01,\n",
      "         2.1026e+00,  4.6922e-01,  6.5214e+00,  2.7796e+00,  1.1153e-02,\n",
      "         4.5814e+00, -3.2083e-01, -5.3974e+00, -2.4021e+00,  7.1075e+00,\n",
      "         2.3739e+00, -6.1923e+00, -1.1991e+00,  7.0069e+00,  2.7199e+00,\n",
      "        -8.3536e-01,  3.5538e-01,  2.4033e+00, -6.0884e-01, -1.6064e+00,\n",
      "        -6.0604e+00,  4.2687e+00,  1.6897e+00,  1.2786e+00, -2.7446e-01,\n",
      "         9.6538e-01,  2.2747e+00,  6.8645e+00, -4.1295e+00,  4.9770e+00,\n",
      "        -5.4339e+00, -1.4455e+00, -8.0863e-01, -5.7469e+00, -3.6156e+00,\n",
      "         2.7752e+00,  2.4012e+00, -6.3051e+00, -3.2512e+00,  3.7048e+00,\n",
      "        -1.2770e+01, -2.3781e+00,  4.1077e+00,  8.3986e+00, -4.2713e+00,\n",
      "         2.1306e+00, -1.5241e+00, -3.3699e+00,  3.8277e-01, -7.6846e+00,\n",
      "         2.5484e+00, -1.5534e+00,  1.5844e+00, -3.9874e+00, -6.6262e+00,\n",
      "         1.9443e+00,  2.1397e+00,  1.0379e+00, -5.9546e-01, -2.7210e+00,\n",
      "         1.1403e+01,  1.6578e+00, -6.3015e+00,  1.7579e+00,  9.1024e-01,\n",
      "        -4.2082e-02,  1.3013e+00,  1.3893e+00, -5.7330e-01,  7.0467e+00,\n",
      "        -4.3614e+00,  5.2747e+00, -5.3925e+00,  5.4410e+00,  5.0858e+00,\n",
      "        -1.9435e+00,  1.6880e+00, -4.6583e-01, -8.3689e+00,  7.7806e+00,\n",
      "         4.1115e-01,  6.5468e+00, -1.9374e+00, -6.2317e+00,  5.0596e+00,\n",
      "         7.7046e+00,  1.3867e+01,  3.3990e+00, -6.8243e+00, -1.0725e+01,\n",
      "         4.8443e+00,  1.9118e+00,  2.6142e+00, -1.0910e+01, -2.9280e+00,\n",
      "        -5.1764e+00, -6.5276e+00, -1.0840e+00, -4.8290e+00, -4.1217e+00,\n",
      "         3.9288e+00,  3.6881e+00,  3.9910e+00,  3.8343e-01, -1.4978e+00,\n",
      "        -3.1547e+00,  4.4486e+00, -3.4393e-01, -3.9515e+00,  6.6660e+00,\n",
      "         4.2730e+00,  2.8136e+00, -6.6209e+00,  8.8890e+00,  4.6384e+00,\n",
      "        -2.0799e+00,  4.0577e+00, -2.2544e+00, -1.1583e+00, -7.8418e+00,\n",
      "        -2.4349e+00,  3.6551e+00,  1.2553e+01, -1.5744e+00, -1.3202e+00,\n",
      "         4.3491e-01, -6.6286e-01,  2.7133e-01, -5.6736e+00,  4.2417e+00,\n",
      "        -4.2776e+00, -1.2709e-01,  1.2063e+00, -5.4993e+00, -4.7965e+00,\n",
      "         5.5949e+00,  9.0100e+00, -3.7840e-01,  7.3247e+00, -2.5321e+00,\n",
      "         1.7036e+00, -1.8222e+00,  6.4886e+00, -1.0731e+01,  7.4828e+00,\n",
      "        -2.5214e+00, -4.2918e-01, -7.9947e+00, -1.5935e+00,  5.0965e+00,\n",
      "        -2.1908e+00,  1.9765e+00,  5.0882e+00, -2.8450e+00, -8.3093e+00,\n",
      "         1.6115e+00,  1.4317e-01, -1.0273e+00,  1.4044e+00,  7.3945e+00,\n",
      "        -3.9151e+00,  3.5837e+00,  9.5746e+00,  4.6916e+00, -3.5766e+00,\n",
      "         4.2397e+00, -6.6243e+00,  4.4796e+00,  6.0166e+00, -3.7366e+00,\n",
      "         8.3851e+00,  2.9503e+00, -3.1615e+00,  1.9325e+00, -5.0427e+00,\n",
      "         2.7740e+00, -3.0512e-01,  5.0627e+00,  5.5331e-01,  2.4304e+00,\n",
      "         1.2823e+00, -5.5423e+00,  2.6544e+00,  1.3280e+00, -1.9807e+00,\n",
      "        -1.9999e-01,  6.4924e+00,  2.7474e+00,  3.0397e+00,  8.3817e-01,\n",
      "         1.2409e+00, -5.1070e+00,  3.6058e+00,  3.3052e+00, -5.9145e+00,\n",
      "        -6.4118e+00,  4.0364e+00,  1.4887e+00,  1.0614e+01, -7.2195e+00,\n",
      "         9.6257e-01, -1.4639e+00,  3.5712e+00,  8.8447e+00, -2.3957e+00,\n",
      "         7.3026e+00,  3.5543e+00, -5.9194e+00,  2.8582e+00, -4.0391e+00,\n",
      "        -2.4769e+00, -2.2458e+00,  7.5438e-01,  3.4859e+00, -4.4907e+00,\n",
      "         2.3614e+00,  2.5337e+00, -3.9899e+00,  1.1547e+01,  1.0945e+00,\n",
      "         9.2221e+00,  3.0211e+00,  4.1178e+00, -5.1979e+00, -3.6109e+00,\n",
      "        -2.9265e+00, -8.0740e+00,  6.0669e+00, -5.2615e+00, -1.3142e+00,\n",
      "        -1.6913e+00,  1.0182e+01, -4.5387e+00, -2.6199e+00, -1.1914e+00,\n",
      "        -1.6310e+00, -3.4836e+00, -3.4204e+00,  2.3740e+00, -3.3422e+00,\n",
      "         1.1245e+01,  2.0558e+00,  1.4935e-01,  3.3152e+00, -2.8464e+00,\n",
      "        -5.4142e+00, -8.6610e+00,  3.8864e+00, -2.2124e+00, -3.0208e+00,\n",
      "         1.3128e+00,  4.6146e-01, -1.3209e+00,  6.4085e+00,  3.6046e+00,\n",
      "         3.2530e+00, -8.2287e+00, -7.5628e+00,  1.2070e+00,  2.9131e+00,\n",
      "         2.7282e+00,  3.7820e-01, -4.6437e+00,  1.6885e+00, -4.5005e+00,\n",
      "        -9.5642e-01,  2.3368e+00, -3.6254e+00, -5.4336e-01, -4.5842e-01,\n",
      "         5.9258e+00, -5.9875e+00,  4.3842e+00, -7.6273e+00,  2.1271e+00,\n",
      "        -5.0902e+00,  5.8521e+00,  3.6038e+00, -7.9091e-01, -7.4048e-01,\n",
      "        -5.6484e+00, -6.0443e+00,  3.3885e+00, -8.1508e+00,  5.7909e+00,\n",
      "        -2.8848e+00,  9.5175e-01, -5.2242e-01,  2.7234e+00, -8.0945e+00,\n",
      "        -4.4856e+00, -1.5924e+00, -2.4281e+00,  1.1244e+01,  5.6689e-01,\n",
      "        -2.7598e+00, -1.2509e+00, -9.9751e-01, -2.3154e-01,  6.4807e+00,\n",
      "         1.0363e+01,  5.6466e+00, -2.0261e+00, -4.3923e+00,  9.4839e+00,\n",
      "        -3.8021e+00,  1.2987e+00, -1.1115e+00, -2.4903e-01, -6.5760e+00,\n",
      "        -5.2979e+00, -3.9959e+00, -1.8522e+00, -5.4322e+00, -8.6189e+00,\n",
      "         8.9756e+00,  3.2931e+00, -6.4819e+00, -8.5078e+00,  4.8990e+00,\n",
      "        -5.0139e+00, -2.2624e+00, -1.8012e-01,  2.9558e+00,  3.0410e-01,\n",
      "         1.1983e-01,  7.0533e+00,  1.1664e+00])}, 'audio': {'emotion_logits': tensor([ 1.2522, -0.9251, -1.6752,  1.2129,  0.9181,  1.9537, -2.1170]), 'personality_scores': tensor([0.3824, 0.5868, 0.2976, 0.4869, 0.4345]), 'last_emo_encoder_features': tensor([-1.1459e+00,  3.4363e-01, -2.7228e-01,  4.5581e-01,  3.2446e-01,\n",
      "         1.7883e-01, -3.4156e-01, -8.5532e-01, -7.1697e-01,  3.4404e-01,\n",
      "         2.7300e-01,  6.9761e-01, -6.2860e-01, -1.0057e+00,  5.9837e-01,\n",
      "         3.1771e-02,  6.3699e-02, -4.9480e-01, -4.9797e-01, -7.4518e-01,\n",
      "         2.7359e-01,  4.8410e-01,  6.7021e-01,  2.4414e-01,  1.2029e+00,\n",
      "         1.4264e-03,  5.4377e-01, -1.9698e-01, -2.3366e-01, -1.8078e-01,\n",
      "         3.4672e-01, -3.6639e-01,  1.0629e+00, -1.8531e-01,  4.0008e-01,\n",
      "         1.8928e-02, -2.7896e-03, -5.5281e-05, -3.3159e-01, -6.8064e-01,\n",
      "        -2.8615e-02,  4.7856e-03, -1.5395e-01,  7.7461e-02,  4.0387e-01,\n",
      "        -3.2867e-01,  1.7661e-01,  6.2669e-02,  1.1362e-01, -1.1992e-01,\n",
      "         1.7907e-01,  3.6917e-01, -4.8777e-01,  3.1120e-01, -1.4931e-01,\n",
      "        -6.2994e-01,  3.2467e-01, -3.2077e-02,  2.3959e-01,  4.6667e-01,\n",
      "         4.4556e-01, -3.4032e-02, -6.4684e-01, -3.0087e-01, -1.1330e-01,\n",
      "         6.0749e-01,  4.1461e-01,  3.2515e-02,  5.2565e-01, -1.9399e-01,\n",
      "         8.2437e-01,  3.1426e-01,  2.5181e-01, -4.9917e-01, -1.3820e+00,\n",
      "        -7.8447e-01,  1.3226e-01, -6.8764e-01, -2.0756e-01,  1.2060e-02,\n",
      "        -1.8413e-01,  7.1184e-01, -5.9132e-03,  1.6167e-01, -7.9189e-01,\n",
      "         1.3240e-01,  7.4786e-01, -4.9731e-03,  2.1953e-01, -3.8488e-01,\n",
      "        -5.3016e-01, -2.5486e-01, -3.1207e-01,  3.2090e-01,  4.1965e-01,\n",
      "        -4.6514e-02, -1.0724e-01, -4.7942e-01, -1.4028e+00, -2.9167e-01,\n",
      "        -5.8794e-02,  5.4748e-01,  2.6169e-01, -4.9637e-01,  3.3700e-01,\n",
      "         1.1443e-01, -1.8780e-01,  2.0946e-01, -4.4084e-01, -7.1341e-01,\n",
      "         4.0987e-01, -2.0472e-01, -7.5692e-01, -2.2181e-01, -6.5261e-01,\n",
      "        -4.5150e-01,  4.1663e-01,  4.6721e-01,  4.9534e-01,  5.3008e-01,\n",
      "         1.1200e+00, -3.0185e-01, -7.6319e-01,  1.7444e-01, -3.5818e-01,\n",
      "        -1.4607e-02,  1.7513e-01, -3.9243e-01,  1.0763e-01, -3.6562e-01,\n",
      "         2.0571e-01,  1.5236e-01,  4.7361e-01,  4.2905e-01,  1.1097e-01,\n",
      "         3.0949e-01, -4.4075e-01, -4.4815e-01,  2.0614e-01,  5.7864e-01,\n",
      "         2.1525e-01,  6.9125e-01, -4.1427e-02,  7.7593e-02,  3.9551e-02,\n",
      "        -7.0129e-01,  5.0375e-01,  8.9657e-02, -8.1872e-01, -2.3437e-01,\n",
      "         3.6144e-01,  2.2433e-01, -8.2914e-02,  5.5653e-01,  1.1518e-01,\n",
      "        -6.3257e-01, -5.8566e-01, -5.5548e-01, -5.4307e-02,  1.2404e+00,\n",
      "         8.9894e-01,  8.9713e-01, -3.1588e-01, -6.7805e-01,  6.4938e-01,\n",
      "        -1.1798e-01,  7.3371e-01, -3.7331e-01,  6.8778e-02,  3.9513e-01,\n",
      "         2.3621e-01, -5.3472e-01,  1.0624e+00,  6.2746e-01,  1.4450e-01,\n",
      "        -5.6089e-01,  1.0251e-01, -4.3961e-01,  4.6816e-01,  5.2880e-01,\n",
      "         6.2057e-01, -2.3974e-02, -1.6427e-01,  5.6944e-01, -1.0187e-01,\n",
      "        -1.4595e-01,  3.2818e-01,  4.9442e-01,  6.8914e-01, -1.1065e+00,\n",
      "        -3.0655e-01, -2.4689e-01,  2.3536e-01, -5.8100e-02, -9.5478e-02,\n",
      "         2.5082e-01,  2.4861e-01,  9.4055e-01,  2.2479e-01,  1.3839e+00,\n",
      "         5.6216e-01, -2.7781e-02,  6.6554e-01, -7.3303e-01, -7.5980e-02,\n",
      "        -1.4066e-01,  1.8955e-01, -1.8036e-01,  5.0391e-01, -9.1001e-01,\n",
      "         2.2362e-01, -5.9209e-01,  3.3144e-01,  5.9314e-01, -1.1557e+00,\n",
      "        -8.8634e-01,  6.9497e-01,  7.7547e-01,  5.1209e-01,  2.3463e-01,\n",
      "        -2.1282e-01, -5.3779e-01, -2.0461e-01, -6.9068e-01, -1.3202e+00,\n",
      "         2.8074e-02,  3.7384e-01, -4.3972e-01,  8.1870e-01,  3.4269e-01,\n",
      "        -2.7619e-01, -6.9583e-01,  3.8031e-01, -6.9739e-02,  2.9916e-01,\n",
      "        -1.6847e-02,  7.1552e-02, -1.2524e-02,  5.5468e-01,  4.9632e-01,\n",
      "        -1.0352e-01,  3.8819e-01,  2.6041e-01,  3.9754e-01, -8.5152e-01,\n",
      "        -6.6239e-01, -3.6751e-01,  8.4718e-02, -5.4614e-01,  2.3846e-01,\n",
      "        -3.7195e-01, -1.4872e-01, -9.4981e-02, -2.2678e-01,  5.2938e-01,\n",
      "        -1.3690e-01]), 'last_per_encoder_features': tensor([-8.2018e-02,  6.0864e-03, -3.3018e-01,  1.4379e-01,  7.1081e-01,\n",
      "         2.3200e-01, -9.0385e-01,  8.2969e-01, -2.4979e-01, -3.6336e-01,\n",
      "        -1.6210e+00, -9.4982e-01, -2.9554e-01,  1.7937e+00, -1.6106e+00,\n",
      "         4.4128e-01,  3.6703e-01,  1.1394e-01,  7.8856e-01,  1.0690e+00,\n",
      "        -6.0316e-01,  4.5971e-01, -1.9958e-01, -8.4004e-01,  7.3590e-01,\n",
      "         2.7164e-01, -1.7686e+00, -4.1535e-01,  1.4585e-01, -1.9355e-01,\n",
      "         1.5619e-01,  4.6923e-01,  5.1726e-01,  2.2411e-01,  7.0359e-02,\n",
      "        -5.7569e-01,  3.4239e-01,  1.4611e+00,  1.5824e+00, -2.1914e-01,\n",
      "         1.7410e-01,  4.9457e-01,  8.2393e-01,  1.7217e-01, -2.4642e-01,\n",
      "         5.2939e-01, -3.3539e-01, -3.3356e-01, -1.8194e-01,  4.5160e-01,\n",
      "        -6.3912e-01, -9.8358e-01,  2.6914e-01, -8.7890e-03, -6.5239e-01,\n",
      "        -1.4058e-01,  4.6011e-01,  3.1600e-01,  1.0420e+00,  4.1395e-01,\n",
      "         5.7192e-01, -5.6138e-01,  1.3224e+00,  1.1357e-01,  4.5948e-01,\n",
      "        -1.0109e+00,  4.1002e-01, -1.8881e+00, -8.7086e-01, -4.8240e-01,\n",
      "        -6.5730e-01, -1.0201e-01,  4.8395e-01,  2.5050e-01, -8.7604e-01,\n",
      "         4.7585e-01,  7.3997e-01,  5.1677e-03,  6.4665e-01, -1.8910e+00,\n",
      "         1.1004e+00,  1.2555e+00,  1.5384e+00, -6.6462e-01,  6.5387e-02,\n",
      "        -8.2393e-01,  1.5020e-01, -2.3800e-01,  5.4048e-01, -5.3662e-01,\n",
      "         2.8020e-01,  4.4546e-01,  4.1529e-01,  5.5195e-01, -2.9595e-01,\n",
      "        -6.3132e-02, -9.8433e-01,  5.0995e-01, -1.4345e+00,  5.4130e-01,\n",
      "         1.5711e-01,  7.6619e-01, -2.9473e-01,  4.4122e-01, -5.2884e-01,\n",
      "        -2.9528e-01, -7.8789e-02,  4.5728e-01,  5.5157e-01,  1.5448e+00,\n",
      "         1.4800e+00, -8.1552e-01, -3.3570e-01,  2.5655e-01,  9.5877e-01,\n",
      "        -8.6151e-01,  5.1902e-01, -2.9346e-01, -3.7297e-01, -2.8025e-01,\n",
      "        -4.1102e-01,  7.0596e-01,  7.3030e-01, -1.4640e+00, -1.7231e-01,\n",
      "         1.0954e+00,  1.2387e+00, -1.2414e-01,  1.2119e+00, -6.3808e-01,\n",
      "         1.6535e+00,  7.9420e-01,  2.8802e-01,  5.7710e-01,  5.5147e-01,\n",
      "        -1.3570e-01,  5.1547e-01, -1.0723e+00, -1.3723e+00,  1.8144e-01,\n",
      "        -5.1702e-01, -7.5431e-01,  4.1834e-01, -1.3239e+00, -4.8288e-01,\n",
      "        -1.6535e-01,  1.2852e+00, -3.1215e-01,  3.3830e-01,  8.3369e-01,\n",
      "         8.7595e-01,  1.2064e+00,  6.5493e-01, -2.3779e-01,  2.7715e-01,\n",
      "         1.0856e+00,  8.0893e-01, -1.1745e-01, -3.3627e-01,  9.4683e-01,\n",
      "         1.2105e+00,  6.3412e-02,  5.3545e-01, -5.6813e-02, -5.3816e-01,\n",
      "         1.4897e+00, -1.2738e-01, -6.8748e-02, -2.9898e-01, -5.1954e-01,\n",
      "        -4.9504e-01,  9.5096e-02,  1.7668e-02, -8.3154e-01, -5.5405e-01,\n",
      "         1.0553e+00,  3.2725e-01, -1.3749e+00,  5.2283e-01,  1.2577e+00,\n",
      "         3.1933e-02, -9.3541e-01,  5.6254e-01, -2.2808e-01, -3.9635e-01,\n",
      "        -1.8639e-01, -6.8930e-01, -3.1386e-01,  7.9359e-01,  4.2217e-01,\n",
      "        -7.3590e-01,  2.3915e-01, -8.8523e-02, -8.4026e-01, -1.9652e-03,\n",
      "         7.9048e-01, -4.2702e-01,  2.8162e-01, -1.1776e+00,  1.3174e+00,\n",
      "         1.0787e+00, -1.1391e-01, -1.0467e-01, -2.3466e-01, -1.5083e+00,\n",
      "         9.8502e-01,  2.0987e-01,  2.1323e-01,  4.8594e-01, -5.3487e-01,\n",
      "        -1.5963e+00, -3.8359e-01,  3.8008e-01, -6.3301e-01, -1.3258e+00,\n",
      "         1.8443e-01, -2.2040e-01, -2.2649e-02, -5.9202e-01,  4.7324e-01,\n",
      "        -4.7545e-01, -1.8483e-01, -8.3967e-01, -1.1601e+00,  2.1467e-02,\n",
      "        -5.3281e-01,  1.4140e-01,  9.1906e-01,  7.5175e-01,  1.5971e-01,\n",
      "        -1.6699e-01,  2.4664e-01, -2.3653e-01,  4.6706e-01, -5.0924e-01,\n",
      "         2.8798e+00,  5.2385e-01, -2.0921e+00,  2.0259e-01,  4.8159e-01,\n",
      "        -3.6804e-01,  6.2902e-01,  4.3946e-01, -1.6756e+00,  2.5742e-01,\n",
      "        -1.8339e-01, -1.3727e+00,  2.1349e-01,  4.7086e-01, -5.6110e-02,\n",
      "        -3.6365e-01,  2.1786e-01,  1.4871e-01, -2.0622e-02,  2.8997e-02,\n",
      "        -1.4948e-01])}, 'text': {'emotion_logits': tensor([ 0.1648, -0.1253, -2.0227,  0.9871,  0.1848,  0.5950, -0.6119]), 'personality_scores': tensor([0.5357, 0.6516, 0.4252, 0.5848, 0.5745]), 'last_emo_encoder_features': tensor([-1.3358e+00, -8.4758e-01, -2.3044e-01, -4.7164e-01, -4.7235e-01,\n",
      "         3.6936e-01,  6.6671e-01, -2.3499e+00, -2.4166e-02,  8.8484e-01,\n",
      "        -9.6384e-01,  1.2834e-01,  1.2693e+00, -3.2887e-01, -2.5729e-01,\n",
      "         8.8311e-01,  2.3343e+00,  1.2263e+00,  8.1256e-02,  5.0738e-01,\n",
      "        -1.4421e+00,  1.1396e+00,  8.8917e-01, -7.1836e-01,  3.4119e-01,\n",
      "        -9.0240e-01,  2.6701e-01, -8.2720e-01,  4.3867e-01, -4.5529e+00,\n",
      "         7.8713e-02, -2.2155e-01, -6.6450e-01,  1.0895e+00,  8.2795e-01,\n",
      "        -9.7151e-01, -8.5668e-01, -1.5223e-01,  4.0128e-01,  3.9293e-03,\n",
      "        -7.4627e-01,  2.2587e-01,  1.4062e-01,  2.5501e-01,  8.7616e-01,\n",
      "         4.2099e-01,  1.4730e+00, -9.7164e-01,  1.7201e+00, -8.6028e-01,\n",
      "        -5.8336e-01,  6.2175e-01,  5.4672e-04,  4.1562e-01,  1.0455e+00,\n",
      "         1.1301e+00,  8.5382e-01,  1.2429e+00, -5.8854e-01,  2.5407e-01,\n",
      "        -2.6758e-01, -1.9859e+00,  1.5960e-01, -1.6895e-03,  3.2072e-01,\n",
      "         1.5387e+00, -5.3779e-01,  2.2951e-01, -6.3712e-02,  5.5153e-01,\n",
      "        -2.1833e-01, -1.1838e+00, -1.1049e+00, -1.3221e+00,  4.4275e-01,\n",
      "        -4.2986e-01, -8.3918e-02,  1.4309e+00, -1.1395e+00,  5.3268e-01,\n",
      "        -2.7168e-01,  2.5212e-01,  1.1273e+00,  3.1878e-01, -1.6921e+00,\n",
      "        -6.8164e-01, -1.5162e-01, -1.9468e+00,  3.3035e-01,  9.6203e-01,\n",
      "        -3.5072e-01, -5.9996e-01, -4.9253e-01, -2.7389e+00,  5.4882e-01,\n",
      "        -9.0683e-01,  3.8994e-01, -8.0958e-01, -6.4628e-01, -7.9893e-01,\n",
      "         1.6379e+00, -7.7442e-01, -3.0949e-01, -1.4134e+00,  7.8849e-01,\n",
      "         2.3537e-01,  1.7712e-01, -1.6739e-01, -1.9857e-01, -5.3808e-02,\n",
      "        -9.8509e-02, -1.9747e+00,  7.7699e-01,  4.3137e-01, -4.7894e-01,\n",
      "        -5.2931e-01, -6.3877e-01, -4.6840e-01, -8.2920e-01, -3.9678e-01,\n",
      "         3.6880e-01, -1.4190e+00,  2.7874e-01, -1.3437e+00,  1.1089e-01,\n",
      "         5.1367e-01,  5.0949e-01, -4.4769e-01,  1.3273e-01, -2.6371e+00,\n",
      "        -4.5426e-02, -8.1573e-01,  9.5208e-02, -4.6106e-01,  4.0965e-01,\n",
      "         9.0766e-02,  7.4265e-01, -4.3592e-01, -3.8997e-01, -4.2355e-02,\n",
      "         3.9041e-01, -5.0474e-01,  8.1442e-01,  1.0279e+00,  3.7824e-01,\n",
      "         1.0921e+00, -3.7227e-01, -1.1158e+00, -8.7036e-01, -1.8758e+00,\n",
      "         4.8802e-01, -5.9608e-01, -7.4713e-01,  3.4617e-01, -6.5450e-01,\n",
      "        -1.0589e+00, -4.4185e-01,  6.1498e-01,  4.1213e-01, -7.8912e-01,\n",
      "         8.9569e-01, -2.3864e+00,  1.2559e-01,  3.2472e-01,  1.0245e+00,\n",
      "         3.2428e-01, -1.8818e+00,  3.6022e-02,  4.9296e-01, -1.0467e+00,\n",
      "         7.6520e-01, -2.2724e+00, -9.9586e-01, -1.4003e+00,  9.0628e-01,\n",
      "        -1.0744e+00,  9.7487e-01, -2.5344e-01, -4.9345e-01, -1.3290e+00,\n",
      "        -5.6224e-01,  1.2525e+00, -8.5775e-01, -1.1377e-01,  1.6923e-01,\n",
      "         6.8671e-01,  8.3530e-01, -1.4700e+00, -1.6231e-02,  7.9436e-02,\n",
      "         1.3398e-01,  3.2815e-01,  2.1025e-01, -3.7068e-01, -4.2592e-01,\n",
      "        -7.7271e-01,  5.0315e-01, -7.0661e-01, -1.5529e+00, -1.0931e+00,\n",
      "        -5.0692e-01, -1.1385e+00, -3.4177e-01,  7.6960e-02, -9.2017e-01,\n",
      "        -1.8970e+00,  8.6781e-01, -2.5839e-01, -6.6447e-01, -7.2077e-01,\n",
      "         1.2968e+00,  2.0852e+00, -1.4753e-01, -7.8208e-01,  8.8558e-02,\n",
      "        -4.6750e-01,  4.5017e-01, -3.9350e-01,  1.0663e+00, -8.7411e-01,\n",
      "        -2.2423e-01, -1.5293e+00, -5.0875e-01, -2.1820e+00,  2.8155e-01,\n",
      "        -3.5808e-01, -6.5394e-01, -7.3360e-01,  4.0936e-01,  2.4147e+00,\n",
      "         9.4128e-01,  2.3534e-02,  3.8097e-01,  2.2371e-01,  8.3138e-01,\n",
      "        -6.5672e-01,  2.6908e+00, -1.3753e+00,  1.6127e+00,  3.7658e-01,\n",
      "         1.1774e+00, -1.5133e+00,  7.2319e-01, -2.2244e+00,  2.6715e-01,\n",
      "         2.5115e-01,  1.7715e+00, -8.7660e-01,  1.5534e+00,  1.2835e+00,\n",
      "         1.9960e+00,  2.8364e+00, -5.1621e-01, -9.0650e-01, -1.8167e+00,\n",
      "        -2.4892e-01]), 'last_per_encoder_features': tensor([-0.5617, -0.4754, -0.5106, -1.9139, -2.2368, -1.5442,  0.3889,  1.3059,\n",
      "        -2.5080, -2.7024,  1.6704, -3.3659, -2.1284,  0.4708, -2.3888, -1.8362,\n",
      "        -1.7174, -3.1922, -1.6847, -4.8887,  1.5824,  1.1730, -1.1249, -1.2272,\n",
      "        -0.6495,  2.5964, -0.3116,  2.4261,  0.5855,  3.2978,  1.2819, -3.1739,\n",
      "         1.2655,  0.3990,  1.7054, -5.4910, -1.1800,  4.1596, -0.3188,  0.5426,\n",
      "         0.3531,  2.3963,  1.6766,  4.4662, -2.4233, -0.4173,  2.6558, -1.4216,\n",
      "        -1.9991, -1.4899, -1.8076,  0.8971, -0.9136,  3.9833, -0.8959, -5.3687,\n",
      "        -1.0280,  0.6228, -0.3523, -2.1558,  0.4374, -1.7920, -2.2489,  1.7766,\n",
      "         3.6240, -3.6330, -0.8952, -0.5685,  2.9917, -1.7360, -1.2813,  2.9777,\n",
      "        -1.1733,  0.2116,  0.3904,  0.3609, -1.8032,  0.7615, -3.0894, -4.0969,\n",
      "         1.0973,  0.9327,  1.3468, -2.7670,  0.8470, -2.5896, -0.4575, -2.4000,\n",
      "        -1.3299, -3.0254,  3.8014, -3.5726,  1.8988, -0.2193, -1.6550,  0.8846,\n",
      "        -0.0711, -0.9288, -0.7491,  4.5822, -1.1895, -0.2547, -1.0454, -0.8254,\n",
      "         2.0710, -3.0766,  2.6767,  1.4832, -4.5981, -0.7972, -0.4137,  1.9193,\n",
      "        -0.4573, -0.1614, -0.6088, -1.7981,  1.7275,  4.9123, -4.2653,  1.2501,\n",
      "        -1.2568, -1.6046, -0.8565,  1.9740, -1.2555,  0.6438, -0.9028,  0.3833,\n",
      "         2.4911, -0.3401, -0.4489,  1.7245,  2.7385,  3.7248, -1.5682,  0.6908,\n",
      "        -0.9083,  2.3505,  0.7613,  1.0179,  0.6986,  1.7139,  4.0763,  2.6789,\n",
      "         1.5764,  0.8972, -1.8942, -0.5954, -0.6580,  1.9810,  2.4286,  2.0008,\n",
      "         1.4488,  3.2282, -3.5589,  0.1318, -1.1317,  0.9613, -0.6777, -0.4712,\n",
      "         2.0476,  1.6964, -2.6010,  1.9819,  2.7621,  2.5636,  2.2354, -1.6254,\n",
      "         3.8726,  2.0713, -2.0942, -2.3288, -1.0607, -0.3918, -1.6984,  1.1620,\n",
      "         1.4016,  2.7543,  0.7612, -0.0228, -0.8079,  0.3211,  1.1013,  0.2292,\n",
      "        -1.6727,  1.7841,  0.7838,  0.1734, -0.9457, -0.3311,  2.0503, -2.3349,\n",
      "        -1.4906, -1.8379,  1.1762, -2.9025,  1.8075,  1.4080, -3.1575,  1.8343,\n",
      "        -2.6904, -1.5437,  0.5474, -0.8632,  2.9140, -0.0882,  0.2358, -0.6875,\n",
      "        -0.8142,  1.3002, -0.2281,  2.4046, -0.6001, -0.5803, -0.1952,  0.3090,\n",
      "        -4.0194,  1.9237,  1.9944, -1.9277,  2.9720, -0.3715,  0.0689,  2.8654,\n",
      "        -1.3955,  5.6283, -1.0063,  0.3758, -0.6852, -3.7382, -1.6456, -0.3087,\n",
      "        -0.9658,  1.3646,  0.6237, -0.2511,  0.5698,  2.2141,  2.6259,  1.7165,\n",
      "        -3.0457,  0.9200, -1.4867,  0.6875, -0.0336, -0.1556, -4.6411, -0.2918,\n",
      "        -2.3902,  2.4793,  2.3391,  1.8227, -0.1899, -2.1618,  3.1631,  2.0859])}}, 'labels': {'emotion': tensor([0.0000, 0.5000, 0.0000, 0.0000, 0.0000, 0.5000, 0.0000]), 'personality': tensor([nan, nan, nan, nan, nan])}}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# –ø—É—Ç—å –∫ —Ç–≤–æ–µ–º—É .pickle —Ñ–∞–π–ª—É\n",
    "pickle_path = \"../features/cmu_mosei_test_seed_42_subset_size_2_average_features_True_feature_norm_False.pickle\"\n",
    "\n",
    "with open(pickle_path, \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# –ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç\n",
    "print(\"üîç –ü–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç:\")\n",
    "item = data[0]\n",
    "print(item)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdb5996-61e3-471b-b5e5-b7a21b8adad6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8d4d3641-6bec-401f-9595-fd3ea934b237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîé –®–µ–π–ø—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:\n",
      "\n",
      "[BODY]\n",
      "  emotion_logits: torch.Size([7])\n",
      "  personality_scores: torch.Size([5])\n",
      "  last_emo_encoder_features: torch.Size([1024])\n",
      "  last_per_encoder_features: torch.Size([1024])\n",
      "\n",
      "[FACE]\n",
      "  emotion_logits: torch.Size([7])\n",
      "  personality_scores: torch.Size([5])\n",
      "  last_emo_encoder_features: torch.Size([512])\n",
      "  last_per_encoder_features: torch.Size([512])\n",
      "\n",
      "[SCENE]\n",
      "  emotion_logits: torch.Size([7])\n",
      "  personality_scores: torch.Size([5])\n",
      "  last_emo_encoder_features: torch.Size([768])\n",
      "  last_per_encoder_features: torch.Size([768])\n",
      "\n",
      "[AUDIO]\n",
      "  emotion_logits: torch.Size([7])\n",
      "  personality_scores: torch.Size([5])\n",
      "  last_emo_encoder_features: torch.Size([256])\n",
      "  last_per_encoder_features: torch.Size([256])\n",
      "\n",
      "[TEXT]\n",
      "  emotion_logits: torch.Size([7])\n",
      "  personality_scores: torch.Size([5])\n",
      "  last_emo_encoder_features: torch.Size([256])\n",
      "  last_per_encoder_features: torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ: —Ä–∞—Å–ø–µ—á–∞—Ç–∞—Ç—å —à–µ–π–ø—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç—è–º\n",
    "print(\"\\nüîé –®–µ–π–ø—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:\")\n",
    "modalities = item.get(\"features\", {})\n",
    "for mod_name, features in modalities.items():\n",
    "    print(f\"\\n[{mod_name.upper()}]\")\n",
    "    for feat_name, feat_val in features.items():\n",
    "        if isinstance(feat_val, torch.Tensor):\n",
    "            print(f\"  {feat_name}: {feat_val.shape}\")\n",
    "        elif isinstance(feat_val, np.ndarray):\n",
    "            print(f\"  {feat_name}: {feat_val.shape}\")\n",
    "        else:\n",
    "            print(f\"  {feat_name}: not a tensor ({type(feat_val)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b3717095-7b61-4f31-bd8a-50d091ef1f52",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../features/cmu_mosei_test_seed_42_subset_size_2_average_features_False_feature_norm_False.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# –ø—É—Ç—å –∫ —Ç–≤–æ–µ–º—É .pickle —Ñ–∞–π–ª—É\u001b[39;00m\n\u001b[0;32m      4\u001b[0m pickle_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../features/cmu_mosei_test_seed_42_subset_size_2_average_features_False_feature_norm_False.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpickle_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      7\u001b[0m     data \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# –ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Prgrm\\EAAI_2025\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../features/cmu_mosei_test_seed_42_subset_size_2_average_features_False_feature_norm_False.pickle'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# –ø—É—Ç—å –∫ —Ç–≤–æ–µ–º—É .pickle —Ñ–∞–π–ª—É\n",
    "pickle_path = \"../features/cmu_mosei_test_seed_42_subset_size_2_average_features_False_feature_norm_False.pickle\"\n",
    "\n",
    "with open(pickle_path, \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# –ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç\n",
    "print(\"üîç –ü–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç:\")\n",
    "item = data[0]\n",
    "print(item)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "808de167-db23-499e-acc4-2cf13f191a91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç –ü–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç:\n",
      "{'body': {'emotion_logits': tensor([-1.3183, -0.8238, -0.6552, -0.6306,  1.2407, -0.7158,  1.3891]), 'personality_scores': tensor([0.5326, 0.5365, 0.4849, 0.6321, 0.5423]), 'last_emo_encoder_features': tensor([-3.8351, -2.2751, -1.4746,  ..., -3.7185, -0.7212, -0.6948]), 'last_per_encoder_features': tensor([ 4.4531,  1.6310,  1.1421,  ...,  0.1990, -1.8134, -0.8094])}, 'face': {'emotion_logits': tensor([ 0.3950, -1.3291, -0.8733,  0.8395, -0.5555, -0.5297, -0.3164]), 'personality_scores': tensor([0.5448, 0.5832, 0.4877, 0.6371, 0.5482]), 'last_emo_encoder_features': tensor([-7.8037e+00,  7.3685e-01, -6.7197e-01,  5.2608e+00,  2.7093e+00,\n",
      "        -8.5908e-01,  7.0660e-01,  1.8818e+00, -7.1252e-02,  1.1847e-01,\n",
      "        -2.0084e+00,  6.3778e-01,  2.5741e+00, -1.2668e+00, -2.0097e+00,\n",
      "        -7.8275e+00,  3.3383e+00, -3.7198e+00, -1.6923e+00, -3.8017e-01,\n",
      "         8.0145e+00, -9.3273e-01, -6.2941e-01,  7.6822e-01,  3.5799e+00,\n",
      "        -5.1096e+00,  1.1017e+00, -4.3097e+00, -1.2193e+00,  1.5965e-01,\n",
      "         4.3750e+00, -4.2092e+00,  5.3175e+00,  3.1465e+00, -1.2244e+00,\n",
      "        -3.3327e+00,  3.1514e+00,  1.7549e+00, -1.4355e+00, -2.0142e-01,\n",
      "         3.6087e+00, -2.8974e-01, -3.7331e+00,  5.6680e-01, -3.0010e-01,\n",
      "         9.0169e-01, -1.1314e+00,  2.1992e+00,  4.5279e+00,  3.2596e+00,\n",
      "        -2.4183e+00, -5.7001e-01, -2.3132e+00, -3.1154e+00, -4.7663e+00,\n",
      "        -4.7279e+00, -2.4950e-01,  2.0279e+00,  2.3348e+00, -1.2379e+00,\n",
      "        -4.6050e-01, -1.1365e+00, -4.7051e-01,  1.8649e+00, -1.0845e+00,\n",
      "         1.6476e-01,  2.5328e+00,  2.3042e-01,  9.4413e-01,  2.4740e+00,\n",
      "        -2.4536e+00, -2.6942e-02, -5.6462e-02, -1.8618e+00, -2.1533e+00,\n",
      "        -4.3332e+00, -4.6510e+00, -5.3784e+00,  6.2951e-01,  3.2483e+00,\n",
      "        -1.5318e+00, -6.5289e+00, -6.8940e+00, -3.1748e+00, -1.0870e+00,\n",
      "        -7.6547e-01,  2.4738e-01, -2.9591e+00, -6.8369e-01,  5.6285e-01,\n",
      "        -4.0368e-01, -7.8555e+00,  3.7978e+00,  4.3003e+00, -2.6177e+00,\n",
      "        -1.7358e+00, -5.0570e-01, -3.5192e+00, -1.5536e+00, -1.7867e+00,\n",
      "        -2.7090e+00,  2.5931e-01, -2.4202e+00, -2.8526e+00,  1.5008e+00,\n",
      "        -3.1185e+00, -2.8423e+00, -3.7828e+00,  5.7870e+00, -5.9704e-01,\n",
      "        -1.8139e+00,  3.0643e+00, -5.1459e-01,  3.9783e+00,  5.7399e-01,\n",
      "         6.6687e-01, -2.8387e+00,  3.2814e+00, -2.7258e-01, -7.9078e-01,\n",
      "        -3.1760e+00,  8.4164e-02, -6.7941e-01,  3.7919e+00, -2.5553e+00,\n",
      "        -8.8240e-01, -4.1269e-01, -2.6904e+00,  2.4317e+00,  8.0473e-01,\n",
      "         1.3077e-01, -1.2166e+00,  1.9612e+00, -2.4235e+00, -3.1416e+00,\n",
      "        -3.2562e+00, -6.5874e-03, -1.6928e+00, -5.3513e+00, -3.8961e+00,\n",
      "         6.4773e+00,  2.3473e+00, -2.7002e+00, -2.1298e-01, -3.3738e+00,\n",
      "        -3.9626e+00, -8.7361e-01,  1.6330e+00, -4.0530e-01, -2.5986e+00,\n",
      "         5.1931e+00, -4.9246e+00,  5.9283e+00,  7.0322e-01, -5.2715e+00,\n",
      "         1.7706e+00,  3.6093e-03,  2.9787e+00,  1.8023e+00,  4.5037e+00,\n",
      "         4.1491e+00, -5.0086e+00,  2.8304e+00, -6.7761e+00, -1.6131e+00,\n",
      "         3.1030e+00, -7.4108e-01, -6.6344e-02,  8.7294e+00, -2.8990e-01,\n",
      "        -2.4898e+00, -5.8864e+00,  7.0400e+00, -5.0946e+00, -4.6184e-01,\n",
      "         3.8533e-01, -2.4418e+00,  2.5270e+00, -2.3711e+00,  1.6995e+00,\n",
      "         2.9339e-02, -5.1209e+00, -2.8351e+00, -7.6300e+00,  3.7635e-01,\n",
      "        -1.2412e+00, -8.1708e-02, -1.6783e+00,  2.0306e+00,  3.8866e-01,\n",
      "         3.2949e+00, -2.0632e+00, -1.0842e+00,  3.8667e+00, -4.9233e+00,\n",
      "        -4.4719e+00,  1.4897e+00, -1.9925e+00, -5.0145e+00,  4.8688e+00,\n",
      "         3.4179e+00, -3.1225e+00, -3.3827e+00, -2.3503e+00, -5.6035e-01,\n",
      "        -1.7340e+00, -2.0889e+00,  3.9123e-01,  7.4105e+00,  4.3279e+00,\n",
      "         1.2880e+00, -3.0574e+00, -3.1282e-01,  4.0478e+00,  2.9353e-01,\n",
      "        -1.8650e+00, -3.2571e+00,  5.1843e+00, -5.0219e+00,  4.9008e-01,\n",
      "        -2.3813e+00,  3.1718e+00, -4.1094e+00, -7.7047e+00,  1.3544e+00,\n",
      "         4.1686e+00, -2.2344e+00,  9.9851e+00,  7.2583e+00,  2.7500e+00,\n",
      "         3.1016e+00, -3.8355e+00, -3.2386e+00,  6.7120e+00,  4.1001e+00,\n",
      "         3.3082e+00,  4.2092e+00, -1.3627e+00,  5.7223e+00,  2.7738e+00,\n",
      "        -5.7553e+00, -1.7233e+00,  2.3039e+00,  3.3323e-01, -4.0872e+00,\n",
      "         1.9451e+00,  5.4706e+00, -1.2814e-01,  1.6041e+00, -2.7116e+00,\n",
      "         6.4094e+00,  2.0969e+00, -2.5715e+00, -1.0724e+00,  8.4452e+00,\n",
      "        -2.9047e+00, -7.1559e-01,  1.0002e+00,  3.4062e+00, -2.0334e-01,\n",
      "         2.2732e-01, -3.1752e+00, -3.3634e+00, -6.5274e-01,  9.6629e+00,\n",
      "         3.1738e+00, -9.7245e+00, -3.0113e-01,  2.8123e+00,  4.0509e+00,\n",
      "         5.1608e-01, -2.7976e+00, -4.0176e+00,  6.1981e-01, -4.4608e+00,\n",
      "         8.0998e+00, -4.2729e+00,  1.4686e+00,  2.7227e+00,  1.2631e+00,\n",
      "        -2.1092e+00,  1.7140e+00, -6.7823e+00,  6.8980e+00, -1.6280e+00,\n",
      "        -3.8437e+00, -5.4106e+00,  6.2556e+00,  2.6934e+00,  1.5199e+00,\n",
      "        -7.3314e+00,  3.1548e+00, -3.9446e+00, -1.1740e+00, -5.1045e+00,\n",
      "         1.3646e+00,  6.1397e+00,  4.3618e+00, -2.5729e-01, -3.6897e-01,\n",
      "         4.7251e+00,  4.7634e-01,  1.8215e+00, -2.1516e+00,  3.6727e+00,\n",
      "        -1.1475e+00, -2.6503e+00,  3.1847e+00,  4.2755e+00, -3.8686e+00,\n",
      "        -1.8565e+00,  2.7543e+00, -3.5417e+00,  5.7170e-01,  5.8162e+00,\n",
      "        -6.0792e-01, -5.5652e+00,  5.7914e+00,  1.4198e+00, -3.2205e+00,\n",
      "         2.2989e+00, -1.4120e-01, -3.6875e+00,  1.5675e+00, -2.1897e+00,\n",
      "         2.8670e+00, -1.8886e+00,  3.5918e+00, -1.1870e+00,  2.6905e+00,\n",
      "        -6.3051e-01,  4.2918e+00,  7.5812e-01,  2.4772e-01,  5.1785e-01,\n",
      "        -3.9748e+00,  5.3593e+00, -3.1866e+00,  5.0718e+00,  2.5495e+00,\n",
      "        -6.3212e-01, -3.4029e+00, -2.1900e+00,  2.1863e+00, -3.7755e-02,\n",
      "        -4.0826e+00,  2.6238e+00,  9.7899e+00,  5.8293e+00,  3.6448e+00,\n",
      "        -7.2764e+00,  1.0600e-01,  5.1786e+00,  1.0723e+00, -4.0616e+00,\n",
      "        -2.1304e+00,  5.7387e-01,  1.9304e+00,  4.9649e+00, -3.3315e-01,\n",
      "        -5.1604e+00,  1.8702e+00, -2.9451e+00,  3.4696e+00,  1.4624e+00,\n",
      "        -3.4567e+00, -2.1601e+00, -1.7772e+00, -6.7261e-01, -2.2673e+00,\n",
      "        -2.6888e+00, -1.7351e+00,  7.6955e+00, -2.7260e+00, -6.0990e+00,\n",
      "         4.6630e+00, -1.4322e+00,  1.9175e+00,  4.6483e+00,  7.2268e+00,\n",
      "         9.9589e-02, -2.6851e-01, -1.3116e+00, -3.6814e+00,  2.3830e+00,\n",
      "         3.8512e+00,  5.8422e+00,  4.1782e+00,  1.1719e-01,  3.0361e+00,\n",
      "        -1.2094e+00,  1.9002e+00, -2.0764e+00, -5.1201e-01,  4.6383e+00,\n",
      "        -1.4158e+00, -2.9361e-01,  6.7242e+00, -3.2070e+00, -1.5660e-01,\n",
      "         4.8738e+00,  3.4067e-01, -3.2068e+00,  8.1257e+00, -9.6805e-01,\n",
      "        -1.0940e+00,  7.5121e-01,  3.6947e+00,  3.2972e+00, -9.5196e-02,\n",
      "        -4.5848e-01, -8.7205e-01, -1.5549e+00, -2.6458e+00, -5.6087e+00,\n",
      "         1.6034e+00, -3.0322e+00,  3.3068e+00,  2.4960e+00,  3.7546e+00,\n",
      "         4.1376e+00, -3.0881e+00,  5.5949e-01,  8.5754e-01, -2.3999e+00,\n",
      "         8.2155e+00, -1.3638e+00,  1.3560e+00, -6.2807e+00, -1.1528e+00,\n",
      "        -6.3262e-01, -6.7930e+00,  3.8524e-01, -3.9740e+00,  2.7598e+00,\n",
      "        -6.0180e+00,  1.2198e+00,  1.6274e+00, -2.5818e-01,  2.2286e+00,\n",
      "        -3.9505e-01,  1.5963e+00, -3.2881e+00,  1.4620e+00, -2.5494e+00,\n",
      "        -1.0654e+01,  2.2111e+00,  3.4549e-02,  1.3166e+00, -1.8049e+00,\n",
      "        -9.3944e-01,  1.6400e+00, -8.8519e-01,  4.2903e+00, -1.6351e+00,\n",
      "         4.6491e+00,  3.8201e+00, -2.2017e+00,  1.7322e+00, -4.2772e+00,\n",
      "         3.1498e+00,  2.0918e+00,  1.0259e+01,  1.4810e+00,  1.3069e+00,\n",
      "         2.9908e+00,  5.6013e-01, -1.8177e+00,  2.1700e+00, -4.4305e+00,\n",
      "         4.9166e+00, -1.3779e+00, -4.7589e+00, -1.7665e+00, -5.0794e+00,\n",
      "        -7.5025e+00,  1.1686e+00,  5.3294e+00,  7.5543e+00,  1.5560e+00,\n",
      "        -3.8046e+00, -1.2945e+00,  1.8654e+00, -1.4736e+00, -2.6009e-02,\n",
      "        -2.0182e+00, -7.6507e+00, -4.8715e+00,  3.7355e+00, -2.4763e+00,\n",
      "         1.2203e+00, -5.3528e+00, -1.1344e+00, -4.8200e-01,  1.5985e-01,\n",
      "        -8.5924e-01,  2.6306e+00, -2.0628e+00, -1.2516e+00, -4.4414e+00,\n",
      "         9.3976e-01,  1.6312e-01, -2.3225e+00,  5.3463e+00,  1.0890e+00,\n",
      "         1.8292e+00,  4.0095e+00,  4.6297e+00, -2.7864e+00, -8.9147e-01,\n",
      "        -1.4158e+00, -1.5528e+00]), 'last_per_encoder_features': tensor([ 3.2338e+00,  2.3267e-01,  1.9298e+00,  3.1293e+00, -3.8693e-01,\n",
      "         1.1911e-01, -2.3682e+00, -3.6019e-01,  1.2491e-01, -1.0656e+00,\n",
      "         5.2936e+00,  2.7773e+00,  1.5649e+00, -6.4209e-01, -4.4660e-01,\n",
      "        -8.7474e-01, -7.2679e-01, -3.9458e+00, -1.1891e+00,  5.5661e+00,\n",
      "        -2.5080e+00,  1.3170e+00,  6.0586e-02, -2.5536e+00, -2.8127e+00,\n",
      "         1.4003e+00,  3.3015e+00, -1.3082e+00,  3.7491e-01,  3.7525e+00,\n",
      "         1.7888e+00,  8.5934e-01, -1.4472e+00, -2.7822e+00, -1.5573e+00,\n",
      "        -1.9809e+00,  6.4740e+00,  1.2897e+00, -4.5894e-01, -2.6831e+00,\n",
      "        -8.9856e-01,  2.1393e+00, -2.4102e+00, -6.9408e-01,  1.6904e+00,\n",
      "        -2.3151e+00, -2.8924e+00,  3.8132e+00, -2.4694e+00,  2.9607e+00,\n",
      "         1.1377e+00, -3.1545e+00, -3.1086e+00, -4.3732e+00,  3.7491e+00,\n",
      "        -7.4108e-01, -3.0854e+00, -4.4863e-01, -3.3211e+00,  1.3572e+00,\n",
      "        -4.3132e+00, -7.8063e-01, -1.8812e+00,  6.7955e-01, -3.0004e+00,\n",
      "         1.0218e-01,  3.6241e+00, -3.8128e+00, -2.3666e+00, -1.5517e+00,\n",
      "        -2.6904e+00,  1.7657e+00,  6.7718e-01,  2.3284e+00,  5.3629e-01,\n",
      "         3.7308e+00,  4.6973e-01,  1.1767e+00,  2.0338e+00, -2.2524e-01,\n",
      "         1.5862e+00, -1.6804e+00,  6.6731e-02,  1.3643e+00, -2.8057e+00,\n",
      "         2.0466e+00,  9.6028e-01, -1.6674e-01,  2.3412e+00, -4.5179e+00,\n",
      "         3.3901e+00,  1.6813e+00, -4.1837e-01,  4.0442e+00, -4.5519e+00,\n",
      "         4.1974e-01,  1.6527e+00,  1.3872e+00,  6.2810e-01, -4.0023e+00,\n",
      "        -8.0105e-01, -1.8720e+00,  3.4250e+00,  7.6286e-03, -3.6836e+00,\n",
      "         1.1063e+00, -3.1521e+00,  3.9879e-01,  1.7497e+00,  3.8681e+00,\n",
      "        -1.7927e+00,  9.6971e-01,  1.7850e+00,  1.0811e+00, -6.5036e-01,\n",
      "         5.2729e-01,  1.1369e+00, -4.5676e+00,  3.3883e+00,  1.3878e+00,\n",
      "        -3.2486e+00, -9.3917e-01, -3.4148e+00, -1.4130e+00, -1.6031e-01,\n",
      "        -2.0971e+00,  1.8944e+00,  5.3803e-02,  2.2753e+00, -1.1502e-01,\n",
      "        -3.7721e+00, -1.6567e+00, -2.4559e+00,  4.1099e+00,  1.5047e+00,\n",
      "         6.0008e-01,  2.7269e+00,  3.8545e+00, -7.4273e-02,  7.6416e-01,\n",
      "         4.6364e+00, -5.6938e-01, -4.9919e+00,  1.4771e+00, -1.9482e+00,\n",
      "         4.3250e+00, -2.5153e+00,  5.1857e+00,  3.3751e+00,  3.9504e+00,\n",
      "         2.2008e+00, -1.1230e-01,  3.0734e+00, -3.6183e+00, -5.8605e-01,\n",
      "        -3.3845e+00, -2.3121e+00,  1.2278e+00, -1.3076e+00,  1.4747e+00,\n",
      "         2.6751e+00, -5.1467e+00,  7.5568e-02,  5.3671e+00,  1.4516e+00,\n",
      "         3.7613e+00, -7.8310e-01,  1.4013e+00,  1.9185e+00,  5.1816e+00,\n",
      "         7.0182e-01,  1.6557e+00, -4.3582e+00, -3.8629e+00,  4.2693e+00,\n",
      "        -3.3388e+00, -5.9582e-01,  4.7503e+00,  8.2866e-01, -2.4502e+00,\n",
      "         1.9049e+00,  3.0588e+00,  6.9975e-01, -2.9076e+00,  9.0025e-01,\n",
      "        -3.4391e+00, -6.2399e+00, -3.2116e+00, -1.7095e+00,  1.3730e-01,\n",
      "        -6.3791e-01,  1.2658e+00, -2.1533e-01, -2.1612e+00, -2.6038e+00,\n",
      "        -7.2521e-02,  2.1140e+00, -3.7742e+00,  3.0219e+00, -3.9221e+00,\n",
      "         1.3807e+00,  6.6327e+00, -5.7396e+00, -7.2849e+00,  4.2359e-01,\n",
      "        -5.2356e+00,  8.9175e-02,  7.4388e-01,  1.0587e+00,  2.7084e-01,\n",
      "        -6.8275e+00, -1.5331e+00, -2.8741e+00,  5.0573e+00, -4.7391e-02,\n",
      "         7.6390e-01, -2.1694e+00, -2.1048e-02,  4.0565e+00, -2.6300e-01,\n",
      "        -2.9214e+00,  2.2646e+00,  1.3314e-01,  1.2463e+00,  7.4784e-01,\n",
      "        -3.2957e+00, -1.3732e+00, -2.3054e+00, -4.0863e+00, -3.9297e+00,\n",
      "        -1.8179e+00, -3.9794e+00, -4.0470e+00,  1.6607e+00, -2.1171e+00,\n",
      "         1.1920e+00,  1.5657e+00, -2.1325e+00,  1.1168e+00, -5.5560e+00,\n",
      "         1.2529e+00,  1.7944e+00, -4.9721e+00, -9.3786e-01,  8.9175e-01,\n",
      "         1.3876e+00, -2.2516e+00,  4.9051e+00,  9.7302e-01, -2.2149e+00,\n",
      "         1.9213e+00,  1.8117e+00,  2.0231e+00,  2.5926e+00, -4.2044e+00,\n",
      "         1.1225e+00,  2.8246e+00,  3.6709e+00, -2.6303e+00,  9.5788e-01,\n",
      "        -5.6983e+00,  3.6058e+00, -3.4928e+00,  2.1949e+00, -3.0186e+00,\n",
      "         1.5239e+00,  9.7444e-01, -1.8070e+00, -2.7498e+00,  2.9544e+00,\n",
      "        -1.1658e+00, -1.4650e+00,  1.8361e-01,  1.7581e+00, -5.9456e+00,\n",
      "        -2.0225e+00, -2.1435e+00,  2.3218e+00,  2.7579e+00,  2.1897e+00,\n",
      "        -4.9537e+00,  3.3348e+00, -1.8958e+00, -4.9453e-01, -2.2985e-01,\n",
      "        -2.7471e+00,  2.7585e+00, -3.1399e+00, -1.2538e+00, -1.8937e+00,\n",
      "         3.5548e+00, -8.5176e-02,  3.0890e+00, -4.9812e+00,  3.5201e-01,\n",
      "        -3.6417e-01,  1.9485e+00,  1.0121e+00, -1.1241e+00,  2.8581e+00,\n",
      "        -1.9528e+00, -6.1504e-01,  4.6464e+00, -4.6865e+00, -6.6013e-01,\n",
      "         5.9946e+00,  1.2056e+00,  1.8354e-01, -3.7932e+00,  4.7302e+00,\n",
      "         1.2248e-01,  1.3842e-01, -1.3366e+00,  4.1323e-01, -5.8237e-01,\n",
      "         2.9351e+00, -3.7018e+00,  2.6084e-01,  1.0671e+00,  2.3701e+00,\n",
      "        -3.6357e-01,  4.0226e+00,  1.2673e+00, -3.7144e+00,  3.6318e+00,\n",
      "         6.4479e+00, -9.1351e-01, -2.2054e+00,  2.2780e+00, -7.8682e+00,\n",
      "        -3.5341e+00, -1.1439e+00, -1.3584e+00,  1.1768e+00,  6.3366e-01,\n",
      "        -1.2893e+00,  2.3888e-02, -1.5118e+00, -1.5829e+00,  5.6466e+00,\n",
      "        -2.6070e+00,  3.2595e-01,  2.7478e+00, -2.1465e+00,  1.1823e+01,\n",
      "        -1.9064e+00,  3.4033e+00, -5.9479e-01,  6.2098e-02, -8.2261e-01,\n",
      "        -1.3202e+00, -4.4438e+00,  2.9334e+00, -5.3838e-01,  7.0116e-01,\n",
      "        -2.6877e+00, -1.5389e+00,  1.4680e-01,  1.7785e+00, -3.1061e+00,\n",
      "        -2.3576e+00,  1.0294e+00, -5.2095e+00, -3.0123e+00,  1.8601e+00,\n",
      "         7.9302e-01, -1.0311e+00,  2.8714e+00, -1.6268e+00,  4.8312e-01,\n",
      "        -3.8697e+00, -5.9141e+00,  4.5940e+00, -9.7427e-01, -1.4188e+00,\n",
      "         3.1737e-01,  3.1455e+00, -4.5668e-02, -1.8410e+00,  4.4376e+00,\n",
      "        -1.0471e+00, -1.1363e-01,  9.2275e-01, -1.2525e+00, -2.2935e-01,\n",
      "         3.8577e+00, -1.4300e+00, -1.2229e+00, -5.1959e+00, -2.8758e-01,\n",
      "         2.8194e-01, -3.0743e+00, -3.9975e+00, -1.0507e+00,  1.6811e+00,\n",
      "         1.9032e+00, -8.7577e-01,  1.3185e-01,  2.0499e+00,  1.9730e+00,\n",
      "        -1.4967e+00,  1.8372e-01, -3.1571e+00,  2.2138e+00, -2.8808e+00,\n",
      "         2.3193e+00,  3.3449e+00,  1.5074e+00,  5.0530e-01, -4.3380e+00,\n",
      "         3.4059e+00, -1.3119e-01,  5.4440e-02,  2.3663e+00,  3.0585e+00,\n",
      "         2.6161e+00,  3.9420e-01,  1.6687e+00,  2.6000e+00,  3.1212e+00,\n",
      "         2.5500e+00,  2.0428e+00,  1.1049e+00, -4.3755e+00,  2.6420e+00,\n",
      "        -2.0083e+00,  3.5497e+00,  1.3036e+00,  2.5543e-01, -3.7884e+00,\n",
      "        -2.2399e+00, -1.7780e+00, -2.9948e+00, -1.4503e+00,  2.6964e+00,\n",
      "         1.3744e-01, -1.1253e+00,  1.4716e+00,  3.5283e+00, -2.2030e+00,\n",
      "        -4.8368e+00,  2.0534e+00,  2.5306e-01, -4.7744e+00,  5.0573e+00,\n",
      "         2.7411e-01,  1.3691e+00, -1.3658e+00,  2.0123e+00,  2.2884e+00,\n",
      "         8.4668e-01,  2.0074e+00,  4.1866e+00,  1.5134e+00,  1.2394e+00,\n",
      "        -2.3605e+00, -1.8505e+00,  2.2327e+00,  1.0555e+00,  6.6356e+00,\n",
      "        -8.4205e-01,  4.2231e-01, -2.7072e-02,  1.8639e+00,  3.6851e-01,\n",
      "        -2.1224e+00, -1.8655e+00, -4.5021e-01, -2.4667e+00,  3.7924e+00,\n",
      "         1.8029e+00,  7.3143e-01, -3.7846e+00,  1.3289e+00,  2.2093e+00,\n",
      "         4.8800e-01, -1.9338e+00,  2.3060e+00,  5.6123e+00,  1.2356e+00,\n",
      "         6.9255e+00, -4.2587e+00,  2.8779e+00,  9.5974e-01,  4.9084e+00,\n",
      "         6.4139e+00,  1.7226e+00,  1.9074e+00,  1.9187e+00, -1.2965e+00,\n",
      "         9.2510e-01, -2.3302e+00, -6.8837e-02, -3.9010e+00, -2.2931e+00,\n",
      "        -6.8565e-01, -3.5461e+00, -3.3087e+00, -2.4025e+00, -7.1152e-01,\n",
      "         2.7465e-01, -4.3777e+00,  1.8202e+00, -2.4710e+00,  1.8866e+00,\n",
      "        -3.9067e+00,  9.0395e-01, -1.1061e+00, -3.8994e+00,  4.9526e-01,\n",
      "         2.0814e+00, -2.7817e-01])}, 'scene': {'emotion_logits': tensor([-1.4333,  0.7245,  0.2676, -0.8584,  0.4059, -0.1515,  1.7094]), 'personality_scores': tensor([0.6100, 0.5503, 0.4974, 0.6232, 0.5360]), 'last_emo_encoder_features': tensor([ 2.3787e-01, -3.8834e+00, -7.1912e+00,  5.3321e+00,  6.3292e+00,\n",
      "        -1.5183e+00,  3.9924e+00, -3.5136e+00, -6.4992e+00,  3.3300e+00,\n",
      "         1.3883e+00,  1.5157e+00,  5.1890e-02,  3.9729e+00,  2.4476e+00,\n",
      "         4.8612e+00, -3.5312e+00,  2.5139e+00, -2.2752e+00, -5.1269e+00,\n",
      "        -1.7450e+00,  1.7746e+00, -5.2801e+00,  8.3871e+00,  1.3502e+00,\n",
      "         2.1368e-01,  6.9356e+00, -2.4151e+00,  5.6247e+00, -7.3593e+00,\n",
      "         3.0710e-01,  3.1934e+00, -2.5554e+00,  3.7122e+00, -6.0992e+00,\n",
      "        -7.3464e+00,  2.1698e+00,  1.3134e+00,  4.6045e+00,  1.0322e+01,\n",
      "        -1.9648e+00, -5.6326e+00, -2.3873e+00,  5.3190e+00, -5.2574e+00,\n",
      "         4.2398e+00,  3.9525e+00,  4.8422e+00, -7.8822e+00, -9.0932e-01,\n",
      "         7.8881e+00, -1.7802e+00, -1.2834e+01, -7.6085e+00,  2.1936e+00,\n",
      "        -3.3690e+00, -2.2804e+00, -3.7461e+00, -1.4956e+00,  5.5032e+00,\n",
      "        -2.8310e+00, -2.9911e+00,  5.4648e+00, -6.1285e+00, -9.3055e+00,\n",
      "        -1.0810e+00, -5.6580e+00, -3.0876e+00, -1.4306e+01,  3.3087e-01,\n",
      "         6.0525e+00,  8.4826e-01,  7.1211e-01,  9.8361e+00, -1.6598e+00,\n",
      "        -1.1091e+00,  3.2384e+00, -5.1005e+00, -1.4814e+00, -6.9780e-01,\n",
      "         8.3499e+00,  7.3279e+00,  5.1125e+00, -1.6738e+00,  9.9289e+00,\n",
      "        -3.4881e+00, -3.1973e+00, -3.2181e+00, -3.6356e+00, -5.5434e+00,\n",
      "         9.2431e-01, -1.8493e+00, -1.6358e-01, -3.1843e+00,  8.2259e-02,\n",
      "         3.9277e+00,  1.0521e+01, -4.7876e+00, -6.2171e+00,  4.7177e+00,\n",
      "        -4.1876e+00, -2.6379e+00, -6.1906e+00,  3.0403e+00,  5.3519e+00,\n",
      "         5.0244e+00,  4.2737e+00, -3.6309e+00,  1.8119e+00,  5.0457e+00,\n",
      "         4.7204e+00, -3.2511e+00, -2.4966e+00, -1.0271e+01,  7.3345e+00,\n",
      "        -8.1386e+00,  2.8831e+00,  2.3173e+00, -1.4867e+00, -7.8071e-01,\n",
      "         4.6816e+00, -8.2825e+00, -2.3328e+00, -1.3373e-01, -6.8470e+00,\n",
      "        -9.0404e+00, -8.0676e+00, -2.2382e+00,  6.6907e+00,  2.0147e-01,\n",
      "         5.4555e-01, -1.8269e+00,  8.8182e-01,  6.1917e+00, -5.3116e+00,\n",
      "        -6.1779e+00,  2.3655e+00,  2.5059e+00, -2.3998e+00, -4.4474e+00,\n",
      "         5.7433e+00, -1.0222e+01,  6.8318e+00, -4.5264e+00, -3.4410e-01,\n",
      "        -4.2875e+00,  4.0702e+00,  9.3599e-02,  1.8182e+00, -4.6854e+00,\n",
      "         2.0914e+00,  1.1476e+00,  3.5378e+00,  3.2371e-01,  3.8176e+00,\n",
      "        -9.9156e-01,  4.0436e-01, -6.5355e+00, -2.5413e+00, -2.0900e+00,\n",
      "         5.3924e+00,  1.1613e+00,  1.0549e+01, -3.0336e+00,  1.1147e+00,\n",
      "        -3.6649e+00, -4.5883e+00, -1.0492e+01,  8.9544e+00, -1.5124e+00,\n",
      "        -7.7820e-01, -1.3490e+00, -6.6801e+00,  3.7681e-01, -1.8330e+00,\n",
      "        -9.6318e+00,  4.2866e+00, -2.9616e-01,  5.5267e+00, -7.5601e-01,\n",
      "         4.5164e-01,  6.4039e+00, -7.6750e-01,  9.4643e+00, -8.9231e+00,\n",
      "        -2.3442e+00, -8.5921e+00, -1.1831e+01, -8.0583e+00, -6.1528e+00,\n",
      "        -1.8007e+00,  8.8117e-01,  1.0867e+00,  4.4776e+00,  5.3892e+00,\n",
      "        -4.8403e+00,  5.1348e+00,  6.9359e+00,  3.1614e+00,  1.3383e+00,\n",
      "        -3.6373e+00, -2.5110e+00,  4.5568e+00,  3.5242e+00,  1.1997e+01,\n",
      "        -6.4365e+00,  3.2448e+00, -4.8026e+00, -7.1843e+00, -8.5060e+00,\n",
      "         8.4152e+00,  5.9144e+00, -4.1653e+00, -6.2699e+00, -5.2620e+00,\n",
      "        -2.3535e+00, -3.3096e+00, -1.1033e+00, -2.8798e+00,  8.8135e+00,\n",
      "        -3.3020e+00,  1.0644e+00,  6.5499e-01,  3.8572e+00,  8.0724e-01,\n",
      "         2.4111e+00,  7.4230e+00, -7.4700e+00, -2.2926e+00, -2.7499e+00,\n",
      "        -1.4253e+00,  1.7071e+00,  9.2847e-01,  4.0783e-01,  4.6657e+00,\n",
      "         1.1054e+00,  6.3835e+00,  8.0056e+00,  3.4464e+00,  3.7628e+00,\n",
      "        -2.0915e+00,  4.3032e+00, -3.2040e+00,  2.8909e+00, -5.4711e+00,\n",
      "        -2.7930e+00, -4.7009e+00,  6.1352e+00,  2.3082e-01, -5.4912e+00,\n",
      "         6.8037e+00, -2.5187e+00, -3.3790e+00, -8.6859e+00,  3.7653e+00,\n",
      "         1.0826e+01, -2.0312e-01,  3.4327e+00, -2.2023e+00,  6.1486e+00,\n",
      "        -1.9101e+00,  5.9995e-01, -6.2679e-01, -4.5138e-01,  3.3159e+00,\n",
      "        -2.4228e+00,  2.3850e+00, -1.4199e+01,  4.0967e+00, -3.3672e+00,\n",
      "        -1.6761e+01, -7.6468e+00, -3.4368e-02,  8.2079e+00, -1.4754e-01,\n",
      "        -7.8879e+00, -1.3252e-01, -1.5666e-01, -2.7280e+00,  1.1280e+01,\n",
      "        -6.5206e+00, -7.6729e+00,  3.8400e+00, -1.6883e+00,  4.6609e+00,\n",
      "        -8.4115e-02,  1.3188e+01, -6.1914e+00, -1.9045e+00,  2.1923e+00,\n",
      "        -4.1606e+00, -6.7669e+00, -9.6703e+00,  1.0640e+01,  7.1485e+00,\n",
      "         3.1097e+00, -8.7797e-01, -7.8766e+00,  4.2617e+00,  3.1649e+00,\n",
      "        -1.3917e+01, -3.7073e+00, -7.3794e+00,  3.1572e+00,  2.6021e-01,\n",
      "        -5.9029e+00,  9.9146e+00,  1.0009e+01,  1.1725e+01, -5.8241e-01,\n",
      "        -2.1396e+00,  6.7563e+00, -1.0472e+01,  8.8183e+00,  5.2901e+00,\n",
      "         1.8175e+00,  6.9565e-01, -7.4367e-01, -9.9724e-01,  9.7592e+00,\n",
      "         5.1865e+00, -6.9197e+00, -4.7459e+00, -8.6184e-02, -2.4251e+00,\n",
      "        -2.2968e+00, -4.0255e+00,  8.2761e+00, -6.1851e+00, -1.3453e+00,\n",
      "         3.3700e+00,  1.0880e+01, -9.8208e+00, -3.2348e+00,  1.8334e+00,\n",
      "         9.7019e+00,  5.9807e+00,  3.4006e+00, -2.3107e+00,  7.8787e+00,\n",
      "        -2.2966e+00, -1.2777e+01, -8.5967e-01, -6.4830e+00,  8.1516e-01,\n",
      "         5.3417e+00,  9.3494e+00,  1.2564e+00,  1.2110e+00,  2.7222e-01,\n",
      "         5.8424e+00,  4.6230e+00, -2.5580e+00,  2.6289e+00,  6.5890e+00,\n",
      "        -1.1180e+00,  9.9163e+00,  4.5176e+00, -2.8784e+00, -3.0252e+00,\n",
      "        -2.1177e+00, -8.8051e+00,  2.7545e+00,  1.0904e+00, -1.1878e+01,\n",
      "        -1.3318e+00, -5.7813e+00,  1.5563e+00, -1.0464e+00,  1.0525e+00,\n",
      "        -1.7684e-01,  1.7452e+00,  1.9554e+00,  4.2497e+00,  5.8221e+00,\n",
      "         4.2908e+00,  2.4817e+00,  2.0982e+00, -8.4228e-01, -4.2798e+00,\n",
      "         7.0708e+00, -4.3140e+00, -2.7967e+00, -5.9767e+00, -1.1393e+00,\n",
      "        -7.3027e+00, -6.9269e-01, -1.2012e+01, -3.7576e+00, -2.9896e+00,\n",
      "        -9.4580e+00,  1.0103e+00,  1.0660e+01,  4.1728e-01,  1.7727e+00,\n",
      "        -6.1872e+00, -3.7642e+00, -2.4434e+00, -7.8747e+00, -9.5886e+00,\n",
      "        -3.8489e+00, -1.4877e+00, -1.1085e+00, -5.3650e+00, -2.7637e+00,\n",
      "        -9.1552e+00, -7.1608e+00,  2.3885e+00, -4.0454e+00, -1.2996e-02,\n",
      "         7.0234e-01,  1.8636e+00, -6.2101e+00, -1.1594e+01, -1.7261e+00,\n",
      "        -6.2137e+00,  6.1855e-02,  1.7723e+00, -5.4557e+00, -7.8594e+00,\n",
      "        -1.4333e+00,  7.6275e+00,  2.0836e+00, -9.0407e+00,  5.2556e+00,\n",
      "        -4.1504e+00, -5.1819e+00, -2.8227e+00, -8.6919e+00,  5.6820e+00,\n",
      "         8.4793e+00,  2.8134e+00,  2.5828e+00,  4.4889e+00,  1.0020e+00,\n",
      "         4.2878e+00,  3.1450e-01,  8.0892e-01,  1.5304e+00, -1.0117e+00,\n",
      "        -6.6626e+00, -5.9094e+00, -9.6859e+00,  9.6772e-02,  1.0876e-01,\n",
      "         2.4252e+00, -4.6321e+00,  2.8069e+00, -2.0257e+00,  1.0270e+01,\n",
      "        -1.0158e+01, -3.9882e-01, -1.1430e+00,  3.3333e-01,  3.5036e+00,\n",
      "         2.5826e+00,  8.3437e+00, -4.3181e+00, -3.3626e+00,  1.1668e+01,\n",
      "        -3.2377e+00,  4.7443e+00, -7.3465e+00,  5.7454e+00, -8.9468e+00,\n",
      "        -4.0794e+00, -6.6916e+00,  6.6732e+00,  1.5221e+00,  4.2347e+00,\n",
      "        -6.9635e+00,  3.3945e+00,  7.3129e+00, -1.3718e+00,  5.0162e+00,\n",
      "         9.2304e+00,  3.7794e+00, -1.1852e+01, -1.0663e+01,  6.0260e+00,\n",
      "         5.6517e+00,  1.1836e+00,  2.8217e+00,  6.1433e+00,  1.0218e+00,\n",
      "        -5.6199e-01,  8.1502e+00, -6.3567e-01,  6.4856e+00,  1.9782e+00,\n",
      "         2.0726e+00,  2.5245e-01,  2.1677e+00,  4.4590e+00,  5.0634e+00,\n",
      "         6.3268e+00, -1.0423e+01,  5.0981e+00, -3.7986e-01,  6.6475e+00,\n",
      "         1.0178e+00,  9.8995e-01,  3.3177e+00,  4.0010e+00, -1.2676e+01,\n",
      "         1.6655e+01, -2.0564e+00, -6.3273e+00,  2.2476e+00, -5.1166e+00,\n",
      "        -1.6911e+00, -3.6893e+00, -2.0025e+00,  2.7875e+00,  9.5758e+00,\n",
      "         2.6204e+00,  8.6320e+00, -8.3483e-01, -6.8274e+00,  6.8998e+00,\n",
      "        -7.9835e+00,  9.5381e-01, -1.2970e+00,  7.3481e+00, -4.5430e+00,\n",
      "         2.1745e+00,  5.8327e+00,  3.0674e+00,  3.7625e+00,  4.7538e+00,\n",
      "         2.6105e+00,  5.8152e+00, -4.9078e+00,  2.5384e+00,  1.3249e+00,\n",
      "        -1.5365e+00,  6.1200e+00,  3.6077e+00, -1.4039e+01,  1.3885e+01,\n",
      "        -1.7664e-02, -3.4103e+00, -7.2147e+00,  1.0290e+01, -7.6213e+00,\n",
      "        -2.6288e+00,  1.4286e+00, -8.7450e+00, -6.3688e+00,  2.4375e+00,\n",
      "         7.2051e+00, -6.2090e-01, -2.0419e+00,  4.3989e+00, -9.1522e-01,\n",
      "         2.9667e+00,  2.4220e+00,  8.9887e+00,  4.2168e+00,  1.7405e+00,\n",
      "        -9.4571e+00,  5.4345e+00, -2.4910e+00,  7.8425e-01, -5.8418e+00,\n",
      "         5.5463e-01,  5.1685e+00, -1.4832e+00,  2.5930e+00,  1.6321e+00,\n",
      "         1.4644e+00,  2.9812e+00, -1.3767e+00, -2.5237e-01, -8.2222e+00,\n",
      "         6.3669e-01,  2.6061e+00,  7.3695e+00, -1.1048e+01, -4.6053e+00,\n",
      "        -4.9406e-01,  5.3344e-01, -4.4758e+00,  5.3481e+00, -1.0148e+00,\n",
      "         1.0995e+01,  3.2176e+00,  5.3637e+00,  1.8544e+00, -8.7966e+00,\n",
      "         5.7315e-01, -6.9909e-01, -7.8226e+00, -1.5315e+00, -5.3935e+00,\n",
      "         1.8618e+00, -3.5726e+00,  6.3574e+00, -4.0371e+00, -4.3491e+00,\n",
      "         3.9022e+00, -5.6799e+00,  2.2404e+00,  1.1779e+00,  2.4978e+00,\n",
      "         8.8711e+00, -1.2098e+00, -4.0397e-01, -2.7559e+00, -4.2358e+00,\n",
      "         1.6956e+00, -4.0048e+00, -7.5931e-02,  3.8934e+00, -1.6308e+00,\n",
      "        -3.3488e+00, -6.1408e+00,  3.0229e+00,  8.5581e+00, -6.0708e+00,\n",
      "         1.2970e+01,  1.0041e+00,  5.5108e+00, -4.2719e+00, -8.6883e+00,\n",
      "         4.7743e+00, -9.9884e+00, -1.6041e+00,  1.4886e+00, -2.3462e+00,\n",
      "        -1.8657e+00, -2.4336e+00,  1.4318e+00, -8.1583e-01, -1.7606e+00,\n",
      "        -2.8726e+00, -1.0231e+00, -2.4061e+00, -3.6037e+00,  5.9612e+00,\n",
      "        -3.9139e+00, -1.0272e+01,  2.6960e+00,  1.2882e+01,  4.0967e+00,\n",
      "        -5.6563e+00,  2.2516e+00,  4.0383e+00,  2.6991e+00,  8.7077e+00,\n",
      "        -5.5376e+00,  7.8236e+00,  8.7870e+00,  1.2516e+01,  3.7844e+00,\n",
      "        -4.7775e-01,  6.1582e+00,  5.5258e+00, -1.9868e+00, -6.0468e+00,\n",
      "         3.9003e+00,  1.2224e+01,  2.1782e+00,  5.8556e+00, -6.1916e+00,\n",
      "         8.1870e-01, -3.6082e+00, -3.6370e+00,  1.2586e+01, -3.1409e+00,\n",
      "         3.5918e+00,  4.0803e+00, -9.6079e+00,  4.5173e-01,  9.5448e+00,\n",
      "         2.5711e+00, -1.1686e+00, -4.8172e-02, -3.1872e-01, -1.0429e+00,\n",
      "         8.8244e+00, -6.0428e+00,  6.3701e+00,  1.0094e+00,  1.0790e+00,\n",
      "         3.9488e+00, -3.7748e+00,  4.4448e+00, -9.3186e+00,  2.1814e+00,\n",
      "        -2.9024e+00,  6.3203e-02,  5.4036e+00,  4.3538e+00,  1.6868e+00,\n",
      "        -1.4195e+00, -8.7651e+00,  5.0847e+00, -5.7335e+00, -1.8023e+00,\n",
      "        -9.0781e+00, -2.6553e-01, -3.3247e+00,  1.7621e+00, -9.7558e+00,\n",
      "         6.2613e+00,  4.8260e+00,  4.1239e+00, -5.3657e+00,  2.6537e+00,\n",
      "        -3.8792e+00,  3.4451e+00, -3.9507e+00, -1.9084e+00, -8.3392e+00,\n",
      "        -8.3460e+00,  3.2348e+00,  8.4944e-01,  8.4488e+00, -6.9818e-03,\n",
      "        -9.1890e+00, -1.1923e+00,  1.3151e+00, -5.7928e+00, -2.0487e+00,\n",
      "         8.4857e+00, -4.3166e+00, -9.7413e-01, -1.1084e+00,  5.7486e-02,\n",
      "         2.8036e-01, -2.6529e+00, -3.1201e+00, -1.9452e+00, -2.0102e+00,\n",
      "        -9.6492e-01, -6.0166e-01,  1.0709e+01, -9.5378e+00, -1.8367e+00,\n",
      "        -5.8738e+00,  9.3012e+00,  1.3789e+01, -2.3880e+00,  4.3237e+00,\n",
      "         4.5467e+00,  6.3141e+00,  1.6710e+00,  6.3429e+00, -3.4105e+00,\n",
      "         6.0107e+00,  1.3215e+01,  3.1614e+00,  2.9405e-01,  1.4334e+00,\n",
      "        -2.4327e+00,  3.9065e+00,  3.1479e+00,  9.4400e+00, -4.8290e+00,\n",
      "        -6.9001e+00,  3.8859e+00, -9.5621e-01, -2.0298e-01, -2.0547e+00,\n",
      "        -6.5331e+00,  9.2660e-01, -1.4366e+01]), 'last_per_encoder_features': tensor([-1.0079e+01,  2.9155e+00, -4.1954e+00, -2.4917e+00,  3.6412e+00,\n",
      "        -1.7523e+00, -5.5399e+00, -9.1149e-01, -1.7929e+00, -2.1998e+00,\n",
      "        -3.4728e+00, -2.5975e+00, -2.8647e+00, -7.4567e+00,  2.5412e-01,\n",
      "        -2.2627e+00, -4.4851e+00,  1.2590e+00,  1.1041e-01, -2.2187e+00,\n",
      "         5.3155e+00, -3.8029e-02, -1.2715e+01,  5.3149e+00, -6.9754e-01,\n",
      "         6.0376e+00,  3.2892e+00,  3.5746e+00, -2.9349e+00,  5.1487e+00,\n",
      "        -2.4690e+00, -1.8876e+00,  2.4121e+00,  3.1189e+00, -2.7554e+00,\n",
      "         1.9466e+00, -2.1079e+00,  2.0291e+00,  6.9235e+00,  5.2300e-01,\n",
      "        -7.9751e+00, -3.4787e+00, -3.5319e+00, -7.0688e+00,  4.2677e+00,\n",
      "         1.8289e+00,  3.9868e+00,  1.1189e+00, -6.8893e-01, -4.1910e-01,\n",
      "        -6.7827e+00,  1.7373e+00, -9.3519e+00, -6.9381e+00,  4.3950e+00,\n",
      "         1.9485e+00,  4.1381e+00, -7.1808e-02, -4.2620e+00,  6.0565e-01,\n",
      "         1.7443e+00, -1.2201e+01,  4.7155e+00,  2.9244e+00, -3.5750e+00,\n",
      "         3.3379e+00,  2.9972e+00,  4.4150e+00,  2.9294e+00,  6.0864e+00,\n",
      "        -4.7239e-01, -1.2821e+00, -4.1894e+00, -5.7459e-01,  5.6957e+00,\n",
      "         7.4972e+00, -5.7049e+00, -1.9128e+00, -1.1967e+01, -1.0975e+00,\n",
      "        -4.3681e+00, -2.6959e+00,  2.4519e-01, -3.3275e+00, -6.5593e-01,\n",
      "         4.5439e+00, -8.4673e+00,  4.2297e+00,  2.9913e+00, -9.8971e+00,\n",
      "        -1.9554e-02, -8.9192e+00, -5.6847e-01, -4.0654e+00, -2.6646e+00,\n",
      "        -5.4103e+00, -9.6924e+00, -4.4935e+00, -1.3544e+00,  3.4089e+00,\n",
      "         4.2311e+00, -4.2349e+00,  6.2168e+00, -4.3542e+00,  1.1235e+00,\n",
      "         3.9927e+00,  6.3132e+00, -9.7299e-01, -4.9124e+00,  1.7469e+00,\n",
      "         6.6689e+00,  1.3913e+00, -4.3118e+00,  5.2006e-01,  6.4041e+00,\n",
      "        -8.0058e+00,  1.0746e+00, -1.6602e+00,  7.7346e+00,  2.0305e+00,\n",
      "         4.7837e+00, -9.1402e-01, -2.1465e+00,  8.2245e-01, -3.5189e+00,\n",
      "        -2.3320e+00,  7.5443e+00, -2.0450e+00, -1.8766e+00,  3.0040e+00,\n",
      "         5.7866e-01, -4.9976e+00, -2.7760e-01, -4.9023e+00, -6.3192e+00,\n",
      "        -1.3560e+00, -9.9203e+00, -1.1500e+01, -7.4354e-03,  3.8488e+00,\n",
      "         1.4185e+00, -3.6404e+00,  1.3103e+01, -1.2346e-01, -1.1764e+01,\n",
      "        -5.3660e+00, -7.1108e+00,  9.9225e-01,  1.2177e+01, -7.3531e+00,\n",
      "         1.1753e+00, -5.0549e+00, -9.5461e-01,  3.2593e+00,  3.5030e+00,\n",
      "         1.0364e-01, -6.3504e+00, -7.4612e+00, -4.5907e+00,  1.6883e+00,\n",
      "         4.5138e+00, -2.9435e+00,  1.3296e+00,  5.3060e+00,  8.9975e-01,\n",
      "        -6.5242e+00, -2.5203e+00,  2.0432e+00,  5.8720e-02,  4.6742e+00,\n",
      "        -3.8783e+00, -1.9073e+00, -9.1184e-03,  3.5182e+00,  6.0409e-01,\n",
      "         1.2120e-01,  8.5030e+00, -4.3152e-01, -6.5115e+00, -7.5184e+00,\n",
      "         1.3175e+01, -9.8047e-01,  3.3232e+00,  6.8978e+00,  6.5943e-01,\n",
      "         7.1717e-01,  3.0076e+00, -6.6217e+00,  4.3328e+00,  9.8964e+00,\n",
      "         9.0186e+00,  4.4809e+00, -4.1182e+00, -5.0461e+00, -9.4469e-01,\n",
      "        -3.1796e+00, -3.1924e-01,  5.9478e+00, -1.1675e+00, -3.4984e+00,\n",
      "        -2.1468e+00,  1.4056e-01,  7.3061e+00,  4.5638e+00, -8.0359e-01,\n",
      "         1.1512e+00,  1.0624e+00, -3.8957e+00, -2.0937e-01, -7.7410e-01,\n",
      "         1.9600e+00,  5.0869e-01, -3.8912e+00, -5.3181e+00,  9.1983e+00,\n",
      "         1.1948e+00,  6.8131e+00, -4.0197e+00,  6.3676e+00,  6.6814e-01,\n",
      "        -2.2782e+00, -4.6407e+00,  7.9976e+00,  1.5078e-03,  6.2491e+00,\n",
      "         1.6277e+00, -4.2905e+00,  3.9895e+00,  1.1564e+00,  1.6725e+00,\n",
      "        -3.3988e-01,  2.3487e-01,  2.3137e+00,  3.2055e+00, -2.5614e+00,\n",
      "        -6.2257e+00, -3.4862e+00,  6.1842e-01, -2.5337e-01,  2.4179e+00,\n",
      "         1.0395e+01, -1.0511e+01, -1.7698e+00, -1.2742e+00,  3.3799e+00,\n",
      "         6.3335e+00, -2.0555e+00, -3.7696e+00, -6.2405e+00,  3.3536e+00,\n",
      "         6.0006e+00, -4.2116e-01, -1.4156e+00,  1.2132e+00, -7.4987e+00,\n",
      "         1.0727e+01,  3.9252e+00, -2.2865e-02,  3.4125e+00, -4.8078e+00,\n",
      "        -2.2488e-01,  6.7128e-01,  1.0756e+00, -2.2097e+00, -3.9168e+00,\n",
      "        -3.0231e+00,  5.9489e+00,  1.8459e+00,  6.8214e+00, -1.3110e+00,\n",
      "        -1.3717e+00,  2.8867e+00,  7.1667e+00, -2.9858e+00,  2.3666e+00,\n",
      "        -5.4298e+00,  1.4686e-01,  4.8979e+00, -4.6937e+00, -1.5482e+00,\n",
      "        -1.9569e+00,  3.9718e+00, -4.8561e+00, -4.8697e+00,  2.2008e+00,\n",
      "        -9.5520e+00,  8.9195e-01, -2.1908e+00,  1.1687e+01,  4.8186e+00,\n",
      "         5.1032e+00,  2.5232e+00,  2.2995e+00, -5.1799e+00, -4.5348e+00,\n",
      "         8.1746e+00,  1.8391e+00, -4.5937e+00, -5.8388e+00, -6.2387e+00,\n",
      "        -8.1238e+00, -8.5082e-01,  7.3760e+00,  5.7515e+00, -6.7138e+00,\n",
      "        -3.8682e+00, -2.3334e+00,  2.4963e+00,  2.9068e-01,  3.1797e-01,\n",
      "         3.6475e-01,  3.7657e+00, -1.1861e-01,  6.6105e+00,  3.9459e+00,\n",
      "        -1.6686e+00, -3.0625e+00, -2.4927e+00,  1.3261e+00,  6.9836e+00,\n",
      "         1.5561e+00, -7.8775e-01, -1.2599e-01,  3.5080e+00,  4.1035e+00,\n",
      "        -6.0749e+00,  2.8163e+00, -8.0009e-01, -1.5545e+00,  1.8709e+00,\n",
      "         2.2479e+00, -5.1186e+00, -4.8471e+00, -1.7140e+00, -4.7540e+00,\n",
      "         2.0400e+00,  2.1510e-01,  8.3550e-01,  7.2478e-01,  4.6791e-01,\n",
      "        -5.6867e+00, -6.7494e+00,  5.7889e+00,  6.0867e+00,  5.9043e+00,\n",
      "         7.4780e+00, -4.3748e-01,  3.6545e+00, -3.9576e+00, -5.5238e+00,\n",
      "         4.6001e+00, -7.9374e+00, -6.4066e-01,  1.5825e+00, -4.8892e+00,\n",
      "         5.4220e+00, -1.6381e+00, -6.0520e+00,  4.2351e+00,  1.5452e+00,\n",
      "        -1.2869e+00,  6.9509e-01,  4.8280e-01, -2.8673e+00, -1.7430e+00,\n",
      "        -5.3874e+00, -5.0257e-01, -3.5964e+00, -1.4988e+00, -9.3882e+00,\n",
      "        -2.1293e+00,  3.5110e+00,  1.7807e+00,  9.4149e-01, -2.2054e+00,\n",
      "        -2.9870e+00, -1.7639e+00, -2.8895e+00,  4.1761e+00,  4.4474e-01,\n",
      "         4.2251e+00, -7.4885e+00,  2.3097e+00, -1.9600e+00, -3.3451e+00,\n",
      "        -7.5039e-01,  4.0444e+00, -8.2884e+00,  1.2641e+00,  2.4458e+00,\n",
      "        -7.7911e-01, -1.1043e+01, -9.3978e+00, -4.4462e+00,  1.8801e+00,\n",
      "         7.2047e+00, -9.4767e+00,  8.6167e+00,  3.8799e+00, -7.3834e-01,\n",
      "        -2.2369e+00, -4.6751e-02,  6.5024e-01,  8.9079e-01, -4.0577e+00,\n",
      "         4.6902e+00,  5.1650e+00,  2.3280e-01,  6.4196e+00,  3.4891e+00,\n",
      "        -5.2933e+00,  3.7874e+00, -1.9033e-02,  1.9205e+00, -2.6620e+00,\n",
      "         4.5240e+00, -8.2425e+00,  3.8450e+00, -3.3491e+00, -4.1970e+00,\n",
      "         1.6880e+00,  3.6000e+00, -3.1377e+00,  1.5141e+00,  1.8200e+00,\n",
      "         5.8746e+00, -2.4835e+00,  1.8183e+00, -6.5150e+00, -9.7107e-01,\n",
      "        -3.2948e-01,  2.5415e-01,  5.2651e-01,  7.4216e+00, -9.0267e-01,\n",
      "        -4.1788e+00,  2.2370e+00,  9.6179e+00,  4.9099e-01, -5.3301e-01,\n",
      "         3.5424e+00, -4.4684e-01, -8.0730e-01, -9.2975e-01,  5.6016e+00,\n",
      "         1.8706e+00, -3.8189e+00,  4.1242e+00,  3.8238e+00,  3.7290e-01,\n",
      "         2.6519e+00, -1.2764e+00, -2.1649e+00,  3.5609e+00, -8.5442e-01,\n",
      "        -4.4107e-01,  9.3796e+00,  2.9520e+00, -3.8170e-01, -1.3617e+00,\n",
      "         5.4898e-01,  9.1378e+00,  4.5382e+00,  7.4073e+00,  2.1877e+00,\n",
      "         3.4941e+00, -1.0535e+01,  3.0390e+00, -3.0659e+00, -1.7488e+00,\n",
      "        -9.3210e+00,  2.5417e+00, -6.3350e+00,  3.4418e+00, -5.2338e+00,\n",
      "        -5.8885e-01,  1.6319e+00,  1.6491e+00,  1.7342e+00, -7.9318e-01,\n",
      "         6.8204e+00, -6.1409e+00,  3.5772e+00,  1.9219e+00,  5.5041e-01,\n",
      "        -3.3191e+00,  2.2557e+00, -8.9615e+00, -7.5672e+00, -1.3450e+00,\n",
      "         4.8523e+00, -6.8862e-01, -8.8473e+00, -3.1955e+00, -2.0104e+00,\n",
      "         9.6998e+00, -1.6352e+00, -4.4211e+00,  4.6420e+00,  2.3833e+00,\n",
      "         2.5475e+00, -4.0904e+00, -7.0739e+00,  1.7430e+00,  1.3902e+00,\n",
      "        -3.9033e+00, -2.1125e+00, -2.6082e+00, -5.2099e+00,  9.5807e+00,\n",
      "        -1.4032e+00,  3.6701e+00, -4.7797e+00,  6.9348e+00,  4.8764e+00,\n",
      "        -2.6500e-01,  4.9907e+00,  2.0800e-01, -7.3440e+00,  1.7602e+00,\n",
      "        -1.3062e+01,  1.0485e+01, -3.5736e+00,  1.4996e+00, -4.1021e+00,\n",
      "        -4.4909e-01,  6.9055e+00,  7.0265e+00, -5.9789e-01, -4.5568e+00,\n",
      "        -3.5238e+00, -8.0854e+00,  6.9935e-01,  5.3185e+00,  9.5748e-01,\n",
      "        -7.0918e+00,  4.2332e+00, -5.4036e+00, -5.0974e+00,  7.8156e-01,\n",
      "         3.9248e+00, -1.2459e-01,  4.5356e+00, -7.9295e-01,  1.5595e+00,\n",
      "         9.2243e+00, -2.0316e+00, -7.9548e-01,  2.8317e-01,  2.6292e+00,\n",
      "         6.0321e+00,  4.6681e+00,  1.6802e+00,  9.6592e+00, -5.4792e+00,\n",
      "         3.9242e+00, -1.2946e-01, -1.0277e+01, -2.2234e-01, -5.3529e+00,\n",
      "        -1.4128e+00,  2.2767e+00,  8.4789e+00,  3.6149e+00, -5.2660e-01,\n",
      "        -8.4713e+00,  9.4161e+00, -1.5926e+00,  6.4449e-01,  4.0824e+00,\n",
      "        -1.3423e+00, -2.9161e+00, -2.3765e+00,  1.0254e+00, -1.9889e+00,\n",
      "         5.9667e+00,  7.9947e+00, -7.4879e+00,  7.8507e+00, -4.2025e+00,\n",
      "        -7.7323e-01, -2.4850e-01,  2.0151e-01,  7.2853e+00, -3.9316e+00,\n",
      "        -7.0431e+00,  3.1569e+00, -1.4668e+00, -1.1118e+00,  3.7967e-01,\n",
      "        -4.9894e+00, -1.4859e+00,  2.2884e+00,  2.4502e+00, -8.3760e+00,\n",
      "         9.7899e+00, -1.1879e+00, -1.8145e+00, -2.0571e+00, -1.1680e+00,\n",
      "         1.3053e+00,  1.0271e-01,  4.9739e+00,  2.6493e+00, -1.4281e+00,\n",
      "        -9.9107e-01, -5.5264e+00,  7.4080e+00,  1.3537e-01, -3.5871e+00,\n",
      "         1.4069e+00,  1.9110e-01, -2.4356e+00, -2.6024e-01, -4.1470e+00,\n",
      "         9.0189e-01,  2.6930e+00, -8.2941e-01, -6.2876e+00,  4.4119e+00,\n",
      "        -2.2803e+00, -2.3798e-01, -4.0744e+00,  1.2899e+00,  5.9259e+00,\n",
      "        -1.4491e+00,  4.1115e+00,  7.6507e+00, -5.2266e-01,  8.1478e-01,\n",
      "        -5.9488e-01, -2.8800e+00,  1.6070e+00, -1.3038e+00,  8.4536e+00,\n",
      "         3.1574e+00,  4.3699e+00,  3.4014e+00,  3.5842e-01, -1.3215e+01,\n",
      "        -1.4053e+00, -2.6288e+00,  4.8143e+00,  2.0539e+00,  1.6748e-01,\n",
      "         4.1767e+00, -5.7380e+00, -1.7701e+00,  1.8064e+00, -3.6607e+00,\n",
      "        -5.5449e+00,  2.8341e+00,  4.1512e+00, -4.7526e-01,  6.4209e+00,\n",
      "         7.9021e+00,  2.0874e+00, -1.0135e+00, -4.5659e-01,  3.9279e+00,\n",
      "         5.2623e+00,  1.1785e+01,  5.6953e+00, -6.3919e+00, -1.8736e+00,\n",
      "        -2.2431e-01, -1.1242e+00,  6.3765e+00,  8.5676e+00,  1.8241e+00,\n",
      "         1.3565e+00,  8.2621e+00, -3.7792e+00,  5.2332e-01,  2.7537e+00,\n",
      "         7.2349e+00, -5.9973e+00, -2.3626e+00, -1.7545e+00, -6.0492e+00,\n",
      "        -1.8521e+00,  7.7976e+00, -1.9034e+00, -2.2468e+00, -6.2180e+00,\n",
      "         1.5873e+00, -5.8712e+00,  2.0896e+00, -2.1326e+00,  5.0761e-01,\n",
      "         6.1060e+00, -4.0378e+00,  3.0972e+00, -1.2133e+00,  3.1608e-01,\n",
      "        -5.4708e-01, -1.0551e+01,  3.8208e+00, -4.5960e+00, -4.6720e+00,\n",
      "         4.2589e+00,  2.4463e+00,  8.6115e-01,  3.8327e+00, -1.2704e+00,\n",
      "        -6.9881e+00,  1.6168e+00, -3.6859e-01, -1.1892e+00,  9.8264e-01,\n",
      "        -2.0420e+00,  3.5137e-01, -2.3380e+00,  6.3113e+00,  5.1162e-01,\n",
      "         3.4345e+00,  5.0087e+00, -3.2619e-01,  2.4778e+00,  5.8520e+00,\n",
      "         5.6123e+00,  3.7472e+00,  2.6442e+00, -5.7065e+00, -5.1231e+00,\n",
      "         2.1446e+00, -3.2127e+00, -4.4776e+00, -3.8182e-01,  6.0845e+00,\n",
      "         4.2760e+00, -2.8033e+00, -7.8626e+00,  6.8845e+00, -6.0340e+00,\n",
      "         2.4813e-01,  7.6411e+00, -3.5006e+00, -1.0102e+00, -1.9267e+00,\n",
      "         3.0783e+00,  1.5398e+00, -4.9042e+00,  5.0269e-01,  2.0002e+00,\n",
      "        -1.4566e+00,  7.0904e+00,  2.1972e+00,  7.2551e+00, -7.9671e+00,\n",
      "         3.1286e+00, -5.5992e+00,  5.7037e+00, -6.5521e+00, -1.2914e+01,\n",
      "         3.0881e+00,  1.5450e+00, -2.8072e+00, -1.0299e+01,  5.9666e+00,\n",
      "        -6.3466e+00,  4.7114e+00, -5.0114e-01, -2.1233e+00, -3.1761e+00,\n",
      "        -5.0386e+00,  6.2882e+00,  3.6287e+00])}, 'audio': {'emotion_logits': tensor([-0.1076,  0.1115,  0.2050, -0.5880,  1.1384, -0.1085,  0.2426]), 'personality_scores': tensor([0.5481, 0.4844, 0.4369, 0.5322, 0.5242]), 'last_emo_encoder_features': tensor([-1.3355e+00, -8.5689e-02,  4.6090e-01, -1.8019e-01, -6.8487e-02,\n",
      "        -7.9714e-01,  1.5483e-01, -1.1817e+00, -5.3850e-01,  5.4323e-01,\n",
      "        -2.9138e-01,  1.7660e-01,  3.7927e-01, -8.1957e-02,  2.8967e-01,\n",
      "         3.4342e-01, -3.8540e-01,  4.6886e-01,  7.8265e-02, -1.1122e-01,\n",
      "        -1.7872e-01,  1.6941e-02,  4.7144e-01,  2.6813e-01,  3.0537e-01,\n",
      "         2.3239e-01, -1.1960e-01,  7.3842e-02,  2.6231e-01, -2.6510e-01,\n",
      "        -4.6058e-02, -6.4226e-02, -2.9877e-01,  3.1593e-01, -2.0665e-01,\n",
      "         1.2790e-02, -3.7107e-01, -5.0167e-02,  2.8607e-02,  7.7152e-02,\n",
      "        -4.5779e-01,  2.6486e-01, -1.2267e-01, -1.9282e-01, -2.8726e-01,\n",
      "         1.3352e-01,  1.5981e-01, -2.9530e-02, -7.9643e-02,  3.6666e-02,\n",
      "         8.3654e-02,  4.9430e-01, -1.3549e-01, -3.1343e-01,  8.7429e-01,\n",
      "        -2.2626e-02, -8.8080e-02,  4.9344e-01, -2.0043e-01,  1.5469e-01,\n",
      "         2.8418e-02,  4.4087e-01,  5.0201e-01, -1.2505e-01, -3.3629e-01,\n",
      "         1.2482e-01, -2.8649e-01,  8.7830e-01,  5.3066e-01, -2.7797e-01,\n",
      "        -1.1342e-01, -5.5768e-02,  7.5021e-01, -2.5901e-01, -6.0458e-01,\n",
      "         5.0563e-02, -3.1710e-02, -7.1117e-01, -2.9598e-01,  1.7841e-01,\n",
      "        -1.0658e-01, -2.3616e-01, -2.6212e-03, -2.4693e-01, -4.6913e-01,\n",
      "         4.0845e-01, -3.0498e-01,  6.1779e-02,  4.5943e-01, -4.2238e-01,\n",
      "        -4.7365e-01,  3.4135e-01, -5.7148e-02, -3.6354e-01,  5.4116e-01,\n",
      "         3.3173e-01,  3.6332e-01, -1.1710e-01, -1.0179e+00,  2.4123e-01,\n",
      "         3.9732e-01, -4.3600e-01,  7.1000e-01,  3.4202e-02,  3.2723e-01,\n",
      "         1.7794e-01, -6.2545e-01,  3.9149e-02, -2.2221e-01, -3.1657e-01,\n",
      "         8.5077e-01,  5.1825e-01, -8.3025e-02, -2.2222e-01, -3.4578e-01,\n",
      "        -2.9228e-01, -4.1871e-01,  2.8280e-01, -5.5250e-01, -7.5368e-02,\n",
      "        -6.0876e-02, -3.6595e-01, -3.3945e-01, -3.3391e-02,  2.1097e-01,\n",
      "        -1.8765e-01, -1.5005e-01,  7.2303e-02, -4.1087e-01, -5.7971e-01,\n",
      "        -8.6625e-01,  3.2982e-02, -1.8321e-01, -1.8292e-02, -2.6247e-02,\n",
      "        -2.4729e-01, -1.8026e-01,  5.2362e-02,  4.7769e-01,  9.8055e-02,\n",
      "         9.2599e-01, -2.8133e-01,  1.3465e-02,  3.0121e-01,  7.9329e-01,\n",
      "        -4.4242e-01, -1.2334e-01,  5.0006e-01,  1.2934e-01,  7.4438e-01,\n",
      "         4.0343e-01, -5.5753e-02,  1.8206e-01, -5.0018e-01, -1.8114e-01,\n",
      "         4.7154e-01,  3.3047e-01,  1.0817e-02,  1.7245e-02,  1.4924e-01,\n",
      "         2.7376e-01,  1.1900e-01,  2.3828e-01, -1.5656e-02,  3.4809e-01,\n",
      "        -1.8488e-01,  8.1097e-04,  1.3745e-01, -3.0497e-01,  5.1091e-01,\n",
      "        -5.5081e-02, -2.0967e-02,  4.9937e-01, -2.6562e-01,  4.2074e-01,\n",
      "        -7.1375e-01,  4.0121e-01, -2.0999e-01, -2.2290e-01,  3.1125e-01,\n",
      "         2.3035e-01, -1.0774e-02,  1.4413e-01, -1.6087e-01, -3.7071e-01,\n",
      "        -2.2799e-01,  4.7164e-01,  3.0333e-01,  2.8435e-01, -2.7192e-01,\n",
      "         5.3863e-02, -8.5868e-02, -5.5163e-02, -4.2883e-01,  1.2452e-01,\n",
      "        -3.9853e-01,  4.7589e-01,  4.8190e-01, -3.7574e-01,  1.5178e+00,\n",
      "         4.6646e-01,  2.5487e-01, -1.0455e-01,  2.0801e-01, -4.5364e-01,\n",
      "         5.1163e-01, -6.2002e-02, -8.1130e-03,  9.1308e-02, -2.7466e-01,\n",
      "        -5.4775e-02, -8.6379e-01,  3.4787e-01,  2.9951e-01, -1.3286e-01,\n",
      "        -7.0264e-01,  3.0289e-04, -1.9829e-01, -5.7148e-03,  3.3260e-01,\n",
      "        -4.2053e-01,  1.1689e-01, -4.1891e-01, -3.4421e-01, -3.1856e-02,\n",
      "        -1.6963e-01, -4.7391e-01, -4.9746e-01,  3.7469e-01,  5.7538e-01,\n",
      "        -2.9695e-01, -7.2013e-01,  1.2484e-01,  2.1572e-01,  5.6515e-02,\n",
      "        -4.1075e-01,  7.7875e-01,  6.7799e-01,  4.5674e-03, -4.1912e-01,\n",
      "         5.2129e-01,  7.6064e-01,  3.7258e-01, -5.9563e-01, -5.3276e-01,\n",
      "        -4.9210e-01, -9.0970e-01, -7.5119e-02,  1.7269e-01, -5.2441e-01,\n",
      "         3.8738e-01, -4.1055e-01,  5.6959e-02, -3.2818e-01, -2.5792e-01,\n",
      "         1.2507e-01]), 'last_per_encoder_features': tensor([-0.2641, -0.2310, -0.7558,  0.2488, -0.0789, -0.3536,  0.2219, -0.3574,\n",
      "         1.2963, -0.3156, -0.9599, -0.1017, -0.7655,  0.7691, -0.2863,  0.5405,\n",
      "         0.4290,  0.5654,  0.0710, -0.5230, -0.4857, -0.2002, -0.6224, -0.8489,\n",
      "         0.7986, -0.3274, -0.8192, -0.7866, -0.6279,  0.5334,  0.0350,  0.2803,\n",
      "         0.1434, -0.0461, -0.0235, -0.4954, -0.1844,  0.4977,  0.9379, -0.5396,\n",
      "         0.4824,  0.4107,  1.9974,  0.5315,  0.3247,  0.0282, -0.6316, -0.6064,\n",
      "         0.5380,  0.1842, -0.1066,  0.6489,  0.1048,  0.0164, -0.5976,  0.1883,\n",
      "        -0.2066,  0.2693,  0.5412,  1.0192,  0.4994,  0.1326, -0.0341,  0.8021,\n",
      "        -0.4973, -0.3757,  0.1763, -1.5760,  0.1222,  0.2187, -0.5125, -0.8347,\n",
      "         0.3684,  1.0637, -0.5532, -0.1632,  0.4516,  0.2847, -0.0602, -0.3185,\n",
      "         0.4469,  0.2841, -0.3654,  0.3704,  0.3099, -0.0432, -0.1248, -0.3555,\n",
      "         0.4505, -0.3147,  0.0934,  0.3029, -0.4013,  0.9521,  0.4735, -0.2377,\n",
      "         0.5819,  0.5469, -0.5570,  1.1016,  0.2558,  0.7575, -0.1614,  0.1763,\n",
      "        -0.7110, -0.5784, -0.5939, -0.2927,  0.1854,  1.5980,  0.5500, -0.1313,\n",
      "         0.1461, -0.2330, -0.0644, -0.4123,  0.2928, -0.1154,  0.1881,  0.1703,\n",
      "        -0.3042, -0.4329,  0.4404, -1.1458,  0.0398,  0.8297,  1.1925, -0.7699,\n",
      "         0.5341, -0.3162,  0.7773,  0.1320,  0.5804, -0.2844, -0.3051,  0.3689,\n",
      "        -0.7564,  0.0104, -0.0321,  0.7028,  0.6100,  0.6107,  0.4356, -0.7625,\n",
      "        -0.3859,  0.1661,  0.2778,  0.6780, -0.1868,  0.4524, -0.4024,  0.4588,\n",
      "         1.1699,  0.3063,  0.1276, -0.1493,  0.9676,  0.0106, -0.2752,  0.8598,\n",
      "         1.1187, -0.1397, -0.1536,  0.6003, -0.6024,  0.4441,  0.1409,  0.0336,\n",
      "         0.0286,  0.5055, -0.5980,  0.1287,  0.3479,  0.6116, -0.3302,  0.3260,\n",
      "        -0.4298, -0.8978,  0.3685,  0.8808,  0.7713, -1.2171,  0.7386, -0.0588,\n",
      "         0.3393, -0.2123, -0.1039, -0.2768,  0.9029, -0.2932,  0.4855, -0.2023,\n",
      "        -0.5565, -1.1449,  0.9671, -0.0915, -0.7331,  0.5613, -1.0176,  0.3805,\n",
      "         1.2471,  0.3241, -0.5269, -0.0357, -0.5754,  0.8233, -0.4126,  0.6305,\n",
      "        -0.4254, -0.3425, -1.2499,  0.6832,  0.5735, -0.0742, -0.5933,  0.0673,\n",
      "         1.3720,  0.1959,  0.0391,  0.1923,  0.7568, -0.8194, -0.7462, -0.9003,\n",
      "         0.4604, -0.8845, -0.5075,  0.7874,  0.6474,  0.6273,  0.1853,  0.9412,\n",
      "        -0.6589,  0.7262, -0.2550,  1.3964,  0.0172, -1.7077, -0.8431,  0.0813,\n",
      "         0.6821,  0.6047,  0.5541, -1.9281,  1.2789, -0.0703, -0.9138, -0.2589,\n",
      "        -0.9199, -0.8584, -0.7435,  0.0166,  0.8706, -0.8303, -0.4226, -0.5856])}, 'text': {'emotion_logits': tensor([-1.7925,  0.0654,  0.3438, -0.3643, -1.1636, -0.1055,  2.4729]), 'personality_scores': tensor([0.4693, 0.4101, 0.3828, 0.5089, 0.4350]), 'last_emo_encoder_features': tensor([ 1.3117,  0.1233,  0.1214, -0.6749,  1.3550,  0.2257,  0.5565,  1.1860,\n",
      "        -0.1013, -0.2597, -0.4604,  0.4811,  0.9304,  0.6934, -1.3293, -0.3832,\n",
      "        -0.2334,  0.5496,  0.8171, -0.3050, -2.9424,  0.0758, -0.1881, -0.2041,\n",
      "        -0.9533, -1.3416,  0.1969, -1.0516, -0.7661, -3.4851,  0.9880, -0.4750,\n",
      "         0.5690,  1.2738, -1.3251, -0.5083,  0.9850,  0.9867,  0.3676,  0.6562,\n",
      "        -0.6075, -0.8803,  1.8229,  0.9221,  0.2806,  0.5674,  0.9808,  1.0890,\n",
      "         0.7677, -0.1906,  0.0849, -0.1676,  0.8111, -0.2369, -0.5160,  1.2389,\n",
      "         0.9324, -0.0288,  0.6982,  0.1881,  0.5070, -1.6251, -0.1079, -0.6248,\n",
      "        -0.2233, -2.4996,  1.1034,  0.0304, -0.0927, -0.1810, -0.3401, -0.9445,\n",
      "        -1.8510, -2.1253, -0.6261,  1.2160, -1.8038, -1.3030, -1.5683,  1.6455,\n",
      "        -0.4817,  1.7856, -0.2689, -0.6165, -1.3724, -0.5397,  0.8658, -1.8734,\n",
      "         1.8740,  0.9101, -0.2718, -2.0057, -0.3465, -1.9095, -0.2953, -0.1595,\n",
      "         0.9911, -0.7710, -0.3047, -2.1182, -0.7757, -0.4620, -1.5437, -0.1667,\n",
      "        -0.1403,  0.2478,  0.3537, -0.9259, -2.4161, -0.5158,  2.8783,  0.3477,\n",
      "        -0.4141,  0.5643,  0.7378, -0.4476,  1.1763, -1.1265, -0.0538, -1.0611,\n",
      "         0.4653, -0.8607, -0.1139, -1.3049,  0.2893, -0.5542,  0.4198, -0.0609,\n",
      "        -1.4974,  0.0406, -0.7295, -0.0865, -0.5733, -1.0767, -0.6369,  1.1113,\n",
      "        -0.4406, -1.3484,  1.3967, -0.9612, -0.8654, -0.2711,  1.9411, -1.5866,\n",
      "        -0.0766,  0.1246, -2.0886,  1.6158, -0.0729,  0.7784,  2.0847, -0.6618,\n",
      "         0.3601, -2.0811,  0.2766, -0.2644, -0.0128,  0.1023,  1.0281,  0.0365,\n",
      "         0.1917,  1.7674, -0.2487,  1.2056, -0.3284,  0.4611, -1.6409, -0.7981,\n",
      "        -1.3425, -1.9783, -0.0963, -1.9919,  0.6237, -0.5455, -0.0987, -0.4003,\n",
      "        -1.1158, -0.1506, -1.5576, -0.2314, -0.9786,  2.0852,  1.2366,  1.0729,\n",
      "         0.2970,  0.4120,  0.0085, -0.2069, -0.0069,  0.1019,  0.7239,  0.7537,\n",
      "        -0.1292,  0.1896, -0.4214, -0.8295,  0.5412, -0.3393, -1.3720, -1.1984,\n",
      "         1.8579, -1.0736, -0.0210,  0.7834, -0.6732, -1.0010, -1.3657,  0.6824,\n",
      "        -0.0895,  0.5278,  0.0349,  0.3871,  0.7223,  1.0460, -0.0253, -0.4317,\n",
      "         0.0855, -1.4607, -0.0265, -1.1861,  1.6116,  0.3913, -1.5451,  0.8913,\n",
      "         0.7283,  0.6867,  1.7406,  0.6090, -0.5990,  0.6313, -1.0585,  1.4705,\n",
      "         0.4126, -0.1873, -1.6296,  0.3986, -0.0329,  0.9603,  0.5962, -0.7992,\n",
      "        -0.4637, -1.1269,  0.4375, -2.2573,  0.2851, -1.4316, -0.2300, -0.4036,\n",
      "        -1.3178,  0.5397,  0.8350, -1.7956,  1.2486,  0.8479,  0.4694, -0.4344]), 'last_per_encoder_features': tensor([ 0.5426,  1.0645, -2.0989, -3.1014, -1.3559,  0.5425,  1.0779,  2.7516,\n",
      "        -1.2365,  0.2915,  1.2540, -2.0358, -1.2977,  1.1356, -1.8996, -0.2158,\n",
      "         0.5879, -0.6509, -0.7874, -3.4764,  3.4650,  1.7006, -0.0768,  2.2589,\n",
      "        -0.0663,  1.0481,  2.7645,  1.1218,  0.5240,  4.4635, -0.4183, -2.1453,\n",
      "        -0.1275, -0.8448, -1.4215, -1.4652,  1.1589,  1.8271, -2.8099, -3.1310,\n",
      "         0.6701, -0.2038,  2.6913,  3.0303, -1.2003,  0.6285, -1.4875,  1.8531,\n",
      "         4.8925,  1.5720, -2.8771, -1.5059, -1.4728, -5.5800, -1.6177, -0.5982,\n",
      "        -0.6509, -0.4453,  1.1731, -2.0243,  0.8411, -2.1620,  4.8387, -0.7772,\n",
      "         4.5490, -2.5652, -0.6364, -4.3771, -0.3411, -3.0718, -1.4518, -1.1763,\n",
      "        -2.6802, -0.8860,  1.4294,  2.3022, -1.1359, -0.8532, -0.8563,  5.2685,\n",
      "        -0.7511, -2.3058, -4.0288, -4.6303, -0.2756, -0.3849,  3.0891, -2.1003,\n",
      "        -0.7071, -1.3395,  3.1762,  0.0364, -1.2352, -2.7171, -2.9043, -2.8764,\n",
      "        -2.6795,  0.5879, -0.2619,  2.0823, -3.2588,  0.1975, -0.7615,  0.3763,\n",
      "         1.2806,  2.2529, -3.3445,  0.0143, -2.9520,  2.3400, -1.0386,  2.4104,\n",
      "        -2.6775, -1.4231,  0.2113,  0.8228, -0.3736, -1.7517,  1.9025, -0.6338,\n",
      "        -2.0133, -0.2947,  0.2376,  1.4427,  1.3880,  0.8147,  2.5831,  3.5425,\n",
      "        -3.5206,  1.3838, -0.5941, -0.9153,  2.1187,  3.6365,  0.2208,  3.2290,\n",
      "         0.0278,  1.3414,  0.5766, -0.6114,  2.4437,  1.9112,  2.6598,  3.5696,\n",
      "         2.3405, -0.5312,  0.0389, -2.6998, -3.0750,  2.7324,  2.0325, -0.2043,\n",
      "        -4.5035, -3.3940,  1.6156,  0.1535, -0.8984,  1.9044, -0.6904, -2.1375,\n",
      "         2.1775,  3.5728, -0.7829,  0.7266,  2.6296, -1.0245, -0.2674,  0.7676,\n",
      "         2.7830, -1.4738, -0.3041,  0.1433, -0.2599, -2.1977, -1.9421, -0.5589,\n",
      "        -0.3278,  2.3638, -2.2062, -0.0663,  0.3710, -0.6494,  0.5393,  2.8830,\n",
      "         0.2444, -0.4842, -2.2247, -0.6965, -0.0560, -0.4123, -0.6624, -0.9111,\n",
      "         0.8858, -1.9075, -0.7388, -1.2997,  0.4630,  1.3783, -3.4890,  3.2895,\n",
      "        -1.2114, -2.5037, -0.2853,  2.4516, -1.6238,  0.0358, -1.3388, -0.0261,\n",
      "        -0.6262,  0.6606,  1.3133,  2.1290,  0.7847,  0.1059, -0.5723, -0.9960,\n",
      "         0.2435,  3.1135,  0.3427, -0.1619,  2.0551, -0.6046, -0.5295,  0.2334,\n",
      "         0.1064,  1.3703, -1.7061,  2.5742,  2.7846,  0.9953,  0.1118, -1.5034,\n",
      "        -0.4731,  0.7922, -0.4870,  0.0148,  1.5639,  1.3181, -1.0070,  2.3792,\n",
      "        -0.4095,  0.9049,  0.1947,  2.1153,  0.8144,  1.0136, -3.3148, -4.6253,\n",
      "        -0.8728,  1.1024,  1.7151,  1.6620, -0.7445, -1.5648, -2.8328,  2.9501])}}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# –ø—É—Ç—å –∫ —Ç–≤–æ–µ–º—É .pickle —Ñ–∞–π–ª—É\n",
    "pickle_path = \"../features/fiv2_test_seed_42_subset_size_2_average_features_True_feature_norm_False.pickle\"\n",
    "\n",
    "with open(pickle_path, \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# –ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç\n",
    "print(\"üîç –ü–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç:\")\n",
    "item = data[0][\"features\"]\n",
    "print(item)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "94645014-a1a1-4c20-8342-d9bf1711a310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîé –®–µ–π–ø—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:\n",
      "\n",
      "[BODY]\n",
      "  emotion_logits: torch.Size([7])\n",
      "  personality_scores: torch.Size([5])\n",
      "  last_emo_encoder_features: torch.Size([1024])\n",
      "  last_per_encoder_features: torch.Size([1024])\n",
      "\n",
      "[FACE]\n",
      "  emotion_logits: torch.Size([7])\n",
      "  personality_scores: torch.Size([5])\n",
      "  last_emo_encoder_features: torch.Size([512])\n",
      "  last_per_encoder_features: torch.Size([512])\n",
      "\n",
      "[SCENE]\n",
      "  emotion_logits: torch.Size([7])\n",
      "  personality_scores: torch.Size([5])\n",
      "  last_emo_encoder_features: torch.Size([768])\n",
      "  last_per_encoder_features: torch.Size([768])\n",
      "\n",
      "[AUDIO]\n",
      "  emotion_logits: torch.Size([7])\n",
      "  personality_scores: torch.Size([5])\n",
      "  last_emo_encoder_features: torch.Size([256])\n",
      "  last_per_encoder_features: torch.Size([256])\n",
      "\n",
      "[TEXT]\n",
      "  emotion_logits: torch.Size([7])\n",
      "  personality_scores: torch.Size([5])\n",
      "  last_emo_encoder_features: torch.Size([256])\n",
      "  last_per_encoder_features: torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ: —Ä–∞—Å–ø–µ—á–∞—Ç–∞—Ç—å —à–µ–π–ø—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç—è–º\n",
    "print(\"\\nüîé –®–µ–π–ø—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:\")\n",
    "modalities = item.get(\"features\", {})\n",
    "for mod_name, features in modalities.items():\n",
    "    print(f\"\\n[{mod_name.upper()}]\")\n",
    "    for feat_name, feat_val in features.items():\n",
    "        if isinstance(feat_val, torch.Tensor):\n",
    "            print(f\"  {feat_name}: {feat_val.shape}\")\n",
    "        elif isinstance(feat_val, np.ndarray):\n",
    "            print(f\"  {feat_name}: {feat_val.shape}\")\n",
    "        else:\n",
    "            print(f\"  {feat_name}: not a tensor ({type(feat_val)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3ce5167-c20c-45ae-a2b6-83fe00944210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "–≠–ª–µ–º–µ–Ω—Ç–æ–≤ –≤ —Å–ø–∏—Å–∫–µ: 10\n"
     ]
    }
   ],
   "source": [
    "print(type(data))\n",
    "print(f\"–≠–ª–µ–º–µ–Ω—Ç–æ–≤ –≤ —Å–ø–∏—Å–∫–µ: {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b54d3cb-f4d8-4c14-b792-c8d6b4b72fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–£–¥–∞–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É/–∏: ['Unnamed: 0']\n",
      "–ì–æ—Ç–æ–≤–æ. –ß–∏—Å—Ç—ã–π CSV —Å–æ—Ö—Ä–∞–Ω—ë–Ω —Å—é–¥–∞: E:/FirstImpressionsV2/dev_full.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def clean_csv_to_copy(csv_path: str, output_path: str):\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # –£–¥–∞–ª—è–µ–º –Ω–µ–Ω–∞–∑–≤–∞–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏\n",
    "    unnamed_cols = [col for col in df.columns if col.startswith(\"Unnamed\") or col.strip() == \"\"]\n",
    "    if unnamed_cols:\n",
    "        print(f\"–£–¥–∞–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É/–∏: {unnamed_cols}\")\n",
    "        df = df.drop(columns=unnamed_cols)\n",
    "\n",
    "    # –ß–∏—Å—Ç–∏–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –≤ video_name\n",
    "    if 'video_name' not in df.columns:\n",
    "        raise ValueError(\"–§–∞–π–ª –±–µ–∑ 'video_name'. –¢—ã —á—Ç–æ, —Ä–µ—à–∏–ª –ø–æ—à—É—Ç–∏—Ç—å?\")\n",
    "    \n",
    "    df['video_name'] = df['video_name'].apply(lambda x: os.path.splitext(str(x))[0])\n",
    "\n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –Ω–æ–≤—ã–π —Ñ–∞–π–ª\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"–ì–æ—Ç–æ–≤–æ. –ß–∏—Å—Ç—ã–π CSV —Å–æ—Ö—Ä–∞–Ω—ë–Ω —Å—é–¥–∞: {output_path}\")\n",
    "    \n",
    "# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\n",
    "csv_path = \"E:/FirstImpressionsV2/dev_FIv2.csv\"\n",
    "output_path = \"E:/FirstImpressionsV2/dev_full.csv\"\n",
    "clean_csv_to_copy(csv_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a29e415-3053-4ba2-ac3e-88ee39d105a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–£–¥–∞–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É/–∏: ['Unnamed: 0']\n",
      "–ì–æ—Ç–æ–≤–æ. –ß–∏—Å—Ç—ã–π CSV —Å–æ—Ö—Ä–∞–Ω—ë–Ω —Å—é–¥–∞: E:/FirstImpressionsV2/test_full.csv\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"E:/FirstImpressionsV2/test_FIv2.csv\"\n",
    "output_path = \"E:/FirstImpressionsV2/test_full.csv\"\n",
    "clean_csv_to_copy(csv_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1aae35de-5703-48e0-ad13-8b306d8a2403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–£–¥–∞–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É/–∏: ['Unnamed: 0']\n",
      "–ì–æ—Ç–æ–≤–æ. –ß–∏—Å—Ç—ã–π CSV —Å–æ—Ö—Ä–∞–Ω—ë–Ω —Å—é–¥–∞: E:/FirstImpressionsV2/train_full.csv\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"E:/FirstImpressionsV2/train_FIv2.csv\"\n",
    "output_path = \"E:/FirstImpressionsV2/train_full.csv\"\n",
    "clean_csv_to_copy(csv_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51906294-cbe0-4c0a-83dd-5bb069cbb0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['emo_model.emo_proj.0.weight', 'emo_model.emo_proj.0.bias', 'emo_model.emo_proj.1.weight', 'emo_model.emo_proj.1.bias', 'emo_model.emotion_encoder.0.in_proj.weight', 'emo_model.emotion_encoder.0.in_proj.bias', 'emo_model.emotion_encoder.0.s_B.weight', 'emo_model.emotion_encoder.0.s_B.bias', 'emo_model.emotion_encoder.0.s_C.weight', 'emo_model.emotion_encoder.0.s_C.bias', 'emo_model.emotion_encoder.0.out_proj.weight', 'emo_model.emotion_encoder.0.out_proj.bias', 'emo_model.emotion_encoder.0.norm.weight', 'emo_model.emotion_encoder.0.norm.bias', 'emo_model.emotion_encoder.1.in_proj.weight', 'emo_model.emotion_encoder.1.in_proj.bias', 'emo_model.emotion_encoder.1.s_B.weight', 'emo_model.emotion_encoder.1.s_B.bias', 'emo_model.emotion_encoder.1.s_C.weight', 'emo_model.emotion_encoder.1.s_C.bias', 'emo_model.emotion_encoder.1.out_proj.weight', 'emo_model.emotion_encoder.1.out_proj.bias', 'emo_model.emotion_encoder.1.norm.weight', 'emo_model.emotion_encoder.1.norm.bias', 'emo_model.emotion_encoder.2.in_proj.weight', 'emo_model.emotion_encoder.2.in_proj.bias', 'emo_model.emotion_encoder.2.s_B.weight', 'emo_model.emotion_encoder.2.s_B.bias', 'emo_model.emotion_encoder.2.s_C.weight', 'emo_model.emotion_encoder.2.s_C.bias', 'emo_model.emotion_encoder.2.out_proj.weight', 'emo_model.emotion_encoder.2.out_proj.bias', 'emo_model.emotion_encoder.2.norm.weight', 'emo_model.emotion_encoder.2.norm.bias', 'emo_model.emotion_encoder.3.in_proj.weight', 'emo_model.emotion_encoder.3.in_proj.bias', 'emo_model.emotion_encoder.3.s_B.weight', 'emo_model.emotion_encoder.3.s_B.bias', 'emo_model.emotion_encoder.3.s_C.weight', 'emo_model.emotion_encoder.3.s_C.bias', 'emo_model.emotion_encoder.3.out_proj.weight', 'emo_model.emotion_encoder.3.out_proj.bias', 'emo_model.emotion_encoder.3.norm.weight', 'emo_model.emotion_encoder.3.norm.bias', 'emo_model.emotion_fc_out.0.weight', 'emo_model.emotion_fc_out.0.bias', 'emo_model.emotion_fc_out.1.weight', 'emo_model.emotion_fc_out.1.bias', 'emo_model.emotion_fc_out.4.weight', 'emo_model.emotion_fc_out.4.bias', 'per_model.per_proj.0.weight', 'per_model.per_proj.0.bias', 'per_model.per_proj.1.weight', 'per_model.per_proj.1.bias', 'per_model.personality_encoder.0.self_attention.in_proj_weight', 'per_model.personality_encoder.0.self_attention.in_proj_bias', 'per_model.personality_encoder.0.self_attention.out_proj.weight', 'per_model.personality_encoder.0.self_attention.out_proj.bias', 'per_model.personality_encoder.0.feed_forward.layer_1.weight', 'per_model.personality_encoder.0.feed_forward.layer_1.bias', 'per_model.personality_encoder.0.feed_forward.layer_2.weight', 'per_model.personality_encoder.0.feed_forward.layer_2.bias', 'per_model.personality_encoder.0.add_norm_after_attention.norm.weight', 'per_model.personality_encoder.0.add_norm_after_attention.norm.bias', 'per_model.personality_encoder.0.add_norm_after_ff.norm.weight', 'per_model.personality_encoder.0.add_norm_after_ff.norm.bias', 'per_model.personality_encoder.0.positional_encoding.pe', 'per_model.personality_fc_out.0.weight', 'per_model.personality_fc_out.0.bias', 'per_model.personality_fc_out.1.weight', 'per_model.personality_fc_out.1.bias', 'per_model.personality_fc_out.4.weight', 'per_model.personality_fc_out.4.bias', 'emo_proj.0.weight', 'emo_proj.0.bias', 'emo_proj.1.weight', 'emo_proj.1.bias', 'per_proj.0.weight', 'per_proj.0.bias', 'per_proj.1.weight', 'per_proj.1.bias', 'emotion_to_personality_attn.0.self_attention.in_proj_weight', 'emotion_to_personality_attn.0.self_attention.in_proj_bias', 'emotion_to_personality_attn.0.self_attention.out_proj.weight', 'emotion_to_personality_attn.0.self_attention.out_proj.bias', 'emotion_to_personality_attn.0.feed_forward.layer_1.weight', 'emotion_to_personality_attn.0.feed_forward.layer_1.bias', 'emotion_to_personality_attn.0.feed_forward.layer_2.weight', 'emotion_to_personality_attn.0.feed_forward.layer_2.bias', 'emotion_to_personality_attn.0.add_norm_after_attention.norm.weight', 'emotion_to_personality_attn.0.add_norm_after_attention.norm.bias', 'emotion_to_personality_attn.0.add_norm_after_ff.norm.weight', 'emotion_to_personality_attn.0.add_norm_after_ff.norm.bias', 'emotion_to_personality_attn.0.positional_encoding.pe', 'emotion_to_personality_attn.1.self_attention.in_proj_weight', 'emotion_to_personality_attn.1.self_attention.in_proj_bias', 'emotion_to_personality_attn.1.self_attention.out_proj.weight', 'emotion_to_personality_attn.1.self_attention.out_proj.bias', 'emotion_to_personality_attn.1.feed_forward.layer_1.weight', 'emotion_to_personality_attn.1.feed_forward.layer_1.bias', 'emotion_to_personality_attn.1.feed_forward.layer_2.weight', 'emotion_to_personality_attn.1.feed_forward.layer_2.bias', 'emotion_to_personality_attn.1.add_norm_after_attention.norm.weight', 'emotion_to_personality_attn.1.add_norm_after_attention.norm.bias', 'emotion_to_personality_attn.1.add_norm_after_ff.norm.weight', 'emotion_to_personality_attn.1.add_norm_after_ff.norm.bias', 'emotion_to_personality_attn.1.positional_encoding.pe', 'personality_to_emotion_attn.0.self_attention.in_proj_weight', 'personality_to_emotion_attn.0.self_attention.in_proj_bias', 'personality_to_emotion_attn.0.self_attention.out_proj.weight', 'personality_to_emotion_attn.0.self_attention.out_proj.bias', 'personality_to_emotion_attn.0.feed_forward.layer_1.weight', 'personality_to_emotion_attn.0.feed_forward.layer_1.bias', 'personality_to_emotion_attn.0.feed_forward.layer_2.weight', 'personality_to_emotion_attn.0.feed_forward.layer_2.bias', 'personality_to_emotion_attn.0.add_norm_after_attention.norm.weight', 'personality_to_emotion_attn.0.add_norm_after_attention.norm.bias', 'personality_to_emotion_attn.0.add_norm_after_ff.norm.weight', 'personality_to_emotion_attn.0.add_norm_after_ff.norm.bias', 'personality_to_emotion_attn.0.positional_encoding.pe', 'personality_to_emotion_attn.1.self_attention.in_proj_weight', 'personality_to_emotion_attn.1.self_attention.in_proj_bias', 'personality_to_emotion_attn.1.self_attention.out_proj.weight', 'personality_to_emotion_attn.1.self_attention.out_proj.bias', 'personality_to_emotion_attn.1.feed_forward.layer_1.weight', 'personality_to_emotion_attn.1.feed_forward.layer_1.bias', 'personality_to_emotion_attn.1.feed_forward.layer_2.weight', 'personality_to_emotion_attn.1.feed_forward.layer_2.bias', 'personality_to_emotion_attn.1.add_norm_after_attention.norm.weight', 'personality_to_emotion_attn.1.add_norm_after_attention.norm.bias', 'personality_to_emotion_attn.1.add_norm_after_ff.norm.weight', 'personality_to_emotion_attn.1.add_norm_after_ff.norm.bias', 'personality_to_emotion_attn.1.positional_encoding.pe', 'emotion_personality_fc_out.0.weight', 'emotion_personality_fc_out.0.bias', 'emotion_personality_fc_out.1.weight', 'emotion_personality_fc_out.1.bias', 'emotion_personality_fc_out.4.weight', 'emotion_personality_fc_out.4.bias', 'personality_emotion_fc_out.0.weight', 'personality_emotion_fc_out.0.bias', 'personality_emotion_fc_out.1.weight', 'personality_emotion_fc_out.1.bias', 'personality_emotion_fc_out.4.weight', 'personality_emotion_fc_out.4.bias'])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "checkpoint = torch.load(\"../modalities/text/checkpoints/Mamba_Transformer_bge-small_fusion.pt\", map_location=\"cpu\")\n",
    "\n",
    "print(checkpoint.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fb29a3-acbc-4709-a56a-057115c001eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
