# ---------------------------
# Настройки корпусов данных
# ---------------------------

[datasets.cmu_mosei]
base_dir = "E:/CMU-MOSEI/"
csv_path = "{base_dir}/{split}_full.csv"
video_dir  = "{base_dir}/video/{split}/"
audio_dir = "{base_dir}/audio/{split}/"

[datasets.fiv2]
base_dir = "E:/FirstImpressionsV2/"
csv_path = "{base_dir}/{split}_full.csv"
video_dir  = "{base_dir}/video/{split}/"
audio_dir = "{base_dir}/audio/{split}/"

# ---------------------------
# DataLoader параметры
# ---------------------------
[dataloader]
num_workers = 0
shuffle = true
prepare_only = false
average_features = true

# ---------------------------
# Общие параметры тренировки
# ---------------------------
[train.general]
random_seed = 42                  # фиксируем random seed для воспроизводимости (0 = каждый раз разный)
subset_size = 0                   # ограничение на количество примеров (0 = использовать весь датасет)
batch_size = 32                   # размер батча
num_epochs = 75                   # число эпох тренировки
max_patience = 15                 # максимальное число эпох без улучшений (для Early Stopping)
save_best_model = true            # сохранять лучшую модель
save_prepared_data = true         # сохранять извлеченные признаки (эмбеддинги)
save_feature_path = './features/' # путь для сохранения эмбеддингов
search_type = "exhaustive"        # стратегия поиска: "greedy", "exhaustive" или "none"
opt_set = 'dev'                   # набор для оптимизации параметров обучения
checkpoint_dir = "checkpoints"
device = "cuda"           # "cuda" или "cpu", куда грузить модел

# ---------------------------
# Параметры модели
# ---------------------------
[train.model]
model_name            = "FusionTransformer" # название модели
model_stage           = 'fusion' # название этапа personality, emotion, fusion
per_activation        = "relu"   # sigmoid
weight_emotion        = 1     # для корректировки лосса эмоций 0.1 при взвешивании классов, 1.0 без взвешивания
weight_pers           = 1        # для корректировки лосса персональных качеств
pers_loss_type        = 'mae'    # ccc, mae, mse, rmse_bell, rmse_logcosh, RMGL
flag_emo_weight       = true     # используем веса для дисбаланса эмоциональных классов
hidden_dim            = 512      # размер скрытого состояния
num_transformer_heads = 8        # количество attention голов в трансформере
tr_layer_number       = 5        # количество слоев в трансформере
positional_encoding   = false    # использовать ли позиционное кодирование
dropout               = 0.15     # dropout между слоями
out_features          = 256      # размер финальных признаков перед классификацией

# ---------------------------
# Параметры оптимизатора
# ---------------------------
[train.optimizer]
optimizer = "adamw"        # тип оптимизатора: "adam", "adamw", "lion", "sgd", "rmsprop"
lr = 1e-4                 # начальная скорость обучения
weight_decay = 1e-5        # weight decay для регуляризации
momentum = 0.9            # momentum (используется только в SGD)

# ---------------------------
# Параметры шедулера
# ---------------------------
[train.scheduler]
scheduler_type = "plateau" # тип шедулера: "none", "plateau", "cosine", "onecycle" ил  и HuggingFace-стиль ("huggingface_linear", "huggingface_cosine" "huggingface_cosine_with_restarts" и т.д.)
warmup_ratio = 0.1         # отношение количества warmup-итераций к общему числу шагов (0.1 = 10%)

[embeddings]
image_classifier_checkpoint = "torchscript_model_0_66_37_wo_gl.pth"
image_model_type = "emo"  # resnet18, emo, емоresnet50, resnet50, clip
image_embedding_dim = 512 # 2048 (емоresnet50, resnet50) и 512 (resnet18, emo, clip) размерность видео-эмбеддинга
cut_target_layer = 2      # 4 (емоresnet50) и 2 (resnet18, resnet50) и 3 (emo) слой до какого обрезать модель и извлечь фичи
roi_video = "body"        # область интереса или либо body или вся scene
counter_need_frames = 30  # сколько кадров отобрать из всех возможных с равномерным шагом
image_size = 224          # ширина и высота изображения
emb_normalize = false     # нормализовать ли вектор L2-нормой
